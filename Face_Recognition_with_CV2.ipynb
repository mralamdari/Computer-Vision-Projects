{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ddOtisxRYE2FpF4qmpfpykrP42oShXYp",
      "authorship_tag": "ABX9TyO2ONf0JpYw8amuK0ow9aNQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/Computer-Vision-Projects/blob/main/Face_Recognition_with_CV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import collections\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "tpy-74wiz6Mg"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "p9eIU7Pxewdk"
      },
      "outputs": [],
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive/'\n",
        "!kaggle datasets download -d olgabelitskaya/yale-face-database\n",
        "os.makedirs('/content/data/', exist_ok=True)\n",
        "os.rename('/content/yale-face-database.zip', '/content/data/yale-face-database.zip')\n",
        "!unzip /content/data/yale-face-database.zip && rm /content/data/yale-face-database.zip\n",
        "os.rename('/content/data/Readme.txt', '/content/Readme.txt')\n",
        "os.rename('/content/data/.ipynb_checkpoints', '/content/.ipynb_checkpoints')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def date_loader(path):\n",
        "\n",
        "  faces, ids = [], []\n",
        "  for p in os.listdir(path):\n",
        "    img = Image.open(os.path.join(path, p)).convert('L')\n",
        "    faces.append(np.array(img, 'uint8'))\n",
        "    id = int(p.split('.')[0].replace('subject', ''))\n",
        "    ids.append(id)\n",
        "  \n",
        "  return faces, np.array(ids)"
      ],
      "metadata": {
        "id": "vXbYkkXR09f4"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "faces, labels = date_loader('/content/data/')"
      ],
      "metadata": {
        "id": "HguSkqji1ebo"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collections.Counter(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugANutYtxjRI",
        "outputId": "759e8ff1-d85d-464b-e4cf-ebe824170364"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({15: 11,\n",
              "         14: 11,\n",
              "         5: 11,\n",
              "         8: 11,\n",
              "         9: 11,\n",
              "         12: 11,\n",
              "         3: 11,\n",
              "         10: 11,\n",
              "         11: 11,\n",
              "         4: 11,\n",
              "         6: 11,\n",
              "         7: 11,\n",
              "         2: 11,\n",
              "         1: 11,\n",
              "         13: 11})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset is balanced, so lets split it to train/test\n",
        "\n",
        "arr = [0]*16\n",
        "test_x, train_x = [], []\n",
        "test_y, train_y = [], []\n",
        "\n",
        "for f, l in zip(faces, labels):\n",
        "  if arr[l] < 1:\n",
        "    arr[l]+= 1\n",
        "    test_x.append(f)\n",
        "    test_y.append(l)\n",
        "  else:\n",
        "    train_x.append(f)\n",
        "    train_y.append(l)"
      ],
      "metadata": {
        "id": "dH9U9htBx4Qq"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lbph_clf = cv2.face.LBPHFaceRecognizer_create()\n",
        "lbph_clf.train(np.array(train_x), np.array(train_y))\n",
        "lbph_clf.write('libph_clf.yml')"
      ],
      "metadata": {
        "id": "fguo4I3tmng2"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lbph_clf = cv2.face.LBPHFaceRecognizer_create()\n",
        "lbph_clf.read('libph_clf.yml')"
      ],
      "metadata": {
        "id": "fIwJqtXCuJQP"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = lbph_clf.predict(np.array(test_x[0]))\n",
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjsV1FmH7TkC",
        "outputId": "baafa1e9-dbd3-47ba-d64e-3a5486690073"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15, 8.440935126341593)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XTjD2bx07igB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}