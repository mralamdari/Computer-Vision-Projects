{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqTqb9KiwMfiupMl0mJsIn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/Computer-Vision-Projects/blob/main/CT_Scans_TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import keras\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from scipy import ndimage"
      ],
      "metadata": {
        "id": "jaNlPoXUmzPo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download url of normal CT scans.\n",
        "url = \"https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-0.zip\"\n",
        "filename = os.path.join(os.getcwd(), \"CT-0.zip\")\n",
        "keras.utils.get_file(filename, url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "mm0ig1o4mZ6I",
        "outputId": "222b3c3e-9320-4045-ec3d-4ea03e089f60"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-0.zip\n",
            "1065471431/1065471431 [==============================] - 19s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/CT-0.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download url of abnormal CT scans.\n",
        "url = \"https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-23.zip\"\n",
        "filename = os.path.join(os.getcwd(), \"CT-23.zip\")\n",
        "keras.utils.get_file(filename, url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "6Lu7nxsPm7Is",
        "outputId": "264fbc38-9134-43b9-bf60-132b063ca519"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-23.zip\n",
            "1045162547/1045162547 [==============================] - 19s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/CT-23.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dVoW9DTVmKA6"
      },
      "outputs": [],
      "source": [
        "# Make a directory to store the data.\n",
        "os.makedirs(\"MosMedData\")\n",
        "\n",
        "# Unzip data in the newly created directory.\n",
        "with zipfile.ZipFile(\"CT-0.zip\", \"r\") as z_fp:\n",
        "    z_fp.extractall(\"./MosMedData/\")\n",
        "\n",
        "with zipfile.ZipFile(\"CT-23.zip\", \"r\") as z_fp:\n",
        "    z_fp.extractall(\"./MosMedData/\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_nifti_file(filepath):\n",
        "    \"\"\"Read and load volume\"\"\"\n",
        "    # Read file\n",
        "    scan = nib.load(filepath)\n",
        "    # Get raw data\n",
        "    scan = scan.get_fdata()\n",
        "    return scan"
      ],
      "metadata": {
        "id": "K3RoqsVBnEIl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(volume):\n",
        "    \"\"\"Normalize the volume\"\"\"\n",
        "    min = -1000\n",
        "    max = 400\n",
        "    volume[volume < min] = min\n",
        "    volume[volume > max] = max\n",
        "    volume = (volume - min) / (max - min)\n",
        "    volume = volume.astype(\"float32\")\n",
        "    return volume"
      ],
      "metadata": {
        "id": "XB5jOMronxMo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_volume(img):\n",
        "    \"\"\"Resize across z-axis\"\"\"\n",
        "    # Set the desired depth\n",
        "    desired_depth = 64\n",
        "    desired_width = 128\n",
        "    desired_height = 128\n",
        "    # Get current depth\n",
        "    current_depth = img.shape[-1]\n",
        "    current_width = img.shape[0]\n",
        "    current_height = img.shape[1]\n",
        "    # Compute depth factor\n",
        "    depth = current_depth / desired_depth\n",
        "    width = current_width / desired_width\n",
        "    height = current_height / desired_height\n",
        "    depth_factor = 1 / depth\n",
        "    width_factor = 1 / width\n",
        "    height_factor = 1 / height\n",
        "    # Rotate\n",
        "    img = ndimage.rotate(img, 90, reshape=False)\n",
        "    # Resize across z-axis\n",
        "    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n",
        "    return img"
      ],
      "metadata": {
        "id": "WGh9hNy0nxI_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_scan(path):\n",
        "    \"\"\"Read and resize volume\"\"\"\n",
        "    # Read scan\n",
        "    volume = read_nifti_file(path)\n",
        "    # Normalize\n",
        "    volume = normalize(volume)\n",
        "    # Resize width, height and depth\n",
        "    volume = resize_volume(volume)\n",
        "    return volume"
      ],
      "metadata": {
        "id": "h2iLNfyHneUA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Folder \"CT-0\" consist of CT scans having normal lung tissue,\n",
        "# no CT-signs of viral pneumonia.\n",
        "normal_scan_paths = [os.path.join(os.getcwd(), \"MosMedData/CT-0\", x) for x in os.listdir(\"MosMedData/CT-0\")]\n",
        "# Folder \"CT-23\" consist of CT scans having several ground-glass opacifications,\n",
        "# involvement of lung parenchyma.\n",
        "abnormal_scan_paths = [os.path.join(os.getcwd(), \"MosMedData/CT-23\", x) for x in os.listdir(\"MosMedData/CT-23\")]\n",
        "\n",
        "print(\"CT scans with normal lung tissue: \" + str(len(normal_scan_paths)))\n",
        "print(\"CT scans with abnormal lung tissue: \" + str(len(abnormal_scan_paths)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFOrbdzNneRY",
        "outputId": "96ad21cd-a3f2-4976-a16c-29b77e3d0470"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CT scans with normal lung tissue: 100\n",
            "CT scans with abnormal lung tissue: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read and process the scans.\n",
        "# Each scan is resized across height, width, and depth and rescaled.\n",
        "abnormal_scans = np.array([process_scan(path) for path in abnormal_scan_paths])\n",
        "normal_scans = np.array([process_scan(path) for path in normal_scan_paths])\n",
        "\n",
        "# For the CT scans having presence of viral pneumonia\n",
        "# assign 1, for the normal ones assign 0.\n",
        "abnormal_labels = np.array([1 for _ in range(len(abnormal_scans))])\n",
        "normal_labels = np.array([0 for _ in range(len(normal_scans))])\n",
        "\n",
        "# Split data in the ratio 70-30 for training and validation.\n",
        "x_train = np.concatenate((abnormal_scans[:70], normal_scans[:70]), axis=0)\n",
        "y_train = np.concatenate((abnormal_labels[:70], normal_labels[:70]), axis=0)\n",
        "x_val = np.concatenate((abnormal_scans[70:], normal_scans[70:]), axis=0)\n",
        "y_val = np.concatenate((abnormal_labels[70:], normal_labels[70:]), axis=0)\n",
        "print(f\"Number of samples in train and validation are {x_train.shape[0]} and {x_val.shape[0]}.\")"
      ],
      "metadata": {
        "id": "o2BX6hsPneOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "from scipy import ndimage\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def rotate(volume):\n",
        "    \"\"\"Rotate the volume by a few degrees\"\"\"\n",
        "\n",
        "    def scipy_rotate(volume):\n",
        "        # define some rotation angles\n",
        "        angles = [-20, -10, -5, 5, 10, 20]\n",
        "        # pick angles at random\n",
        "        angle = random.choice(angles)\n",
        "        # rotate volume\n",
        "        volume = ndimage.rotate(volume, angle, reshape=False)\n",
        "        volume[volume < 0] = 0\n",
        "        volume[volume > 1] = 1\n",
        "        return volume\n",
        "\n",
        "    augmented_volume = tf.numpy_function(scipy_rotate, [volume], tf.float32)\n",
        "    return augmented_volume\n",
        "\n",
        "\n",
        "def train_preprocessing(volume, label):\n",
        "    \"\"\"Process training data by rotating and adding a channel.\"\"\"\n",
        "    # Rotate volume\n",
        "    volume = rotate(volume)\n",
        "    volume = tf.expand_dims(volume, axis=3)\n",
        "    return volume, label\n",
        "\n",
        "\n",
        "def validation_preprocessing(volume, label):\n",
        "    \"\"\"Process validation data by only adding a channel.\"\"\"\n",
        "    volume = tf.expand_dims(volume, axis=3)\n",
        "    return volume, label"
      ],
      "metadata": {
        "id": "0kZv23hzo9J9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data loaders.\n",
        "train_loader = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "validation_loader = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "\n",
        "batch_size = 2\n",
        "# Augment the on the fly during training.\n",
        "train_dataset = (\n",
        "    train_loader.shuffle(len(x_train))\n",
        "    .map(train_preprocessing)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(2)\n",
        ")\n",
        "# Only rescale.\n",
        "validation_dataset = (\n",
        "    validation_loader.shuffle(len(x_val))\n",
        "    .map(validation_preprocessing)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(2)\n",
        ")"
      ],
      "metadata": {
        "id": "1Kdd5tr0o9HU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = train_dataset.take(1)\n",
        "images, labels = list(data)[0]\n",
        "images = images.numpy()\n",
        "image = images[0]\n",
        "print(\"Dimension of the CT scan is:\", image.shape)\n",
        "plt.imshow(np.squeeze(image[:, :, 30]), cmap=\"gray\")"
      ],
      "metadata": {
        "id": "ZWFekzzfo9EQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_slices(num_rows, num_columns, width, height, data):\n",
        "    \"\"\"Plot a montage of 20 CT slices\"\"\"\n",
        "    data = np.rot90(np.array(data))\n",
        "    data = np.transpose(data)\n",
        "    data = np.reshape(data, (num_rows, num_columns, width, height))\n",
        "    rows_data, columns_data = data.shape[0], data.shape[1]\n",
        "    heights = [slc[0].shape[0] for slc in data]\n",
        "    widths = [slc.shape[1] for slc in data[0]]\n",
        "    fig_width = 12.0\n",
        "    fig_height = fig_width * sum(heights) / sum(widths)\n",
        "    f, axarr = plt.subplots(\n",
        "        rows_data,\n",
        "        columns_data,\n",
        "        figsize=(fig_width, fig_height),\n",
        "        gridspec_kw={\"height_ratios\": heights},\n",
        "    )\n",
        "    for i in range(rows_data):\n",
        "        for j in range(columns_data):\n",
        "            axarr[i, j].imshow(data[i][j], cmap=\"gray\")\n",
        "            axarr[i, j].axis(\"off\")\n",
        "    plt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Visualize montage of slices.\n",
        "# 4 rows and 10 columns for 100 slices of the CT scan.\n",
        "plot_slices(4, 10, 128, 128, image[:, :, :40])"
      ],
      "metadata": {
        "id": "-Bu4p7CZpB97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(width=128, height=128, depth=64):\n",
        "    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n",
        "\n",
        "    inputs = keras.Input((width, height, depth, 1))\n",
        "\n",
        "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n",
        "    x = layers.MaxPool3D(pool_size=2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "    x = layers.MaxPool3D(pool_size=2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "    x = layers.MaxPool3D(pool_size=2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "    x = layers.MaxPool3D(pool_size=2)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling3D()(x)\n",
        "    x = layers.Dense(units=512, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    # Define the model.\n",
        "    model = keras.Model(inputs, outputs, name=\"3dcnn\")\n",
        "    return model\n",
        "\n",
        "\n",
        "# Build model.\n",
        "model = get_model(width=128, height=128, depth=64)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "iIYzwAkapEkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model.\n",
        "initial_learning_rate = 0.0001\n",
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
        ")\n",
        "model.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "    metrics=[\"acc\"],\n",
        ")\n",
        "\n",
        "# Define callbacks.\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
        "    \"3d_image_classification.h5\", save_best_only=True\n",
        ")\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_acc\", patience=15)\n",
        "\n",
        "# Train the model, doing validation at the end of each epoch\n",
        "epochs = 100\n",
        "model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=validation_dataset,\n",
        "    epochs=epochs,\n",
        "    shuffle=True,\n",
        "    verbose=2,\n",
        "    callbacks=[checkpoint_cb, early_stopping_cb],\n",
        ")"
      ],
      "metadata": {
        "id": "zs43zLVdpB7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PZrolvZsoUOJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}