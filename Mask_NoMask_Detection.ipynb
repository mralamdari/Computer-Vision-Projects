{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "UFC1PDWCWZox",
        "gwrpmeblX-1u"
      ],
      "mount_file_id": "1W-EQw-9wFkcIxPj5VYRQt74NoHDZju5g",
      "authorship_tag": "ABX9TyPZmtn5n8DJH8LBH2Gue4OZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/Computer-Vision-Projects/blob/main/Mask_NoMask_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "from roboflow import Roboflow\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "\n",
        "!pip install tensorflow==2.8\n",
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"
      ],
      "metadata": {
        "id": "Ogf9_gtrGdgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "t1DR9_jvZJAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = Roboflow(api_key=\"\")\n",
        "project = rf.workspace(\"joseph-nelson\").project(\"mask-wearing\")\n",
        "dataset = project.version(4).download(\"tensorflow\")\n",
        "os.rename('/content/Mask-Wearing-4', '/content/data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbSezrfrPavr",
        "outputId": "3af30f0c-8b76-433f-e8c2-83fb7f4036bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in Mask-Wearing-4 to tensorflow: 100% [19457480 / 19457480] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to Mask-Wearing-4 in tensorflow:: 100%|██████████| 154/154 [00:00<00:00, 793.86it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XML to CSV\n",
        "Convert annotation files(xml format) to a csv file.\n",
        "(for manually annotated imges)\n"
      ],
      "metadata": {
        "id": "UFC1PDWCWZox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def xml_to_csv(path):\n",
        "    xml_list = []\n",
        "    for xml_file in glob.glob(path + '/*.xml'):\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        for member in root.findall('object'):\n",
        "            value = (root.find('filename').text,\n",
        "                     int(root.find('size')[0].text),\n",
        "                     int(root.find('size')[1].text),\n",
        "                     member[0].text,\n",
        "                     int(member[4][0].text),\n",
        "                     int(member[4][1].text),\n",
        "                     int(member[4][2].text),\n",
        "                     int(member[4][3].text))\n",
        "            \n",
        "            xml_list.append(value)\n",
        "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "    return xml_df"
      ],
      "metadata": {
        "id": "Tq7LdCW0Gene"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_path = '/content/'\n",
        "\n",
        "xml_df = xml_to_csv(images_path)\n",
        "xml_df.to_csv('/content/annotations.csv', index=None)    "
      ],
      "metadata": {
        "id": "b3YIegnoLa2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Label Map\n",
        "\n",
        "Used in TensorFlow Object Detection API"
      ],
      "metadata": {
        "id": "gwrpmeblX-1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labelmap_file = '''item {\n",
        "    id: 1\n",
        "    name: 'mask'\n",
        "}\n",
        "item {\n",
        "    id: 2\n",
        "    name: 'no-mask'\n",
        "}'''\n",
        "\n",
        "with open('/content/data/labelmap.pbtxt', 'w+') as f:\n",
        "  f.write(labelmap_file)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "u2ZXsJFhRZ4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer Dataset to TFrecords"
      ],
      "metadata": {
        "id": "QDAyV56CZOeV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Object Detection API\n"
      ],
      "metadata": {
        "id": "ijYTTY63cVKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "# Clone the tensorflow models repository if it doesn't already exist\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWu_eZr7cdOs",
        "outputId": "96b2529a-7de3-41c4-ffdf-bd29474a4b49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 3634, done.\u001b[K\n",
            "remote: Counting objects: 100% (3634/3634), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3030/3030), done.\u001b[K\n",
            "remote: Total 3634 (delta 960), reused 1536 (delta 550), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3634/3634), 47.37 MiB | 18.46 MiB/s, done.\n",
            "Resolving deltas: 100% (960/960), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the Object Detection API\n",
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ],
      "metadata": {
        "id": "v17vFLlkcgdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import argparse\n",
        "import collections\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "\n",
        "from object_detection.utils import dataset_util\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "def split(df, group):\n",
        "\tdata = collections.namedtuple('data', ['filename', 'object'])\n",
        "\tgb = df.groupby(group)\n",
        "\treturn [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
        "\n",
        "\n",
        "def create_tf_example(group, path, category_idx):\n",
        "\twith tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
        "\t\tencoded_jpg = fid.read()\n",
        "\tencoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "\timage = Image.open(encoded_jpg_io)\n",
        "\twidth, height = image.size\n",
        "\n",
        "\tfilename = group.filename.encode('utf8')\n",
        "\timage_format = b'jpg'\n",
        "\txmins = []\n",
        "\txmaxs = []\n",
        "\tymins = []\n",
        "\tymaxs = []\n",
        "\tclasses_text = []\n",
        "\tclasses = []\n",
        "\n",
        "\tfor index, row in group.object.iterrows():\n",
        "\t\txmins.append(float(row['xmin']) / width)\n",
        "\t\txmaxs.append(float(row['xmax']) / width)\n",
        "\t\tymins.append(float(row['ymin']) / height)\n",
        "\t\tymaxs.append(float(row['ymax']) / height)\n",
        "\t\tclasses_text.append(row['class'].encode('utf8'))\n",
        "\t\tclasses.append(category_idx[row['class']])\n",
        "\n",
        "\ttf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "\t\t'image/height': dataset_util.int64_feature(height),\n",
        "\t\t'image/width': dataset_util.int64_feature(width),\n",
        "\t\t'image/filename': dataset_util.bytes_feature(filename),\n",
        "\t\t'image/source_id': dataset_util.bytes_feature(filename),\n",
        "\t\t'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "\t\t'image/format': dataset_util.bytes_feature(image_format),\n",
        "\t\t'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "\t\t'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "\t\t'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "\t\t'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "\t\t'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "\t\t'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "\t}))\n",
        "\treturn tf_example"
      ],
      "metadata": {
        "id": "srCb-afeRhuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for f_name in ['train', 'test', 'valid']:\n",
        "\n",
        "  img_path = f'/content/data/{f_name}'\n",
        "  csv_path = f'/content/data/{f_name}/_annotations.csv'\n",
        "  tfrecord_path = f'/content/data/{f_name}/{f_name}.tfrecord'\n",
        "  labelmap_path  = '/content/data/labelmap.pbtxt'\n",
        "\n",
        "  label_map_dict = label_map_util.get_label_map_dict(labelmap_path)\n",
        "  writer = tf.io.TFRecordWriter(tfrecord_path)\n",
        "\n",
        "  examples = pd.read_csv(csv_path)\n",
        "  grouped = split(examples, 'filename')\n",
        "  for group in grouped:\n",
        "    tf_example = create_tf_example(group, img_path, label_map_dict)\n",
        "    writer.write(tf_example.SerializeToString())\n",
        "\n",
        "  writer.close()\n",
        "  print(f'Successfully created the TFRecords: {tfrecord_path}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woE6k-l-bkIg",
        "outputId": "fdc07f60-e3c5-43b5-8b4d-924a506351d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created the TFRecords: /content/data/train/train.tfrecord\n",
            "Successfully created the TFRecords: /content/data/test/test.tfrecord\n",
            "Successfully created the TFRecords: /content/data/valid/valid.tfrecord\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "yqPJkSe2ttiG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install a model from the model garden\n",
        "Choose from a large selection of object detection models in the [TensorFlow 2 Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)."
      ],
      "metadata": {
        "id": "MrkQIt95_rtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL = \"faster_rcnn_resnet50_v1_640x640_coco17_tpu-8\"\n",
        "\n",
        "%cd /content/models/research/object_detection\n",
        "!mkdir pre-trained-models\n",
        "%cd pre-trained-models\n",
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/{MODEL}.tar.gz\n",
        "!tar -xf {MODEL}.tar.gz\n",
        "!rm {MODEL}.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skA7tAJA_rTc",
        "outputId": "0d1afba2-16c1-4e7d-9a8b-6e84552eefd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research/object_detection\n",
            "/content/models/research/object_detection/pre-trained-models\n",
            "--2022-12-29 19:00:41--  http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.195.128, 2607:f8b0:400e:c09::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.195.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 211996178 (202M) [application/x-tar]\n",
            "Saving to: ‘faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz’\n",
            "\n",
            "faster_rcnn_resnet5 100%[===================>] 202.17M   143MB/s    in 1.4s    \n",
            "\n",
            "2022-12-29 19:00:43 (143 MB/s) - ‘faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz’ saved [211996178/211996178]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Edit pipeline.config\n",
        "The pipeline.config file is in protocol buffer format, and we can use the config_util to change the settings we need."
      ],
      "metadata": {
        "id": "dmagfqHoAepA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from object_detection.utils import config_util\n",
        "\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder"
      ],
      "metadata": {
        "id": "MZyXXBfx4tRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_config = f\"./{MODEL}/pipeline.config\"\n",
        "model_dir = f\"./{MODEL}/checkpoint\"\n",
        "\n",
        "config = config_util.get_configs_from_pipeline_file(pipeline_config)\n",
        "\n",
        "model_config = config['model']\n",
        "model_config.faster_rcnn.num_classes = 2\n",
        "\n",
        "train_config = config['train_config']\n",
        "\n",
        "#Starting checkpoin location\n",
        "train_config.fine_tune_checkpoint = f\"/content/models/research/object_detection/pre-trained-models/{MODEL}/checkpoint/ckpt-0\"\n",
        "\n",
        "# GPU memory limits batch size\n",
        "train_config.batch_size = 32\n",
        "train_config.use_bfloat16 = False\n",
        "\n",
        "\n",
        "#...................$$$$$$$$$$$$$$$.................\n",
        "# some models use \"fine_tune\" rather than \"detection\" for fine-tuning\n",
        "train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "# detection      ===> use all the layers as pretrained layers\n",
        "# classification ===> use only the classification layer as pretrained and initialize the weights randomly\n",
        "\n",
        "\n",
        "# set auto-augmentation\n",
        "# del train_config.data_augmentation_options[:]\n",
        "\n",
        "# a1=train_config.data_augmentation_options.add()\n",
        "# a1.autoaugment_image.policy_name = \"v2\"\n",
        "\n",
        "# training dataset\n",
        "train_input_config = config['train_input_config']\n",
        "train_input_config.label_map_path = \"/content/data/labelmap.pbtxt\"\n",
        "train_input_config.tf_record_input_reader.input_path[:] = [\"/content/data/train/*.tfrecord\",\n",
        "                                                           \"/content/data/eval/*.tfrecord\"]  # have little data, so we use eval as train data\n",
        "# evaluation dataset                                                           \n",
        "eval_input_config = config['eval_input_config']\n",
        "eval_input_config.label_map_path = \"/content/data/labelmap.pbtxt\"\n",
        "eval_input_config.tf_record_input_reader.input_path[:] = [\"/content/data/test/*.tfrecord\"]\n",
        "\n",
        "# save pipeline.config file\n",
        "pipeline_proto = config_util.create_pipeline_proto_from_configs(config)\n",
        "config_util.save_pipeline_config(pipeline_config=pipeline_proto, directory=f'/content/models/research/object_detection/pre-trained-models/{MODEL}')"
      ],
      "metadata": {
        "id": "Zqgdhby1AlQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the contents of the pipeline.config file:\n"
      ],
      "metadata": {
        "id": "5s3RmNtPHFN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !cat /content/models/research/object_detection/pre-trained-models/{MODEL}/pipeline.config"
      ],
      "metadata": {
        "id": "4gJ21vV3G1N3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "ayADewGsHJMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/data/train_process/"
      ],
      "metadata": {
        "id": "_WIhifYaKaae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/models/research\n",
        "!python object_detection/model_main_tf2.py \\\n",
        "    --num_train_steps=1000 \\\n",
        "    --pipeline_config_path=/content/models/research/object_detection/pre-trained-models/{MODEL}/pipeline.config \\\n",
        "    --model_dir=/content/data/train_process/ \\\n",
        "    --alsologtostderr\n",
        "    #  &> /content/data/train.log"
      ],
      "metadata": {
        "id": "b2YeXp_wHFyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -n 10 /content/data/train.log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFcDU85FK5fn",
        "outputId": "426759ce-fbcb-4081-ac5a-cdbac883997f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      return multilevel_roi_align(images,\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/object_detection/utils/spatial_transform_ops.py\", line 358, in multilevel_roi_align\n",
            "      flattened_feature_values = _gather_valid_indices(flattened_features,\n",
            "    File \"/usr/local/lib/python3.8/dist-packages/object_detection/utils/spatial_transform_ops.py\", line 275, in _gather_valid_indices\n",
            "      return tf.gather(padded_tensor, indices + 1)\n",
            "Node: 'MultiLevelMatMulCropAndResize/MultiLevelRoIAlign/GatherV2_1'\n",
            "OOM when allocating tensor with shape[7526400,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
            "\t [[{{node MultiLevelMatMulCropAndResize/MultiLevelRoIAlign/GatherV2_1}}]]\n",
            "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
            " [Op:__inference__dummy_computation_fn_99545]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluaion"
      ],
      "metadata": {
        "id": "BnK8ITU1LRI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path=/content/models/research/object_detection/pre-trained-models/{MODEL}/pipeline.config \\\n",
        "    --model_dir=/content/data/train_process/ \\\n",
        "    --checkpoint_dir=/content/data/train_process/ \\\n",
        "    --eval_timeout=30 \\\n",
        "    --alsologtostderr\n",
        "\n",
        "#checkpoint_dir:  Only different to select it as Testing not training the"
      ],
      "metadata": {
        "id": "A8mgYoG9LFbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Copy the piplie.config for later use\n",
        "!cp /content/models/research/object_detection/pre-trained-models/{MODEL}/pipeline.config /content/training/."
      ],
      "metadata": {
        "id": "TDzR1SqcarbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Export trained model\n",
        "!python object_detection/exporter_main_v2.py \\\n",
        "    --input_type image_tensor \\\n",
        "    --pipeline_config_path=/kaggle/working/models/research/object_detection/pre-trained-models/{MODEL}/pipeline.config \\\n",
        "    --trained_checkpoint_dir /kaggle/working/training/ \\\n",
        "    --output_directory /kaggle/working/exported-models/effdet_d2"
      ],
      "metadata": {
        "id": "uuuwAW6uMEcg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}