{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "UFC1PDWCWZox",
        "gwrpmeblX-1u"
      ],
      "mount_file_id": "1W-EQw-9wFkcIxPj5VYRQt74NoHDZju5g",
      "authorship_tag": "ABX9TyOK6B8S2vieTI+semv7iJ4a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/Computer-Vision-Projects/blob/main/Mask_NoMask_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "from roboflow import Roboflow\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "\n",
        "!pip install tensorflow==2.8\n",
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"
      ],
      "metadata": {
        "id": "Ogf9_gtrGdgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "t1DR9_jvZJAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = Roboflow(api_key=\"\")\n",
        "project = rf.workspace(\"joseph-nelson\").project(\"mask-wearing\")\n",
        "dataset = project.version(4).download(\"tensorflow\")\n",
        "os.rename('/content/Mask-Wearing-4', '/content/data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbSezrfrPavr",
        "outputId": "d0dd8b37-c1c0-4c09-d615-b6b05629c2d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in Mask-Wearing-4 to tensorflow: 100% [19457480 / 19457480] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to Mask-Wearing-4 in tensorflow:: 100%|██████████| 154/154 [00:00<00:00, 726.41it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XML to CSV\n",
        "Convert annotation files(xml format) to a csv file.\n",
        "(for manually annotated imges)\n"
      ],
      "metadata": {
        "id": "UFC1PDWCWZox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def xml_to_csv(path):\n",
        "    xml_list = []\n",
        "    for xml_file in glob.glob(path + '/*.xml'):\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        for member in root.findall('object'):\n",
        "            value = (root.find('filename').text,\n",
        "                     int(root.find('size')[0].text),\n",
        "                     int(root.find('size')[1].text),\n",
        "                     member[0].text,\n",
        "                     int(member[4][0].text),\n",
        "                     int(member[4][1].text),\n",
        "                     int(member[4][2].text),\n",
        "                     int(member[4][3].text))\n",
        "            \n",
        "            xml_list.append(value)\n",
        "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "    return xml_df"
      ],
      "metadata": {
        "id": "Tq7LdCW0Gene"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_path = '/content/'\n",
        "\n",
        "xml_df = xml_to_csv(images_path)\n",
        "xml_df.to_csv('/content/annotations.csv', index=None)    "
      ],
      "metadata": {
        "id": "b3YIegnoLa2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Label Map\n",
        "\n",
        "Used in TensorFlow Object Detection API"
      ],
      "metadata": {
        "id": "gwrpmeblX-1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labelmap_file = '''item {\n",
        "    id: 1\n",
        "    name: 'mask'\n",
        "}\n",
        "item {\n",
        "    id: 2\n",
        "    name: 'no-mask'\n",
        "}'''\n",
        "\n",
        "with open('/content/data/labelmap.pbtxt', 'w+') as f:\n",
        "  f.write(labelmap_file)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "u2ZXsJFhRZ4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer Dataset to TFrecords"
      ],
      "metadata": {
        "id": "QDAyV56CZOeV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Object Detection API\n"
      ],
      "metadata": {
        "id": "ijYTTY63cVKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "# Clone the tensorflow models repository if it doesn't already exist\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWu_eZr7cdOs",
        "outputId": "05068fe9-3efd-4ab0-f72e-443788c17a0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 3634, done.\u001b[K\n",
            "remote: Counting objects: 100% (3634/3634), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3031/3031), done.\u001b[K\n",
            "remote: Total 3634 (delta 960), reused 1535 (delta 549), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3634/3634), 47.37 MiB | 28.41 MiB/s, done.\n",
            "Resolving deltas: 100% (960/960), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the Object Detection API\n",
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ],
      "metadata": {
        "id": "v17vFLlkcgdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import argparse\n",
        "import collections\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "\n",
        "from object_detection.utils import dataset_util\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "def split(df, group):\n",
        "\tdata = collections.namedtuple('data', ['filename', 'object'])\n",
        "\tgb = df.groupby(group)\n",
        "\treturn [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
        "\n",
        "\n",
        "def create_tf_example(group, path, category_idx):\n",
        "\twith tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
        "\t\tencoded_jpg = fid.read()\n",
        "\tencoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "\timage = Image.open(encoded_jpg_io)\n",
        "\twidth, height = image.size\n",
        "\n",
        "\tfilename = group.filename.encode('utf8')\n",
        "\timage_format = b'jpg'\n",
        "\txmins = []\n",
        "\txmaxs = []\n",
        "\tymins = []\n",
        "\tymaxs = []\n",
        "\tclasses_text = []\n",
        "\tclasses = []\n",
        "\n",
        "\tfor index, row in group.object.iterrows():\n",
        "\t\txmins.append(float(row['xmin']) / width)\n",
        "\t\txmaxs.append(float(row['xmax']) / width)\n",
        "\t\tymins.append(float(row['ymin']) / height)\n",
        "\t\tymaxs.append(float(row['ymax']) / height)\n",
        "\t\tclasses_text.append(row['class'].encode('utf8'))\n",
        "\t\tclasses.append(category_idx[row['class']])\n",
        "\n",
        "\ttf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "\t\t'image/height': dataset_util.int64_feature(height),\n",
        "\t\t'image/width': dataset_util.int64_feature(width),\n",
        "\t\t'image/filename': dataset_util.bytes_feature(filename),\n",
        "\t\t'image/source_id': dataset_util.bytes_feature(filename),\n",
        "\t\t'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "\t\t'image/format': dataset_util.bytes_feature(image_format),\n",
        "\t\t'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "\t\t'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "\t\t'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "\t\t'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "\t\t'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "\t\t'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "\t}))\n",
        "\treturn tf_example"
      ],
      "metadata": {
        "id": "srCb-afeRhuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for f_name in ['train', 'test', 'valid']:\n",
        "\n",
        "  img_path = f'/content/data/{f_name}'\n",
        "  csv_path = f'/content/data/{f_name}/_annotations.csv'\n",
        "  tfrecord_path = f'/content/data/{f_name}/{f_name}.tfrecord'\n",
        "  labelmap_path  = '/content/data/labelmap.pbtxt'\n",
        "\n",
        "  label_map_dict = label_map_util.get_label_map_dict(labelmap_path)\n",
        "  writer = tf.io.TFRecordWriter(tfrecord_path)\n",
        "\n",
        "  examples = pd.read_csv(csv_path)\n",
        "  grouped = split(examples, 'filename')\n",
        "  for group in grouped:\n",
        "    tf_example = create_tf_example(group, img_path, label_map_dict)\n",
        "    writer.write(tf_example.SerializeToString())\n",
        "\n",
        "  writer.close()\n",
        "  print(f'Successfully created the TFRecords: {tfrecord_path}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woE6k-l-bkIg",
        "outputId": "68534b5b-aaff-4e5a-b4ec-20f18005c3bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created the TFRecords: /content/data/train/train.tfrecord\n",
            "Successfully created the TFRecords: /content/data/test/test.tfrecord\n",
            "Successfully created the TFRecords: /content/data/valid/valid.tfrecord\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "yqPJkSe2ttiG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install a model from the model garden\n",
        "Choose from a large selection of object detection models in the [TensorFlow 2 Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)."
      ],
      "metadata": {
        "id": "MrkQIt95_rtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL = \"faster_rcnn_resnet50_v1_640x640_coco17_tpu-8\"\n",
        "\n",
        "%cd /content/models/research/object_detection\n",
        "!mkdir pre-trained-models\n",
        "%cd pre-trained-models\n",
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/{MODEL}.tar.gz\n",
        "!tar -xf {MODEL}.tar.gz\n",
        "!rm {MODEL}.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skA7tAJA_rTc",
        "outputId": "2bad6947-3746-4587-d9a7-e3fac626452c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research/object_detection\n",
            "/content/models/research/object_detection/pre-trained-models\n",
            "--2022-12-30 07:52:44--  http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 173.194.196.128, 2607:f8b0:4001:c1a::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|173.194.196.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 211996178 (202M) [application/x-tar]\n",
            "Saving to: ‘faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz’\n",
            "\n",
            "faster_rcnn_resnet5 100%[===================>] 202.17M   172MB/s    in 1.2s    \n",
            "\n",
            "2022-12-30 07:52:45 (172 MB/s) - ‘faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz’ saved [211996178/211996178]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Edit pipeline.config\n",
        "The pipeline.config file is in protocol buffer format, and we can use the config_util to change the settings we need."
      ],
      "metadata": {
        "id": "dmagfqHoAepA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from object_detection.utils import config_util\n",
        "\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder"
      ],
      "metadata": {
        "id": "MZyXXBfx4tRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_config = f\"./{MODEL}/pipeline.config\"\n",
        "model_dir = f\"./{MODEL}/checkpoint\"\n",
        "\n",
        "config = config_util.get_configs_from_pipeline_file(pipeline_config)\n",
        "\n",
        "model_config = config['model']\n",
        "model_config.faster_rcnn.num_classes = 2\n",
        "\n",
        "train_config = config['train_config']\n",
        "\n",
        "#Starting checkpoin location\n",
        "train_config.fine_tune_checkpoint = f\"/content/models/research/object_detection/pre-trained-models/{MODEL}/checkpoint/ckpt-0\"\n",
        "\n",
        "# GPU memory limits batch size\n",
        "train_config.batch_size = 32\n",
        "train_config.use_bfloat16 = False\n",
        "\n",
        "\n",
        "#...................$$$$$$$$$$$$$$$.................\n",
        "# some models use \"fine_tune\" rather than \"detection\" for fine-tuning\n",
        "train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "# detection      ===> use all the layers as pretrained layers\n",
        "# classification ===> use only the classification layer as pretrained and initialize the weights randomly\n",
        "\n",
        "\n",
        "# set auto-augmentation\n",
        "# del train_config.data_augmentation_options[:]\n",
        "\n",
        "# a1=train_config.data_augmentation_options.add()\n",
        "# a1.autoaugment_image.policy_name = \"v2\"\n",
        "\n",
        "# training dataset\n",
        "train_input_config = config['train_input_config']\n",
        "train_input_config.label_map_path = \"/content/data/labelmap.pbtxt\"\n",
        "train_input_config.tf_record_input_reader.input_path[:] = [\"/content/data/train/*.tfrecord\",\n",
        "                                                           \"/content/data/eval/*.tfrecord\"]  # have little data, so we use eval as train data\n",
        "# evaluation dataset                                                           \n",
        "eval_input_config = config['eval_input_config']\n",
        "eval_input_config.label_map_path = \"/content/data/labelmap.pbtxt\"\n",
        "eval_input_config.tf_record_input_reader.input_path[:] = [\"/content/data/test/*.tfrecord\"]\n",
        "\n",
        "# save pipeline.config file\n",
        "pipeline_proto = config_util.create_pipeline_proto_from_configs(config)\n",
        "config_util.save_pipeline_config(pipeline_config=pipeline_proto, directory=f'/content/models/research/object_detection/pre-trained-models/{MODEL}')"
      ],
      "metadata": {
        "id": "Zqgdhby1AlQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the contents of the pipeline.config file:\n"
      ],
      "metadata": {
        "id": "5s3RmNtPHFN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !cat /content/models/research/object_detection/pre-trained-models/{MODEL}/pipeline.config"
      ],
      "metadata": {
        "id": "4gJ21vV3G1N3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "ayADewGsHJMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/data/train_process/"
      ],
      "metadata": {
        "id": "_WIhifYaKaae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/models/research\n",
        "!python object_detection/model_main_tf2.py \\\n",
        "    --num_train_steps=1000 \\\n",
        "    --pipeline_config_path=/content/models/research/object_detection/pre-trained-models/{MODEL}/pipeline.config \\\n",
        "    --model_dir=/content/data/train_process/ \\\n",
        "    --alsologtostderr\n",
        "    #  &> /content/data/train.log"
      ],
      "metadata": {
        "id": "b2YeXp_wHFyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -n 10 /content/data/train.log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFcDU85FK5fn",
        "outputId": "8ca9a6f2-1612-4073-cba2-864da28ccfc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tail: cannot open '/content/data/train.log' for reading: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluaion"
      ],
      "metadata": {
        "id": "BnK8ITU1LRI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path=/content/models/research/object_detection/pre-trained-models/{MODEL}/pipeline.config \\\n",
        "    --model_dir=/content/data/train_process/ \\\n",
        "    --checkpoint_dir=/content/data/train_process/ \\\n",
        "    --eval_timeout=30 \\\n",
        "    --alsologtostderr\n",
        "\n",
        "#checkpoint_dir:  Only different to select it as Testing not training the"
      ],
      "metadata": {
        "id": "A8mgYoG9LFbS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b737506c-0c61-41bb-8c3b-990959ce75d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-30 07:55:38.241594: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2022-12-30 07:55:38.241790: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2022-12-30 07:55:38.241813: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W1230 07:55:42.792839 140484463544192 model_lib_v2.py:1089] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "I1230 07:55:42.793295 140484463544192 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I1230 07:55:42.793417 140484463544192 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I1230 07:55:42.793509 140484463544192 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W1230 07:55:42.793639 140484463544192 model_lib_v2.py:1106] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "2022-12-30 07:55:44.106385: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/data/test/*.tfrecord']\n",
            "I1230 07:55:44.167685 140484463544192 dataset_builder.py:162] Reading unweighted datasets: ['/content/data/test/*.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/data/test/*.tfrecord']\n",
            "I1230 07:55:44.168610 140484463544192 dataset_builder.py:79] Reading record datasets for input file: ['/content/data/test/*.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1230 07:55:44.168815 140484463544192 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W1230 07:55:44.168914 140484463544192 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W1230 07:55:44.173640 140484463544192 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W1230 07:55:44.199962 140484463544192 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "W1230 07:55:45.207754 140484463544192 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W1230 07:55:51.395070 140484463544192 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1230 07:55:53.345375 140484463544192 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Waiting for new checkpoint at /content/data/train_process/\n",
            "I1230 07:55:55.937891 140484463544192 checkpoint_utils.py:140] Waiting for new checkpoint at /content/data/train_process/\n",
            "INFO:tensorflow:Timed-out waiting for a checkpoint.\n",
            "I1230 07:56:24.974952 140484463544192 checkpoint_utils.py:203] Timed-out waiting for a checkpoint.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Copy the piplie.config for later use\n",
        "!cp /content/models/research/object_detection/pre-trained-models/{MODEL}/pipeline.config /content/training/."
      ],
      "metadata": {
        "id": "TDzR1SqcarbT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2d27ed5-448c-4f6f-9539-1d3697df6e5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot create regular file '/content/training/.': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Export trained model\n",
        "!python object_detection/exporter_main_v2.py \\\n",
        "    --input_type image_tensor \\\n",
        "    --pipeline_config_path=/kaggle/working/models/research/object_detection/pre-trained-models/{MODEL}/pipeline.config \\\n",
        "    --trained_checkpoint_dir /kaggle/working/training/ \\\n",
        "    --output_directory /kaggle/working/exported-models/effdet_d2"
      ],
      "metadata": {
        "id": "uuuwAW6uMEcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#dd"
      ],
      "metadata": {
        "id": "poqCrEurkAvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Step 5- Download TensorFlow Model Garden.\n",
        "\n",
        "#cd into the TensorFlow directory in your Google Drive\n",
        "%cd '/content/gdrive/My Drive/TensorFlow'\n",
        "\n",
        "#and clone the TensorFlow Model Garden repository\n",
        "!git clone https://github.com/tensorflow/models.git\n",
        "\n",
        "#using a older version of repo (21 Sept 2020)\n",
        "%cd '/content/gdrive/MyDrive/TensorFlow/models'\n",
        "!git checkout -f e04dafd04d69053d3733bb91d47d0d95bc2c8199\n",
        "     \n",
        "\n",
        "#Step 6- Install some required libraries and tools.\n",
        "\n",
        "!apt-get install protobuf-compiler python-lxml python-pil\n",
        "!pip install Cython pandas tf-slim lvis\n",
        "     \n",
        "\n",
        "#Step 7- Compile the Protobuf libraries.\n",
        "\n",
        "#cd into 'TensorFlow/models/research'\n",
        "%cd '/content/gdrive/My Drive/TensorFlow/models/research/'\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "     \n",
        "\n",
        "#Step 8- Set the environment.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "os.environ['PYTHONPATH']+=\":/content/gdrive/My Drive/TensorFlow/models\"\n",
        "sys.path.append(\"/content/gdrive/My Drive/TensorFlow/models/research\")\n",
        "     \n",
        "\n",
        "#Step 9- Build and Install setup.py.\n",
        "\n",
        "!python setup.py build\n",
        "!python setup.py install\n",
        "     \n",
        "\n",
        "#Step 10- Test the installation.\n",
        "\n",
        "#cd into 'TensorFlow/models/research/object_detection/builders/'\n",
        "%cd '/content/gdrive/My Drive/TensorFlow/models/research/object_detection/builders/'\n",
        "!python model_builder_tf2_test.py\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "print('Done')\n",
        "     \n",
        "NOTE:\n",
        "\n",
        "You should have the images in test and train folder (with their corresponding XML files) and label_map.pbtxt file ready in respective directories.\n",
        "\n",
        "You should also have the generate_tfrecord.py in your preprocessing directory.\n",
        "\n",
        "If you don't have these files ready, go back to Step 1 and finish downloading required files.\n",
        "\n",
        "\n",
        "#Step 11- Generate TFrecords.\n",
        "\n",
        "#cd into preprocessing directory\n",
        "%cd '/content/gdrive/My Drive/TensorFlow/scripts/preprocessing'\n",
        "\n",
        "#run the cell to generate test.record and train.record\n",
        "!python generate_tfrecord.py -x '/content/gdrive/My Drive/TensorFlow/workspace/training_demo/images/train' -l '/content/gdrive/My Drive/TensorFlow/workspace/training_demo/annotations/label_map.pbtxt' -o '/content/gdrive/My Drive/TensorFlow/workspace/training_demo/annotations/train.record'\n",
        "!python generate_tfrecord.py -x '/content/gdrive/My Drive/TensorFlow/workspace/training_demo/images/test' -l '/content/gdrive/My Drive/TensorFlow/workspace/training_demo/annotations/label_map.pbtxt' -o '/content/gdrive/My Drive/TensorFlow/workspace/training_demo/annotations/test.record'\n",
        "\n",
        "# !python generate_tfrecord.py -x '[path_to_train_folder]' -l '[path_to_annotations_folder]/label_map.pbtxt' -o '[path_to_annotations_folder]/train.record'\n",
        "# !python generate_tfrecord.py -x '[path_to_test_folder]' -l '[path_to_annotations_folder]/label_map.pbtxt' -o '[path_to_annotations_folder]/test.record'\n",
        "\n",
        "     \n",
        "NOTE:\n",
        "\n",
        "If you haven't downloaded any pre-trained model yet, go back to Step 1 and finish downloading any pre-trained model of your choice.\n",
        "\n",
        "We are almost ready to start our model training, just a few more steps before we start our model training!\n",
        "\n",
        "Step 12- Copying some files\n",
        "\n",
        "Copy the \"model_main_tf2.py\" file from \"TensorFlow\\models\\research\\object_detection\" and paste it into training_demo. We will need this file for training the model.\n",
        "\n",
        "Copy the \"exporter_main_v2.py\" file from \"TensorFlow\\models\\research\\object_detection\" and paste it into training_demo.\n",
        "\n",
        "We will need this file to export the trained model\n",
        "\n",
        "Step 13- Configure the pipeline file.\n",
        "\n",
        "Refer the mentioned Medium article for more details!\n",
        "\n",
        "\n",
        "#Step 14- Start Tensorboard.\n",
        "\n",
        "#cd into training_demo\n",
        "%cd '/content/gdrive/My Drive/TensorFlow/workspace/training_demo'\n",
        "\n",
        "#start the Tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=models/my_ssd_resnet50_v1_fpn\n",
        "\n",
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir=models/[name_of_pre-trained-model_you_downloaded]\n",
        "     \n",
        "\n",
        "#optional\n",
        "#code to check how much session time is remaining \n",
        "\n",
        "import time,psutil\n",
        "uptime=time.time()-psutil.boot_time()\n",
        "remaintime=(12*60*60)-uptime\n",
        "print(remaintime/(60*60))\n",
        "     \n",
        "\n",
        "#Step 15- Train the model.\n",
        "\n",
        "#run the cell to start model training \n",
        "!python model_main_tf2.py --model_dir=models/my_ssd_resnet50_v1_fpn --pipeline_config_path=models/my_ssd_resnet50_v1_fpn/pipeline.config\n",
        "\n",
        "# !python model_main_tf2.py --model_dir=models/[name_of_pre-trained-model_you_downloaded] --pipeline_config_path=models/[name_of_pre-trained-model_you_downloaded]/pipeline.config\n",
        "     \n",
        "Congratulations! You have finished model training!\n",
        "\n",
        "\n",
        "#Step 16- Export the Trained Model.\n",
        "\n",
        "#run the cell to start model training \n",
        "!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path ./models/my_ssd_resnet50_v1_fpn/pipeline.config --trained_checkpoint_dir ./models/my_ssd_resnet50_v1_fpn/ --output_directory ./exported-models/my_model\n",
        "\n",
        "# !python exporter_main_v2.py --input_type image_tensor --pipeline_config_path ./models/[name_of_pre-trained-model you downloaded]/pipeline.config --trained_checkpoint_dir ./models/[name_of_pre-trained-model_you_downloaded]/ --output_directory ./exported-models/my_model\n",
        "     \n",
        "We have finished training and exporting our model. It's time to test our model!\n",
        "\n",
        "\n",
        "#Step 17- Test the Model.\n",
        "\n",
        "#Loading the saved_model\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "PATH_TO_SAVED_MODEL=\"/content/gdrive/My Drive/TensorFlow/workspace/training_demo/exported-models/my_model/saved_model\"\n",
        "\n",
        "print('Loading model...', end='')\n",
        "\n",
        "# Load saved model and build the detection function\n",
        "detect_fn=tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
        "\n",
        "print('Done!')\n",
        "     \n",
        "\n",
        "#Step 18- Testing the Model.\n",
        "\n",
        "#Loading the label_map\n",
        "category_index=label_map_util.create_category_index_from_labelmap(\"/content/gdrive/My Drive/TensorFlow/workspace/training_demo/annotations/label_map.pbtxt\",use_display_name=True)\n",
        "\n",
        "#category_index=label_map_util.create_category_index_from_labelmap([path_to_label_map],use_display_name=True)\n",
        "     \n",
        "\n",
        "#Step 19- Testing the Model.\n",
        "\n",
        "#Loading the image\n",
        "img=['/content/img1.jpg','/content/img2.jpg']\n",
        "print(img)\n",
        "\n",
        "#list containing paths of all the images\n",
        "     \n",
        "\n",
        "#Step 20- Running the Inference.\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "    \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "    Puts image into numpy array to feed into tensorflow graph.\n",
        "    Note that by convention we put it into a numpy array with shape\n",
        "    (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "    Args:\n",
        "      path: the file path to the image\n",
        "\n",
        "    Returns:\n",
        "      uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    \"\"\"\n",
        "    return np.array(Image.open(path))\n",
        "\n",
        "for image_path in img:\n",
        "\n",
        "    print('Running inference for {}... '.format(image_path), end='')\n",
        "    image_np=load_image_into_numpy_array(image_path)\n",
        "\n",
        "    # Things to try:\n",
        "    # Flip horizontally\n",
        "    # image_np = np.fliplr(image_np).copy()\n",
        "    # Convert image to grayscale\n",
        "    # image_np = np.tile(\n",
        "    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
        "\n",
        "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "    input_tensor=tf.convert_to_tensor(image_np)\n",
        "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "    input_tensor=input_tensor[tf.newaxis, ...]\n",
        "\n",
        "    # input_tensor = np.expand_dims(image_np, 0)\n",
        "    detections=detect_fn(input_tensor)\n",
        "\n",
        "    # All outputs are batches tensors.\n",
        "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "    # We're only interested in the first num_detections.\n",
        "    num_detections=int(detections.pop('num_detections'))\n",
        "    detections={key:value[0,:num_detections].numpy()\n",
        "                   for key,value in detections.items()}\n",
        "    detections['num_detections']=num_detections\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    detections['detection_classes']=detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    image_np_with_detections=image_np.copy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "          image_np_with_detections,\n",
        "          detections['detection_boxes'],\n",
        "          detections['detection_classes'],\n",
        "          detections['detection_scores'],\n",
        "          category_index,\n",
        "          use_normalized_coordinates=True,\n",
        "          max_boxes_to_draw=1,     #max number of bounding boxes in the image\n",
        "          min_score_thresh=.3,      #min prediction threshold\n",
        "          agnostic_mode=False)\n",
        "    %matplotlib inline\n",
        "    plt.figure()\n",
        "    plt.imshow(image_np_with_detections)\n",
        "    print('Done')\n",
        "    plt.show()\n",
        "     "
      ],
      "metadata": {
        "id": "pyQrB9lzkBGj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}