{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/Computer-Vision-Projects/blob/main/Parking_spot_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsQYxqEyaaj7"
      },
      "source": [
        "#Image Classifier\n",
        "\n",
        "We buid a modelto predict the parking spots, if they are empty or not.\n",
        "\n",
        "[Data](https://drive.google.com/file/d/11DyZ165lZGzULEZSQNofyy9A8xaYgFJ2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-y3mBR5vuiw_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import pickle\n",
        "import shutil\n",
        "import sklearn\n",
        "import skimage\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "from sklearn import model_selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1o0hyJwgfP2z"
      },
      "outputs": [],
      "source": [
        "zip_folder = '/content/drive/MyDrive/DATA/car-parking-slot-empty-notempty.zip'\n",
        "shutil.copyfile(zip_folder, '/content/data.zip')\n",
        "!unzip \\*.zip && rm *.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yn5QkPWzuxAz",
        "outputId": "d9e6edd9-c7ba-4709-f138-f9dde2ff655e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((6090, 675), (6090,))"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = []\n",
        "labels = []\n",
        "for id, cat in enumerate(['empty', 'not_empty']):\n",
        "  path = f'./clf-data/{cat}/'\n",
        "  for img in os.listdir(path):\n",
        "    img = skimage.io.imread(path+img)\n",
        "    img = skimage.transform.resize(img, (15, 15))\n",
        "    data.append(img.flatten())\n",
        "    labels.append(id)\n",
        "\n",
        "data = np.asarray(data)\n",
        "labels = np.asarray(labels)\n",
        "\n",
        "data.shape,labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z23BY9DIIycu"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(data, labels, test_size=0.2, random_state=32)\n",
        "x_train.shape, x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWwdSCD2JywS"
      },
      "outputs": [],
      "source": [
        "clf = svm.SVC()\n",
        "\n",
        "parameters = [{'gamma': [0.01, 0.001, 0.0001], 'C': [1, 10, 100, 1000]}]\n",
        "\n",
        "grid_search = model_selection.GridSearchCV(clf, parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CL49JZHuKpNL",
        "outputId": "e557ad36-f313-415a-80fd-9a3273df848e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100.0% of samples were correctly classified\n"
          ]
        }
      ],
      "source": [
        "# grid_search.fit(x_train, y_train)\n",
        "\n",
        "# # test performance\n",
        "# best_estimator = grid_search.best_estimator_\n",
        "\n",
        "# y_prediction = best_estimator.predict(x_test)\n",
        "\n",
        "# score = metrics.accuracy_score(y_prediction, y_test)\n",
        "\n",
        "# print('{}% of samples were correctly classified'.format(str(score * 100)))\n",
        "\n",
        "# pickle.dump(best_estimator, open('./model.p', 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNa1JXN2eOiD"
      },
      "source": [
        "#Parking Spot Detector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ql613_LCeRyH"
      },
      "outputs": [],
      "source": [
        "MODEL = pickle.load(open(\"./drive/MyDrive/DATA/model.p\", \"rb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1n1spMQeaZo"
      },
      "outputs": [],
      "source": [
        "def empty_or_not(spot_bgr):\n",
        "\n",
        "    img_resized = skimage.transform.resize(spot_bgr, (15, 15, 3))\n",
        "    pred = MODEL.predict(np.array([img_resized.flatten()]))\n",
        "    return True if pred == 0 else False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJnT64bUeY88"
      },
      "outputs": [],
      "source": [
        "def get_parking_spots_bboxes(connected_components, coef=1):\n",
        "    (totalLabels, label_ids, values, centroid) = connected_components\n",
        "\n",
        "    slots = []\n",
        "    for i in range(1, totalLabels):\n",
        "\n",
        "        # Now extract the coordinate points\n",
        "        x1 = int(values[i, cv2.CC_STAT_LEFT] * coef)\n",
        "        y1 = int(values[i, cv2.CC_STAT_TOP] * coef)\n",
        "        w = int(values[i, cv2.CC_STAT_WIDTH] * coef)\n",
        "        h = int(values[i, cv2.CC_STAT_HEIGHT] * coef)\n",
        "\n",
        "        slots.append([x1, y1, w, h])\n",
        "\n",
        "    return slots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WK2bG3kHedLJ"
      },
      "outputs": [],
      "source": [
        "calc_diff = lambda im1, im2: np.abs(np.mean(im1) - np.mean(im2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7V19EZ6bxxD"
      },
      "outputs": [],
      "source": [
        "mask = './mask_1920_1080.png'\n",
        "video_path = './samples/parking_1920_1080_loop.mp4'\n",
        "\n",
        "\n",
        "mask = cv2.imread(mask, 0)\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "connected_components = cv2.connectedComponentsWithStats(mask, 4, cv2.CV_32S)\n",
        "\n",
        "spots = get_parking_spots_bboxes(connected_components)\n",
        "\n",
        "spots_status = [None for j in spots]\n",
        "diffs = [None for j in spots]\n",
        "\n",
        "previous_frame = None\n",
        "\n",
        "frame_nmr = 0\n",
        "ret = True\n",
        "step = 30\n",
        "while ret:\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if frame_nmr % step == 0 and previous_frame is not None:\n",
        "        for spot_indx, spot in enumerate(spots):\n",
        "            x1, y1, w, h = spot\n",
        "\n",
        "            spot_crop = frame[y1:y1 + h, x1:x1 + w, :]\n",
        "\n",
        "            diffs[spot_indx] = calc_diff(spot_crop, previous_frame[y1:y1 + h, x1:x1 + w, :])\n",
        "\n",
        "        print([diffs[j] for j in np.argsort(diffs)][::-1])\n",
        "\n",
        "    if frame_nmr % step == 0:\n",
        "        if previous_frame is None:\n",
        "            arr_ = range(len(spots))\n",
        "        else:\n",
        "            arr_ = [j for j in np.argsort(diffs) if diffs[j] / np.amax(diffs) > 0.4]\n",
        "        for spot_indx in arr_:\n",
        "            spot = spots[spot_indx]\n",
        "            x1, y1, w, h = spot\n",
        "\n",
        "            spot_crop = frame[y1:y1 + h, x1:x1 + w, :]\n",
        "\n",
        "            spot_status = empty_or_not(spot_crop)\n",
        "\n",
        "            spots_status[spot_indx] = spot_status\n",
        "\n",
        "    if frame_nmr % step == 0:\n",
        "        previous_frame = frame.copy()\n",
        "\n",
        "    for spot_indx, spot in enumerate(spots):\n",
        "        spot_status = spots_status[spot_indx]\n",
        "        x1, y1, w, h = spots[spot_indx]\n",
        "\n",
        "        if spot_status:\n",
        "            frame = cv2.rectangle(frame, (x1, y1), (x1 + w, y1 + h), (0, 255, 0), 2)\n",
        "        else:\n",
        "            frame = cv2.rectangle(frame, (x1, y1), (x1 + w, y1 + h), (0, 0, 255), 2)\n",
        "\n",
        "    cv2.rectangle(frame, (80, 20), (550, 80), (0, 0, 0), -1)\n",
        "    cv2.putText(frame, 'Available spots: {} / {}'.format(str(sum(spots_status)), str(len(spots_status))), (100, 60),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "\n",
        "    cv2.namedWindow('frame', cv2.WINDOW_NORMAL)\n",
        "    cv2.imshow('frame', frame)\n",
        "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "    frame_nmr += 1\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cuS8uFAtd_U"
      },
      "source": [
        "#New\n",
        "[pklotsdbs](https://www.kaggle.com/datasets/ipythonx/pklotdbs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QHJabRqJupxe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        "\n",
        "img_width, img_height = 224, 224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDrjvopEteZy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78e95993-0f52-4171-adf8-3efb5f1ac3a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading pklotdbs.zip to /content\n",
            "  1% 58.0M/4.98G [00:03<03:16, 26.8MB/s]"
          ]
        }
      ],
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive'\n",
        "!kaggle datasets download -d ipythonx/pklotdbs\n",
        "!unzip \\*.zip && rm *.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Classification"
      ],
      "metadata": {
        "id": "GXy-F-NjbKMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cls_data = './PKLotSegmented'\n",
        "data_path = './data/'\n",
        "os.makedirs(data_path, exist_ok=True)\n",
        "os.makedirs(data_path+'Empty', exist_ok=True)\n",
        "os.makedirs(data_path+'Occupied', exist_ok=True)\n",
        "\n",
        "path_dict = {'Empty': [],\n",
        "             'Occupied': []}\n",
        "\n",
        "data = []"
      ],
      "metadata": {
        "id": "qj0lO8Zkh-cT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for cat in os.listdir(cls_data):\n",
        "  for crs in os.listdir(cls_data+'/'+cat):\n",
        "    for day in os.listdir(cls_data+'/'+cat+'/'+crs):\n",
        "      for E_O in os.listdir(cls_data+'/'+cat+'/'+crs+'/'+day):\n",
        "        for img in os.listdir(cls_data+'/'+cat+'/'+crs+'/'+day+'/'+E_O):\n",
        "          path = os.path.join(cls_data, cat, crs, day, E_O, img)\n",
        "          target = os.path.join(data, E_O, img)\n",
        "          img = cv2.imread(target)\n",
        "          img = cv2.resize(img, (224, 224))\n",
        "          label = 0 if E_O == 'Empty' else 1\n",
        "          data.append([img, label])\n",
        "          os.replace(path, target)\n",
        "          path_dict[E_O].append(target)"
      ],
      "metadata": {
        "id": "8cb7RSFnYIZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_selection"
      ],
      "metadata": {
        "id": "ax5Y10MpjUgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = (180, 180)\n",
        "batch_size = 128\n",
        "\n",
        "train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    \"PetImages\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"both\",\n",
        "    seed=1337,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# train_datagen = ImageDataGenerator(\n",
        "#     rescale=1. / 255,\n",
        "#     shear_range=0.2,\n",
        "#     zoom_range=0.2,\n",
        "#     horizontal_flip=True)\n",
        "\n",
        "# test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "# train_generator = train_datagen.flow_from_directory(\n",
        "#     train_data_dir,\n",
        "#     target_size=(img_width, img_height),\n",
        "#     batch_size=batch_size,\n",
        "#     class_mode='binary')\n",
        "\n",
        "# validation_generator = test_datagen.flow_from_directory(\n",
        "#     validation_data_dir,\n",
        "#     target_size=(img_width, img_height),\n",
        "#     batch_size=batch_size,\n",
        "#     class_mode='binary')\n",
        "\n",
        "# model.fit_generator(\n",
        "#     train_generator,\n",
        "#     steps_per_epoch=nb_train_samples // batch_size,\n",
        "#     epochs=epochs,\n",
        "#     validation_data=validation_generator,\n",
        "#     validation_steps=nb_validation_samples // batch_size)"
      ],
      "metadata": {
        "id": "XxTxe88J958k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "\n",
        "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "data_dir = tf.keras.utils.get_file('flower_photos.tar', origin=dataset_url, extract=True)\n",
        "data_dir = pathlib.Path(data_dir).with_suffix('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Um4FBOVdPoHa",
        "outputId": "77d65cb2-cd24-4e86-b5dc-dc09b4e11ab2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
            "228813984/228813984 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir\n",
        "# import glob\n",
        "# image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "# print(image_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYFuvfLCQGaO",
        "outputId": "36e25e1d-efff-4b39-9fb8-8d6939591e3d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/root/.keras/datasets/flower_photos')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.replace('/root/.keras/datasets/flower_photos', './')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "0Qyd-stEQcMW",
        "outputId": "7e293f34-8972-46bf-9ccc-e4d6c7e6fadb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-fc0a6e1806ce>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/root/.keras/datasets/flower_photos'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m: [Errno 16] Device or resource busy: '/root/.keras/datasets/flower_photos' -> './'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9qCO3z_MSU-p"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "TsQYxqEyaaj7",
        "sNa1JXN2eOiD"
      ],
      "provenance": [],
      "mount_file_id": "1KVRbBvKz6JbCOIpxUHPj6mLS7G9fcJ0j",
      "authorship_tag": "ABX9TyPvcb/kMggT8j9hc/V93LW5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}