{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/Computer-Vision-Projects/blob/main/Parking_spot_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsQYxqEyaaj7"
      },
      "source": [
        "#Image Classifier\n",
        "\n",
        "We buid a modelto predict the parking spots, if they are empty or not.\n",
        "\n",
        "[Data](https://drive.google.com/file/d/11DyZ165lZGzULEZSQNofyy9A8xaYgFJ2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-y3mBR5vuiw_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import pickle\n",
        "import shutil\n",
        "import sklearn\n",
        "import skimage\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "from sklearn import model_selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1o0hyJwgfP2z"
      },
      "outputs": [],
      "source": [
        "zip_folder = '/content/drive/MyDrive/DATA/car-parking-slot-empty-notempty.zip'\n",
        "shutil.copyfile(zip_folder, '/content/data.zip')\n",
        "!unzip \\*.zip && rm *.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yn5QkPWzuxAz",
        "outputId": "d9e6edd9-c7ba-4709-f138-f9dde2ff655e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((6090, 675), (6090,))"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = []\n",
        "labels = []\n",
        "for id, cat in enumerate(['empty', 'not_empty']):\n",
        "  path = f'./clf-data/{cat}/'\n",
        "  for img in os.listdir(path):\n",
        "    img = skimage.io.imread(path+img)\n",
        "    img = skimage.transform.resize(img, (15, 15))\n",
        "    data.append(img.flatten())\n",
        "    labels.append(id)\n",
        "\n",
        "data = np.asarray(data)\n",
        "labels = np.asarray(labels)\n",
        "\n",
        "data.shape,labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z23BY9DIIycu"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(data, labels, test_size=0.2, random_state=32)\n",
        "x_train.shape, x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWwdSCD2JywS"
      },
      "outputs": [],
      "source": [
        "clf = svm.SVC()\n",
        "\n",
        "parameters = [{'gamma': [0.01, 0.001, 0.0001], 'C': [1, 10, 100, 1000]}]\n",
        "\n",
        "grid_search = model_selection.GridSearchCV(clf, parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CL49JZHuKpNL",
        "outputId": "e557ad36-f313-415a-80fd-9a3273df848e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100.0% of samples were correctly classified\n"
          ]
        }
      ],
      "source": [
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# test performance\n",
        "best_estimator = grid_search.best_estimator_\n",
        "y_prediction = best_estimator.predict(x_test)\n",
        "score = metrics.accuracy_score(y_prediction, y_test)\n",
        "print('{}% of samples were correctly classified'.format(str(score * 100)))\n",
        "pickle.dump(best_estimator, open('./model.p', 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNa1JXN2eOiD"
      },
      "source": [
        "#Parking Spot Detector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ql613_LCeRyH"
      },
      "outputs": [],
      "source": [
        "MODEL = pickle.load(open(\"./drive/MyDrive/DATA/model.p\", \"rb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1n1spMQeaZo"
      },
      "outputs": [],
      "source": [
        "def empty_or_not(spot_bgr):\n",
        "\n",
        "    img_resized = skimage.transform.resize(spot_bgr, (15, 15, 3))\n",
        "    pred = MODEL.predict(np.array([img_resized.flatten()]))\n",
        "    return True if pred == 0 else False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJnT64bUeY88"
      },
      "outputs": [],
      "source": [
        "def get_parking_spots_bboxes(connected_components, coef=1):\n",
        "    (totalLabels, label_ids, values, centroid) = connected_components\n",
        "\n",
        "    slots = []\n",
        "    for i in range(1, totalLabels):\n",
        "\n",
        "        # Now extract the coordinate points\n",
        "        x1 = int(values[i, cv2.CC_STAT_LEFT] * coef)\n",
        "        y1 = int(values[i, cv2.CC_STAT_TOP] * coef)\n",
        "        w = int(values[i, cv2.CC_STAT_WIDTH] * coef)\n",
        "        h = int(values[i, cv2.CC_STAT_HEIGHT] * coef)\n",
        "\n",
        "        slots.append([x1, y1, w, h])\n",
        "\n",
        "    return slots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WK2bG3kHedLJ"
      },
      "outputs": [],
      "source": [
        "calc_diff = lambda im1, im2: np.abs(np.mean(im1) - np.mean(im2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7V19EZ6bxxD"
      },
      "outputs": [],
      "source": [
        "mask = './mask_1920_1080.png'\n",
        "video_path = './samples/parking_1920_1080_loop.mp4'\n",
        "\n",
        "\n",
        "mask = cv2.imread(mask, 0)\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "connected_components = cv2.connectedComponentsWithStats(mask, 4, cv2.CV_32S)\n",
        "\n",
        "spots = get_parking_spots_bboxes(connected_components)\n",
        "\n",
        "spots_status = [None for j in spots]\n",
        "diffs = [None for j in spots]\n",
        "\n",
        "previous_frame = None\n",
        "\n",
        "frame_nmr = 0\n",
        "ret = True\n",
        "step = 30\n",
        "while ret:\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if frame_nmr % step == 0 and previous_frame is not None:\n",
        "        for spot_indx, spot in enumerate(spots):\n",
        "            x1, y1, w, h = spot\n",
        "\n",
        "            spot_crop = frame[y1:y1 + h, x1:x1 + w, :]\n",
        "\n",
        "            diffs[spot_indx] = calc_diff(spot_crop, previous_frame[y1:y1 + h, x1:x1 + w, :])\n",
        "\n",
        "        print([diffs[j] for j in np.argsort(diffs)][::-1])\n",
        "\n",
        "    if frame_nmr % step == 0:\n",
        "        if previous_frame is None:\n",
        "            arr_ = range(len(spots))\n",
        "        else:\n",
        "            arr_ = [j for j in np.argsort(diffs) if diffs[j] / np.amax(diffs) > 0.4]\n",
        "        for spot_indx in arr_:\n",
        "            spot = spots[spot_indx]\n",
        "            x1, y1, w, h = spot\n",
        "\n",
        "            spot_crop = frame[y1:y1 + h, x1:x1 + w, :]\n",
        "\n",
        "            spot_status = empty_or_not(spot_crop)\n",
        "\n",
        "            spots_status[spot_indx] = spot_status\n",
        "\n",
        "    if frame_nmr % step == 0:\n",
        "        previous_frame = frame.copy()\n",
        "\n",
        "    for spot_indx, spot in enumerate(spots):\n",
        "        spot_status = spots_status[spot_indx]\n",
        "        x1, y1, w, h = spots[spot_indx]\n",
        "\n",
        "        if spot_status:\n",
        "            frame = cv2.rectangle(frame, (x1, y1), (x1 + w, y1 + h), (0, 255, 0), 2)\n",
        "        else:\n",
        "            frame = cv2.rectangle(frame, (x1, y1), (x1 + w, y1 + h), (0, 0, 255), 2)\n",
        "\n",
        "    cv2.rectangle(frame, (80, 20), (550, 80), (0, 0, 0), -1)\n",
        "    cv2.putText(frame, 'Available spots: {} / {}'.format(str(sum(spots_status)), str(len(spots_status))), (100, 60),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "\n",
        "    cv2.namedWindow('frame', cv2.WINDOW_NORMAL)\n",
        "    cv2.imshow('frame', frame)\n",
        "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "    frame_nmr += 1\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cuS8uFAtd_U"
      },
      "source": [
        "#New\n",
        "[pklotsdbs](https://www.kaggle.com/datasets/blanderbuss/parking-lot-dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHJabRqJupxe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDrjvopEteZy"
      },
      "outputs": [],
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive'\n",
        "!kaggle datasets download -d blanderbuss/parking-lot-dataset\n",
        "!unzip \\*.zip && rm *.zip\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXy-F-NjbKMb"
      },
      "source": [
        "#Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cb7RSFnYIZL"
      },
      "outputs": [],
      "source": [
        "cls_data = './PKLot/PKLotSegmented'\n",
        "data = './data/'\n",
        "os.makedirs(data, exist_ok=True)\n",
        "VAL_THRESHOLD = 0.2\n",
        "data_arr = []\n",
        "\n",
        "for cat in os.listdir(cls_data):\n",
        "  for crs in os.listdir(cls_data+'/'+cat):\n",
        "    for day in os.listdir(cls_data+'/'+cat+'/'+crs):\n",
        "      for E_O in os.listdir(cls_data+'/'+cat+'/'+crs+'/'+day):\n",
        "        for img in os.listdir(cls_data+'/'+cat+'/'+crs+'/'+day+'/'+E_O):\n",
        "          path = os.path.join(cls_data, cat, crs, day, E_O, img)\n",
        "          folder_name = 'train' if np.random.randn()<VAL_THRESHOLD else 'validation'\n",
        "          target = os.path.join(data, folder_name, img)\n",
        "          label = 0 if E_O == 'Empty' else 1\n",
        "          data_arr.append([target, label])\n",
        "          os.replace(path, target)\n",
        "\n",
        "data = pd.DataFrame(data_arr, columns=['path', 'label'])\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x_train, x_test, y_train, y_test = model_selection.train_test_split(data.path.values, data.label.values, test_size=0.2, random_state=32)\n",
        "# x_train.shape, x_test.shape\n",
        "\n",
        "train_path = './data/train'\n",
        "val_path   = './data/validation'\n",
        "\n",
        "os.makedirs(train_path, exist_ok=True)\n",
        "os.makedirs(val_path, exist_ok=True)\n",
        "\n",
        "for i in x_train:\n",
        "  try:\n",
        "    os.replace(i, train_path+i[6:])\n",
        "  except FileNotFoundError:\n",
        "    pass\n",
        "for i in x_test:\n",
        "  try:\n",
        "    os.replace(i, val_path+i[6:])\n",
        "  except FileNotFoundError:\n",
        "    pass"
      ],
      "metadata": {
        "id": "HcdpD34hP3oL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuwluNC08Eu8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a95888f-2ea3-4f1b-9473-9b5c1b6fc5cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256, 256)\n"
          ]
        }
      ],
      "source": [
        "for i in os.listdir('./data'):\n",
        "  # img = cv2.imread()\n",
        "  path = f'./data/{i}'\n",
        "  # img = tf.keras.preprocessing.image.load_img(path)\n",
        "  img = tf.keras.utils.load_img(\n",
        "    path,\n",
        "    grayscale=False,\n",
        "    color_mode='rgb',\n",
        "    target_size=(256, 256),\n",
        "    interpolation='nearest',\n",
        "    keep_aspect_ratio=False\n",
        ")\n",
        "  print(img.size)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPQ2vpFy8Ixa"
      },
      "outputs": [],
      "source": [
        "ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "\t'/content/Empty/',\n",
        "\tlabels=\"inferred\",\n",
        "\tlabel_mode=\"int\",\n",
        "\tclass_names=None,\n",
        "\tcolor_mode=\"rgb\",\n",
        "\tbatch_size=32,\n",
        "\timage_size=(256, 256),\n",
        "\tshuffle=True,\n",
        "\tseed=32,\n",
        "\tvalidation_split=None,\n",
        "\tsubset=None,\n",
        "\tinterpolation=\"bilinear\",\n",
        "\tfollow_links=False,\n",
        "\tcrop_to_aspect_ratio=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4ZpOJ7eqitD",
        "outputId": "3360c8b3-0705-4ce9-969c-3af1ed6dcf97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_a7P3wUgrPIh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "TsQYxqEyaaj7",
        "sNa1JXN2eOiD"
      ],
      "provenance": [],
      "mount_file_id": "1KVRbBvKz6JbCOIpxUHPj6mLS7G9fcJ0j",
      "authorship_tag": "ABX9TyN7hRSPCx+p+dIXp5x8jyKi",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}