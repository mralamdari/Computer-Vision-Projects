{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/Computer-Vision-Projects/blob/main/Parking_spot_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsQYxqEyaaj7"
      },
      "source": [
        "#Image Classifier\n",
        "\n",
        "We buid a modelto predict the parking spots, if they are empty or not.\n",
        "\n",
        "[Data](https://drive.google.com/file/d/11DyZ165lZGzULEZSQNofyy9A8xaYgFJ2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-y3mBR5vuiw_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import pickle\n",
        "import shutil\n",
        "import sklearn\n",
        "import skimage\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "from sklearn import model_selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1o0hyJwgfP2z"
      },
      "outputs": [],
      "source": [
        "zip_folder = '/content/drive/MyDrive/DATA/car-parking-slot-empty-notempty.zip'\n",
        "shutil.copyfile(zip_folder, '/content/data.zip')\n",
        "!unzip \\*.zip && rm *.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yn5QkPWzuxAz",
        "outputId": "d9e6edd9-c7ba-4709-f138-f9dde2ff655e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((6090, 675), (6090,))"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = []\n",
        "labels = []\n",
        "for id, cat in enumerate(['empty', 'not_empty']):\n",
        "  path = f'./clf-data/{cat}/'\n",
        "  for img in os.listdir(path):\n",
        "    img = skimage.io.imread(path+img)\n",
        "    img = skimage.transform.resize(img, (15, 15))\n",
        "    data.append(img.flatten())\n",
        "    labels.append(id)\n",
        "\n",
        "data = np.asarray(data)\n",
        "labels = np.asarray(labels)\n",
        "\n",
        "data.shape,labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z23BY9DIIycu"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(data, labels, test_size=0.2, random_state=32)\n",
        "x_train.shape, x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWwdSCD2JywS"
      },
      "outputs": [],
      "source": [
        "clf = svm.SVC()\n",
        "\n",
        "parameters = [{'gamma': [0.01, 0.001, 0.0001], 'C': [1, 10, 100, 1000]}]\n",
        "\n",
        "grid_search = model_selection.GridSearchCV(clf, parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CL49JZHuKpNL",
        "outputId": "e557ad36-f313-415a-80fd-9a3273df848e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100.0% of samples were correctly classified\n"
          ]
        }
      ],
      "source": [
        "# grid_search.fit(x_train, y_train)\n",
        "\n",
        "# # test performance\n",
        "# best_estimator = grid_search.best_estimator_\n",
        "\n",
        "# y_prediction = best_estimator.predict(x_test)\n",
        "\n",
        "# score = metrics.accuracy_score(y_prediction, y_test)\n",
        "\n",
        "# print('{}% of samples were correctly classified'.format(str(score * 100)))\n",
        "\n",
        "# pickle.dump(best_estimator, open('./model.p', 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNa1JXN2eOiD"
      },
      "source": [
        "#Parking Spot Detector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ql613_LCeRyH"
      },
      "outputs": [],
      "source": [
        "MODEL = pickle.load(open(\"./drive/MyDrive/DATA/model.p\", \"rb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1n1spMQeaZo"
      },
      "outputs": [],
      "source": [
        "def empty_or_not(spot_bgr):\n",
        "\n",
        "    img_resized = skimage.transform.resize(spot_bgr, (15, 15, 3))\n",
        "    pred = MODEL.predict(np.array([img_resized.flatten()]))\n",
        "    return True if pred == 0 else False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJnT64bUeY88"
      },
      "outputs": [],
      "source": [
        "def get_parking_spots_bboxes(connected_components, coef=1):\n",
        "    (totalLabels, label_ids, values, centroid) = connected_components\n",
        "\n",
        "    slots = []\n",
        "    for i in range(1, totalLabels):\n",
        "\n",
        "        # Now extract the coordinate points\n",
        "        x1 = int(values[i, cv2.CC_STAT_LEFT] * coef)\n",
        "        y1 = int(values[i, cv2.CC_STAT_TOP] * coef)\n",
        "        w = int(values[i, cv2.CC_STAT_WIDTH] * coef)\n",
        "        h = int(values[i, cv2.CC_STAT_HEIGHT] * coef)\n",
        "\n",
        "        slots.append([x1, y1, w, h])\n",
        "\n",
        "    return slots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WK2bG3kHedLJ"
      },
      "outputs": [],
      "source": [
        "calc_diff = lambda im1, im2: np.abs(np.mean(im1) - np.mean(im2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7V19EZ6bxxD"
      },
      "outputs": [],
      "source": [
        "mask = './mask_1920_1080.png'\n",
        "video_path = './samples/parking_1920_1080_loop.mp4'\n",
        "\n",
        "\n",
        "mask = cv2.imread(mask, 0)\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "connected_components = cv2.connectedComponentsWithStats(mask, 4, cv2.CV_32S)\n",
        "\n",
        "spots = get_parking_spots_bboxes(connected_components)\n",
        "\n",
        "spots_status = [None for j in spots]\n",
        "diffs = [None for j in spots]\n",
        "\n",
        "previous_frame = None\n",
        "\n",
        "frame_nmr = 0\n",
        "ret = True\n",
        "step = 30\n",
        "while ret:\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if frame_nmr % step == 0 and previous_frame is not None:\n",
        "        for spot_indx, spot in enumerate(spots):\n",
        "            x1, y1, w, h = spot\n",
        "\n",
        "            spot_crop = frame[y1:y1 + h, x1:x1 + w, :]\n",
        "\n",
        "            diffs[spot_indx] = calc_diff(spot_crop, previous_frame[y1:y1 + h, x1:x1 + w, :])\n",
        "\n",
        "        print([diffs[j] for j in np.argsort(diffs)][::-1])\n",
        "\n",
        "    if frame_nmr % step == 0:\n",
        "        if previous_frame is None:\n",
        "            arr_ = range(len(spots))\n",
        "        else:\n",
        "            arr_ = [j for j in np.argsort(diffs) if diffs[j] / np.amax(diffs) > 0.4]\n",
        "        for spot_indx in arr_:\n",
        "            spot = spots[spot_indx]\n",
        "            x1, y1, w, h = spot\n",
        "\n",
        "            spot_crop = frame[y1:y1 + h, x1:x1 + w, :]\n",
        "\n",
        "            spot_status = empty_or_not(spot_crop)\n",
        "\n",
        "            spots_status[spot_indx] = spot_status\n",
        "\n",
        "    if frame_nmr % step == 0:\n",
        "        previous_frame = frame.copy()\n",
        "\n",
        "    for spot_indx, spot in enumerate(spots):\n",
        "        spot_status = spots_status[spot_indx]\n",
        "        x1, y1, w, h = spots[spot_indx]\n",
        "\n",
        "        if spot_status:\n",
        "            frame = cv2.rectangle(frame, (x1, y1), (x1 + w, y1 + h), (0, 255, 0), 2)\n",
        "        else:\n",
        "            frame = cv2.rectangle(frame, (x1, y1), (x1 + w, y1 + h), (0, 0, 255), 2)\n",
        "\n",
        "    cv2.rectangle(frame, (80, 20), (550, 80), (0, 0, 0), -1)\n",
        "    cv2.putText(frame, 'Available spots: {} / {}'.format(str(sum(spots_status)), str(len(spots_status))), (100, 60),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "\n",
        "    cv2.namedWindow('frame', cv2.WINDOW_NORMAL)\n",
        "    cv2.imshow('frame', frame)\n",
        "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "    frame_nmr += 1\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cuS8uFAtd_U"
      },
      "source": [
        "#New\n",
        "[pklotsdbs](https://www.kaggle.com/datasets/blanderbuss/parking-lot-dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QHJabRqJupxe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDrjvopEteZy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64b76e85-7d57-4161-8ee3-07e01773100a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading parking-lot-dataset.zip to /content\n",
            " 99% 9.90G/9.98G [08:49<00:03, 22.6MB/s]"
          ]
        }
      ],
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive'\n",
        "!kaggle datasets download -d blanderbuss/parking-lot-dataset\n",
        "!unzip \\*.zip && rm *.zip\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXy-F-NjbKMb"
      },
      "source": [
        "#Classification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cls_data = './PKLot/PKLotSegmented'\n",
        "train_path = './data/train'\n",
        "val_path   = './data/validation'\n",
        "os.makedirs(train_path, exist_ok=True)\n",
        "os.makedirs(val_path, exist_ok=True)\n",
        "\n",
        "VAL_THRESHOLD = 0.2\n",
        "data_arr = []"
      ],
      "metadata": {
        "id": "su8_6GkGZtml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cb7RSFnYIZL"
      },
      "outputs": [],
      "source": [
        "for cat in os.listdir(cls_data):\n",
        "  for crs in os.listdir(cls_data+'/'+cat):\n",
        "    for day in os.listdir(cls_data+'/'+cat+'/'+crs):\n",
        "      for E_O in os.listdir(cls_data+'/'+cat+'/'+crs+'/'+day):\n",
        "        for img in os.listdir(cls_data+'/'+cat+'/'+crs+'/'+day+'/'+E_O):\n",
        "          path = os.path.join(cls_data, cat, crs, day, E_O, img)\n",
        "          folder_name = train_path if np.random.randn()<VAL_THRESHOLD else val_path\n",
        "          target = os.path.join(folder_name, img)\n",
        "          label = 0 if E_O == 'Empty' else 1\n",
        "          data_arr.append([target, label])\n",
        "          os.replace(path, target)\n",
        "\n",
        "data = pd.DataFrame(data_arr, columns=['path', 'label'])\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.groupby(['label']).count()"
      ],
      "metadata": {
        "id": "M5NVbBbcFWdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuwluNC08Eu8"
      },
      "outputs": [],
      "source": [
        "train_ds, val_ds = tf.keras.utils.image_dataset_from_directory('./data',\n",
        "                                                               validation_split=0.2,\n",
        "                                                               subset='both',\n",
        "                                                               seed=32,\n",
        "                                                               image_size=(528, 528),\n",
        "                                                               batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images(ds, augmentation=False):\n",
        "  plt.figure(figsize=(3, 3))\n",
        "  for images, labels in ds.take(1):\n",
        "      for i in range(9):\n",
        "          ax = plt.subplot(3, 3, i + 1)\n",
        "          if augmentation:\n",
        "            images = data_augmentation(images)\n",
        "            i = 0\n",
        "          plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "          plt.title(int(labels[i]))\n",
        "          plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "YzhBDCfZbvqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_images(train_ds)"
      ],
      "metadata": {
        "id": "Md4P_O2EytfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomRotation(factor=0.15),\n",
        "    tf.keras.layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
        "    tf.keras.layers.RandomFlip(),\n",
        "    tf.keras.layers.RandomContrast(factor=0.1),\n",
        "    ], name=\"img_augmentation\")"
      ],
      "metadata": {
        "id": "dm9kAKrAw9-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPQ2vpFy8Ixa"
      },
      "outputs": [],
      "source": [
        "show_images(train_ds, augmentation=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_train_ds = train_ds.map(lambda img, label : (data_augmentation(img), label),\n",
        "                                  num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "#(buffered) Prefetching samples in GPU memory helps maximize GPU utilization.\n",
        "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
        "val_ds   = val_ds.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "b-qWux7zzd4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Model(input_shape, num_cls):\n",
        "  inputs = tf.keras.Input(shape=input_shape)\n",
        "  x = tf.keras.layers.Rescaling(1/255)(inputs)\n",
        "  x = layers = tf.keras.layers.Conv2D(128, 3, strides=3, padding='same')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "  #Set Aside residual\n",
        "  previous_block_activation = x\n",
        "\n",
        "  for size in [256, 512, 728]:\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    x = tf.keras.layers.SeparableConv2D(size, 3, padding='same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    x = tf.keras.layers.SeparableConv2D(size, 3, padding='same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "    x = tf.keras.layers.MaxPooling2D(3, strides=2, padding='same')(x)\n",
        "\n",
        "    residual = tf.keras.layers.Conv2D(size, 1, strides=2, padding='same')(previous_block_activation)\n",
        "\n",
        "    x = tf.keras.layers.add([x, residual])\n",
        "    previous_block_activation = x\n",
        "\n",
        "  x = tf.keras.layers.SeparableConv2D(1024, 3, padding='same')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "  x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "  if num_cls == 2:\n",
        "    activation = 'sigmoid'\n",
        "    units = 1\n",
        "  else:\n",
        "    activation = 'softmax'\n",
        "    units = num_cls\n",
        "\n",
        "  x  = tf.keras.layers.Dropout(0.5)(x)\n",
        "  outputs = tf.keras.layers.Dense(units, activation=activation)(x)\n",
        "  return tf.keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "91mYPVKsAAqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = Model(input_shape=train_ds.take(1).element_spec[0].shape[1:], num_cls=2)\n",
        "# tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "rBHjFuV3FkF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EfficientNetB6 input dim = 528\n",
        "IMG_SIZE = 528\n",
        "epochs = 10\n",
        "callbacks = [tf.keras.callbacks.ModelCheckpoint('save_at_{epoch}.keras')]\n",
        "\n",
        "inputs = tf.keras.layers.Input((IMG_SIZE, IMG_SIZE, 3))\n",
        "x = data_augmentation(inputs)\n",
        "model = tf.keras.applications.EfficientNetB6(include_top=True, input_tensor=x, weighs='imagenet')\n",
        "\n",
        "model.trainable=False\n",
        "\n",
        "\n",
        "\n",
        "# Rebuild top\n",
        "x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
        "x = layers.BatchNormalization()(x)\n",
        "\n",
        "top_dropout_rate = 0.2\n",
        "x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_ds,\n",
        "          epochs=epochs,\n",
        "          callbacks=callbacks,\n",
        "          validation_data=val_ds)"
      ],
      "metadata": {
        "id": "aKKNKVml5m2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(num_classes):\n",
        "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    x = img_augmentation(inputs)\n",
        "    model = EfficientNetB0(include_top=False, input_tensor=x, weights=\"imagenet\")\n",
        "\n",
        "    # Freeze the pretrained weights\n",
        "    model.trainable = False\n",
        "\n",
        "    # Rebuild top\n",
        "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    top_dropout_rate = 0.2\n",
        "    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")(x)\n",
        "\n",
        "    # Compile\n",
        "    model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
        "    model.compile(\n",
        "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "WBmKChRWTwtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(num_classes=NUM_CLASSES)\n",
        "\n",
        "# epochs = 19 # @param {type:\"slider\", min:8, max:80, step:1}\n",
        "hist = model.fit(ds_train, epochs=epochs, validation_data=ds_test, verbose=2)\n",
        "plot_hist(hist)"
      ],
      "metadata": {
        "id": "XbkuMWDwT7Jp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_hist(hist):\n",
        "    plt.plot(hist.history[\"accuracy\"])\n",
        "    plt.plot(hist.history[\"val_accuracy\"])\n",
        "    plt.title(\"model accuracy\")\n",
        "    plt.ylabel(\"accuracy\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_hist(hist)"
      ],
      "metadata": {
        "id": "Rk9BTKeOF4sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from cloud_tpu_client import Client\n",
        "c = Client()\n",
        "c.configure_tpu_version(tf.__version__, restart_type=\"always\")\n",
        "import tensorflow as tf\n",
        "\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
        "    print(\"Device:\", tpu.master())\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "except ValueError:\n",
        "    print(\"Not connected to a TPU runtime. Using CPU/GPU strategy\")\n",
        "    strategy = tf.distribute.MirroredStrategy()"
      ],
      "metadata": {
        "id": "oCsGmgSt1NgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = keras.utils.load_img(\"PetImages/Cat/6779.jpg\", target_size=image_size)\n",
        "plt.imshow(img)\n",
        "\n",
        "img_array = keras.utils.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "score = float(predictions[0])\n",
        "print(f\"This image is {100 * (1 - score):.2f}% cat and {100 * score:.2f}% dog.\")"
      ],
      "metadata": {
        "id": "P4k3BXeQVKpb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "TsQYxqEyaaj7",
        "sNa1JXN2eOiD"
      ],
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1KVRbBvKz6JbCOIpxUHPj6mLS7G9fcJ0j",
      "authorship_tag": "ABX9TyPdps10HrLbnIZ3g2CEF3HQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}