{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "f8WQmjeZtgE-"
      ],
      "authorship_tag": "ABX9TyNAgGzQsOnbMhRJ7X6wxS3x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/Computer-Vision-Projects/blob/main/Objects_Counter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, the aim is to create an algorithm to detect objects on the video frames"
      ],
      "metadata": {
        "id": "pQ-N5_m2cFDx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc8u4d-Kb1tm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import IPython\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "IPython.display.clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1"
      ],
      "metadata": {
        "id": "f8WQmjeZtgE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = (128, 128)\n",
        "data = np.random.randint(5, 100, size=(1000, image_size[0], image_size[1]))\n",
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pY3DJE-3Vuis",
        "outputId": "d4abbc6d-5ec1-472b-bb75-fb9473419792"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[39,  7, 48, ..., 33, 61, 10],\n",
              "       [47, 18,  5, ..., 36, 30, 79],\n",
              "       [79, 68, 20, ..., 67, 20, 19],\n",
              "       ...,\n",
              "       [40, 34, 11, ..., 92,  9, 21],\n",
              "       [18, 83, 10, ..., 30, 44, 67],\n",
              "       [73, 67, 39, ..., 78, 62, 93]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_synthetic_data(num_samples, image_size=(128, 128), num_objects_range=(5, 20)):\n",
        "    data = []\n",
        "    for _ in range(num_samples):\n",
        "        num_objects = np.random.randint(*num_objects_range)\n",
        "        image = np.zeros(image_size)\n",
        "        for _ in range(num_objects):\n",
        "            object_x = np.random.randint(0, image_size[1])\n",
        "            object_y = np.random.randint(0, image_size[0])\n",
        "            image[object_y, object_x] += 1\n",
        "        data.append(image)\n",
        "    return np.array(data)\n",
        "\n",
        "# Prepare the data\n",
        "num_samples = 1000\n",
        "image_size = (128, 128)\n",
        "input_data = generate_synthetic_data(num_samples, image_size)\n",
        "density_maps = input_data.reshape(num_samples, image_size[0], image_size[1], 1)"
      ],
      "metadata": {
        "id": "nuRLGSsgaYyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data.shape, density_maps.shape"
      ],
      "metadata": {
        "id": "ijSdijY7abhi",
        "outputId": "23db72dd-1d8a-47d1-876b-ea323c273d05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1000, 128, 128), (1000, 128, 128, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the density map estimation model\n",
        "def create_density_map_model(input_shape):\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    density_map = tf.keras.layers.Conv2D(1, (1, 1), activation='relu', padding='same')(x)\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=density_map)\n",
        "    return model"
      ],
      "metadata": {
        "id": "LufRgBO3VlXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and compile the model\n",
        "input_shape = (image_size[0], image_size[1], 1)\n",
        "model = create_density_map_model(input_shape)\n",
        "model.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError())\n",
        "\n",
        "# Train the model\n",
        "model.fit(input_data, density_maps, batch_size=32, epochs=10, validation_split=0.2)\n",
        "\n",
        "# Test the model on a new image\n",
        "test_image = generate_synthetic_data(1, image_size)[0]\n",
        "predicted_density_map = model.predict(test_image.reshape(1, image_size[0], image_size[1], 1))\n",
        "\n",
        "# Perform object counting by summing up the density map values\n",
        "predicted_count = np.sum(predicted_density_map)\n",
        "\n",
        "print(f\"True object count: {test_image.sum()}\")\n",
        "print(f\"Predicted object count: {predicted_count}\")"
      ],
      "metadata": {
        "id": "zzr1ywmUVGxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#[link text](https://www.analyticsvidhya.com/blog/2021/11/complete-guide-to-people-counting-and-tracking-end-to-end-deep-learning-project/)\n",
        "\n",
        "\n",
        "[link text](https://github.com/BakingBrains/People_counting_basic/blob/main/utils/centroidtracker.py)"
      ],
      "metadata": {
        "id": "tHr412wHte9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "from scipy.spatial import distance as dist"
      ],
      "metadata": {
        "id": "y3VsYJO1tnVs"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrackableObject:\n",
        "\tdef __init__(self, objectID, centroid):\n",
        "\t\tself.objectID = objectID\n",
        "\t\tself.centroids = [centroid]\n",
        "\t\tself.counted = False"
      ],
      "metadata": {
        "id": "BqK-SKDi2U_U"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CentroidTracker:\n",
        "\tdef __init__(self, maxDisappeared=50, maxDistance=50):\n",
        "\t\tself.nextObjectID = 0\n",
        "\t\tself.objects = OrderedDict()\n",
        "\t\tself.disappeared = OrderedDict()\n",
        "\t\tself.maxDisappeared = maxDisappeared\n",
        "\t\tself.maxDistance = maxDistance\n",
        "\n",
        "\tdef register(self, centroid):\n",
        "\t\tself.objects[self.nextObjectID] = centroid\n",
        "\t\tself.disappeared[self.nextObjectID] = 0\n",
        "\t\tself.nextObjectID += 1\n",
        "\n",
        "\tdef deregister(self, objectID):\n",
        "\t\tdel self.objects[objectID]\n",
        "\t\tdel self.disappeared[objectID]\n",
        "\n",
        "\tdef update(self, rects):\n",
        "\t\tif len(rects) == 0:\n",
        "\t\t\tfor objectID in list(self.disappeared.keys()):\n",
        "\t\t\t\tself.disappeared[objectID] += 1\n",
        "\n",
        "\t\t\t\tif self.disappeared[objectID] > self.maxDisappeared:\n",
        "\t\t\t\t\tself.deregister(objectID)\n",
        "\n",
        "\t\t\treturn self.objects\n",
        "\n",
        "\t\tinputCentroids = np.zeros((len(rects), 2), dtype=\"int\")\n",
        "\n",
        "\t\tfor (i, (startX, startY, endX, endY)) in enumerate(rects):\n",
        "\t\t\tcX = int((startX + endX) / 2.0)\n",
        "\t\t\tcY = int((startY + endY) / 2.0)\n",
        "\t\t\tinputCentroids[i] = (cX, cY)\n",
        "\n",
        "\t\tif len(self.objects) == 0:\n",
        "\t\t\tfor i in range(0, len(inputCentroids)):\n",
        "\t\t\t\tself.register(inputCentroids[i])\n",
        "\n",
        "\t\telse:\n",
        "\t\t\tobjectIDs = list(self.objects.keys())\n",
        "\t\t\tobjectCentroids = list(self.objects.values())\n",
        "\n",
        "\t\t\tD = dist.cdist(np.array(objectCentroids), inputCentroids)\n",
        "\n",
        "\t\t\trows = D.min(axis=1).argsort()\n",
        "\n",
        "\t\t\tcols = D.argmin(axis=1)[rows]\n",
        "\n",
        "\t\t\tusedRows = set()\n",
        "\t\t\tusedCols = set()\n",
        "\n",
        "\t\t\tfor (row, col) in zip(rows, cols):\n",
        "\t\t\t\tif row in usedRows or col in usedCols:\n",
        "\t\t\t\t\tcontinue\n",
        "\n",
        "\t\t\t\tif D[row, col] > self.maxDistance:\n",
        "\t\t\t\t\tcontinue\n",
        "\n",
        "\t\t\t\tobjectID = objectIDs[row]\n",
        "\t\t\t\tself.objects[objectID] = inputCentroids[col]\n",
        "\t\t\t\tself.disappeared[objectID] = 0\n",
        "\n",
        "\t\t\t\tusedRows.add(row)\n",
        "\t\t\t\tusedCols.add(col)\n",
        "\n",
        "\t\t\tunusedRows = set(range(0, D.shape[0])).difference(usedRows)\n",
        "\t\t\tunusedCols = set(range(0, D.shape[1])).difference(usedCols)\n",
        "\n",
        "\t\t\tif D.shape[0] >= D.shape[1]:\n",
        "\t\t\t\tfor row in unusedRows:\n",
        "\t\t\t\t\tobjectID = objectIDs[row]\n",
        "\t\t\t\t\tself.disappeared[objectID] += 1\n",
        "\n",
        "\t\t\t\t\tif self.disappeared[objectID] > self.maxDisappeared:\n",
        "\t\t\t\t\t\tself.deregister(objectID)\n",
        "\n",
        "\t\t\telse:\n",
        "\t\t\t\tfor col in unusedCols:\n",
        "\t\t\t\t\tself.register(inputCentroids[col])\n",
        "\n",
        "\t\treturn self.objects"
      ],
      "metadata": {
        "id": "hwcoZPbutfjA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import argparse\n",
        "import sys\n",
        "import numpy as np\n",
        "import os.path\n",
        "import math\n",
        "\n",
        "confThreshold = 0.6\n",
        "nmsThreshold = 0.4\n",
        "inpWidth = 416\n",
        "inpHeight = 416\n",
        "\n",
        "parser = argparse.ArgumentParser(description='Object Detection using YOLO in OPENCV')\n",
        "\n",
        "parser.add_argument('--video', default='test.mp4', help='Path to video file.')\n",
        "args = parser.parse_args()\n",
        "\n",
        "classesFile = \"coco.names\"\n",
        "classes = None\n",
        "with open(classesFile, 'rt') as f:\n",
        "    classes = f.read().rstrip('\\n').split('\\n')\n",
        "\n",
        "modelConfiguration = \"yolov3.cfg\"\n",
        "modelWeights = \"yolov3.weights\"\n",
        "\n",
        "print(\"[INFO] loading model...\")\n",
        "net = cv.dnn.readNetFromDarknet(modelConfiguration, modelWeights)\n",
        "net.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)\n",
        "net.setPreferableTarget(cv.dnn.DNN_TARGET_OPENCL)\n",
        "\n",
        "writer = None\n",
        "\n",
        "W = None\n",
        "H = None\n",
        "\n",
        "ct = CentroidTracker(maxDisappeared=40, maxDistance=50)\n",
        "trackers = []\n",
        "trackableObjects = {}\n",
        "\n",
        "totalDown = 0\n",
        "totalUp = 0\n",
        "\n",
        "def getOutputsNames(net):\n",
        "    layersNames = net.getLayerNames()\n",
        "    return [layersNames[i - 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "\n",
        "def postprocess(frame, outs):\n",
        "    frameHeight = frame.shape[0]\n",
        "    frameWidth = frame.shape[1]\n",
        "\n",
        "    rects = []\n",
        "\n",
        "    classIds = []\n",
        "    confidences = []\n",
        "    boxes = []\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            classId = np.argmax(scores)\n",
        "            confidence = scores[classId]\n",
        "            if confidence > confThreshold:\n",
        "                center_x = int(detection[0] * frameWidth)\n",
        "                center_y = int(detection[1] * frameHeight)\n",
        "                width = int(detection[2] * frameWidth)\n",
        "                height = int(detection[3] * frameHeight)\n",
        "                left = int(center_x - width / 2)\n",
        "                top = int(center_y - height / 2)\n",
        "                classIds.append(classId)\n",
        "                confidences.append(float(confidence))\n",
        "                boxes.append([left, top, width, height])\n",
        "\n",
        "    indices = cv.dnn.NMSBoxes(boxes, confidences, confThreshold, nmsThreshold)\n",
        "    for i in indices:\n",
        "        box = boxes[i]\n",
        "        left = box[0]\n",
        "        top = box[1]\n",
        "        width = box[2]\n",
        "        height = box[3]\n",
        "        if classIds[i] == 0:\n",
        "            rects.append((left, top, left + width, top + height))\n",
        "            objects = ct.update(rects)\n",
        "            counting(objects)\n",
        "\n",
        "\n",
        "def counting(objects):\n",
        "    frameHeight = frame.shape[0]\n",
        "    frameWidth = frame.shape[1]\n",
        "\n",
        "    global totalDown\n",
        "    global totalUp\n",
        "\n",
        "    for (objectID, centroid) in objects.items():\n",
        "        to = trackableObjects.get(objectID, None)\n",
        "\n",
        "        if to is None:\n",
        "            to = TrackableObject(objectID, centroid)\n",
        "\n",
        "        else:\n",
        "            y = [c[1] for c in to.centroids]\n",
        "            direction = centroid[1] - np.mean(y)\n",
        "            print(direction)\n",
        "            to.centroids.append(centroid)\n",
        "\n",
        "            if not to.counted:\n",
        "\n",
        "                if direction < 0 and centroid[1] in range(frameHeight//2 - 30, frameHeight//2 + 30):\n",
        "                    totalUp += 1\n",
        "                    to.counted = True\n",
        "\n",
        "                elif direction > 0 and centroid[1] in range(frameHeight//2 - 30, frameHeight//2 + 30):\n",
        "                    totalDown += 1\n",
        "                    to.counted = True\n",
        "\n",
        "        trackableObjects[objectID] = to\n",
        "        # text = \"ID {}\".format(objectID)\n",
        "        # cv.putText(frame, text, (centroid[0] - 10, centroid[1] - 10),\n",
        "            # cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "        cv.circle(frame, (centroid[0], centroid[1]), 4, (0, 255, 0), -1)\n",
        "    info = [\n",
        "        (\"Up\", totalUp),\n",
        "        (\"Down\", totalDown),\n",
        "    ]\n",
        "\n",
        "    for (i, (k, v)) in enumerate(info):\n",
        "\n",
        "        text = \"{}\".format(v)\n",
        "        if k == 'Up':\n",
        "            cv.putText(frame, f'Up : {text}', (10, 55),\n",
        "                cv.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
        "        if k == 'Down':\n",
        "            cv.putText(frame, f'Down : {text}', (10, 75),\n",
        "                       cv.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
        "\n",
        "winName = 'People Counting and Tracking System'\n",
        "cv.namedWindow(winName, cv.WINDOW_NORMAL)\n",
        "\n",
        "outputFile = \"yolo_out_py.avi\"\n",
        "\n",
        "if (args.video):\n",
        "    if not os.path.isfile(args.video):\n",
        "        print(\"Input video file \", args.video, \" doesn't exist\")\n",
        "        sys.exit(1)\n",
        "    cap = cv.VideoCapture(args.video)\n",
        "    outputFile = args.video[:-4]+'_output.avi'\n",
        "else:\n",
        "    cap = cv.VideoCapture(0)\n",
        "\n",
        "vid_writer = cv.VideoWriter(outputFile, cv.VideoWriter_fourcc('M','J','P','G'), 30, (round(cap.get(cv.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv.CAP_PROP_FRAME_HEIGHT))))\n",
        "\n",
        "while cv.waitKey(1) < 0:\n",
        "\n",
        "    hasFrame, frame = cap.read()\n",
        "    frameHeight = frame.shape[0]\n",
        "    frameWidth = frame.shape[1]\n",
        "    cv.line(frame, (0, frameHeight // 2), (frameWidth, frameHeight // 2), (0, 255, 255), 2)\n",
        "\n",
        "    if not hasFrame:\n",
        "        print(\"Done processing !!!\")\n",
        "        print(\"Output file is stored as \", outputFile)\n",
        "        cv.waitKey(3000)\n",
        "        cap.release()\n",
        "        break\n",
        "\n",
        "    blob = cv.dnn.blobFromImage(frame, 1/255, (inpWidth, inpHeight), [0,0,0], 1, crop=False)\n",
        "\n",
        "    net.setInput(blob)\n",
        "\n",
        "    outs = net.forward(getOutputsNames(net))\n",
        "\n",
        "    postprocess(frame, outs)\n",
        "\n",
        "    t, _ = net.getPerfProfile()\n",
        "    label = 'Inference time: %.2f ms' % (t * 1000.0 / cv.getTickFrequency())\n",
        "    cv.putText(frame, label, (0, 15), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255))\n",
        "    vid_writer.write(frame.astype(np.uint8))\n",
        "    cv.imshow(winName, frame)\n",
        "\n"
      ],
      "metadata": {
        "id": "UH-lfmRT2BQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3"
      ],
      "metadata": {
        "id": "fNH0PSp63YwL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VdqbMwV_3L5h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}