{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/CV-Object-Detection-Projects/blob/main/Flower_Recognition_Challenges.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aZen4Gyyr-v"
      },
      "source": [
        "**Flowers Recognition**\n",
        "It is a dataset from kaggle and I will implement some of the best notebooks and compare them to learn the best pattern to solve this problem.\n",
        "you can access the dataset or the notebooks in [here](https://www.kaggle.com/datasets/alxmamaev/flowers-recognition)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvUh2IGTxv0v"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from zipfile import ZipFile\n",
        "from matplotlib import style\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "style.use('fivethirtyeight')\n",
        "sns.set(style='whitegrid', color_codes=True)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('always')\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from sklearn import preprocessing, model_selection, metrics, decomposition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMJbTD53TqfH"
      },
      "source": [
        "###Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2LYYXBQTpva"
      },
      "outputs": [],
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive/'\n",
        "!kaggle datasets download -d alxmamaev/flowers-recognition\n",
        "!unzip \\*.zip && rm *.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####1.Train/Test Split data first way\n",
        "A simple code to only open folders and save them one by one in the data and label folder"
      ],
      "metadata": {
        "id": "UM3MQssxwQYq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKuMQ_DSVF29"
      },
      "outputs": [],
      "source": [
        "path_folder = '/content/flowers'\n",
        "\n",
        "size = 224\n",
        "data = []\n",
        "label = []\n",
        "data_names = []\n",
        "id = 0\n",
        "for folder in tqdm.tqdm(os.listdir(path_folder)):\n",
        "  for files in tqdm.tqdm(os.listdir(os.path.join(path_folder, folder))):\n",
        "    if files.endswith('jpg'):\n",
        "      label.append(folder)\n",
        "      img_path = os.path.join(path_folder, folder, files)\n",
        "      data_names.append((id, img_path))\n",
        "      img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "      im = cv2.resize(img, (size, size))\n",
        "      data.append(im)\n",
        "      id += 1\n",
        "    else:\n",
        "      continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf8c0U7FXceQ"
      },
      "outputs": [],
      "source": [
        "categories = set(label)\n",
        "categories, len(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cKZT8X0XgKu",
        "outputId": "826655b8-e3a2-4e17-b4ab-8e032fa34b89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4317, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "np.array(data).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aW6SCiQhXgHn"
      },
      "outputs": [],
      "source": [
        "data = np.array(data)\n",
        "label = np.array(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szesPTsMXjSD"
      },
      "outputs": [],
      "source": [
        "x = data/255\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "y = encoder.fit_transform(label)\n",
        "y = tf.keras.utils.to_categorical(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o7Z_7c8Ddpw"
      },
      "source": [
        "Creating test, train data from x, will consume all them memory we have in colab,\n",
        "so instead we can put **data_names** in to train/test splits.\n",
        "\n",
        "\n",
        "Since vgg16 model, returns the exact names of the categories and not it's encoded form, we will use label as y\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YL1P4-FEcha9"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, random_state=32, test_size=0.2)\n",
        "\n",
        "# x_train, x_test, y_train, y_test = model_selection.train_test_split(data_names, y, random_state=32, test_size=0.2)\n",
        "\n",
        "# x_train, x_test, y_train, y_test = model_selection.train_test_split(data_names, label, random_state=32, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REMebpcbc_Wi",
        "outputId": "fe6a5ce5-ac19-42e2-b917-1881c5581b32"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3453, 864)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(x_train), len(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUpQd0jnJwS1",
        "outputId": "871726a7-c3c4-4ecc-df79-aa752cbe3fd6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(270, '/content/flowers/tulip/9446982168_06c4d71da3_n.jpg'),\n",
              " (3088, '/content/flowers/daisy/4837182901_69a6cc782b_n.jpg'),\n",
              " (3784, '/content/flowers/sunflower/5043409856_395300dbe5_m.jpg'),\n",
              " (238, '/content/flowers/tulip/17730239562_9aa0fc0738_n.jpg'),\n",
              " (1325, '/content/flowers/dandelion/19067907051_16d530c7d2.jpg'),\n",
              " (3828, '/content/flowers/sunflower/2950505226_529e013bf7_m.jpg'),\n",
              " (3313, '/content/flowers/daisy/2901376034_cdb4bac26b_m.jpg'),\n",
              " (911, '/content/flowers/tulip/6994351792_343e18cbf6_n.jpg'),\n",
              " (4228, '/content/flowers/sunflower/44079668_34dfee3da1_n.jpg'),\n",
              " (8, '/content/flowers/tulip/8454707381_453b4862eb_m.jpg'),\n",
              " (3030, '/content/flowers/daisy/5109508979_68e3530791_m.jpg'),\n",
              " (593, '/content/flowers/tulip/8586205168_8294e67195_n.jpg'),\n",
              " (3547, '/content/flowers/daisy/367020749_3c9a652d75.jpg'),\n",
              " (464, '/content/flowers/tulip/16986144192_55e0e6c152.jpg'),\n",
              " (1564, '/content/flowers/dandelion/6044710875_0459796d1b_m.jpg'),\n",
              " (2783, '/content/flowers/rose/18990187093_09f2bff8fc_m.jpg'),\n",
              " (1080, '/content/flowers/dandelion/33857574164_b0b724b567_n.jpg'),\n",
              " (1416, '/content/flowers/dandelion/14439618952_470224b89b_n.jpg'),\n",
              " (3298, '/content/flowers/daisy/1314069875_da8dc023c6_m.jpg'),\n",
              " (508, '/content/flowers/tulip/13903937027_44b9f2f5b8.jpg')]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Visualize data"
      ],
      "metadata": {
        "id": "2gkgIx4h9f1u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "rqlfFq0n6_97",
        "outputId": "4bfd39f0-926a-4ba0-ba07-b452956da96e"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(4, 4)\n",
        "fig.set_size_inches(20, 20)\n",
        "for i in range(4):\n",
        "  for j in range(4):\n",
        "    rnd = np.random.randint(0, len(x), 1)[0]\n",
        "    ax[i, j].imshow(x[rnd])\n",
        "    ax[i, j].set_title(f'Flower {label[rnd]}')\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBB884Uwp7Va"
      },
      "source": [
        "# 1.CNN Architectures : VGG, ResNet, Inception + TL\n",
        "[Note Book](https://www.kaggle.com/code/shivamb/cnn-architectures-vgg-resnet-inception-tl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYe3j7OqvYSl"
      },
      "source": [
        "##1.1 VGG16\n",
        "####Visual Geometry Group from Oxford\n",
        "VGG-16 is a convolutional neural network that is 16 layers deep. You can load a pretrained version of the network trained on more than a million images from the ImageNet database. The pretrained network can classify images into 1000 object categories, such as keyboard, mouse, pencil, and many animals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-ECyNtXE8Wf"
      },
      "outputs": [],
      "source": [
        "n_1, n_2, n_3, n_4 = np.random.randint(0, len(x_train), 4)\n",
        "test_imgs = np.array([x_train[n_1], x_train[n_2], x_train[n_3], x_train[n_4]])\n",
        "test_imgs_y = np.array([y_train[n_1], y_train[n_2], y_train[n_3], y_train[n_4]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMWFw9L3opem"
      },
      "outputs": [],
      "source": [
        "def image_loader(img_path, t_size=224):\n",
        "  img = tf.keras.preprocessing.image.load_img(img_path, target_size=(t_size, t_size))\n",
        "  img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img = np.expand_dims(img, axis=0)\n",
        "  img = tf.keras.applications.vgg16.preprocess_input(img)\n",
        "  return img\n",
        "\n",
        "def predict_img(imgs, imgs_y, model):\n",
        "  fig, ax = plt.subplots(1, 4, figsize=(30, 40))  \n",
        "  for i, img_path in enumerate(imgs):\n",
        "    img = image_loader(img_path[1])\n",
        "    preds = tf.keras.applications.vgg16.decode_predictions(model.predict(img), top=10)[0]\n",
        "    flower_pred = None\n",
        "    for p in preds:\n",
        "      if p[1] in categories:\n",
        "        flower_pred = p\n",
        "        break\n",
        "    final_pred = flower_pred if flower_pred else preds[0]\n",
        "\n",
        "    ax[i].imshow(Image.open(imgs[i][1]).resize((200, 200), Image.ANTIALIAS))\n",
        "    color = 'green' if final_pred[1] == imgs_y[i] else 'red'\n",
        "    ax[i].set_title(f\"Pred: {final_pred[1]} with: %{100*final_pred[-1]:.2f} Confidence\", color= color, fontweight='bold')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m0uapPC-auP"
      },
      "source": [
        "###From Scratch VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmSwf58-01TO"
      },
      "outputs": [],
      "source": [
        "class VGG16(tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super(VGG16, self).__init__()\n",
        "\n",
        "    #1\n",
        "    self.conv1 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu', name='block1_conv1')\n",
        "    self.conv2 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu', name='block1_conv2')\n",
        "    self.maxpool1 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))\n",
        "    #2\n",
        "    self.conv3 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu', name='block2_conv1')\n",
        "    self.conv4 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu', name='block2_conv2')\n",
        "    self.maxpool2 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))\n",
        "    #3\n",
        "    self.conv5 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu', name='block3_conv1')\n",
        "    self.conv6 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu', name='block3_conv2')\n",
        "    self.conv7 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu', name='block3_conv3')\n",
        "    self.maxpool3 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))\n",
        "    #4\n",
        "    self.conv8 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, padding='same', activation='relu', name='block4_conv1')\n",
        "    self.conv9 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, padding='same', activation='relu', name='block4_conv2')\n",
        "    self.conv10 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, padding='same', activation='relu', name='block4_conv3')\n",
        "    self.maxpool4 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))\n",
        "    #5\n",
        "    self.conv11 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, padding='same', activation='relu', name='block5_conv1')\n",
        "    self.conv12 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, padding='same', activation='relu', name='block5_conv2')\n",
        "    self.conv13 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, padding='same', activation='relu', name='block5_conv3')\n",
        "    self.maxpool5 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))\n",
        "    #6\n",
        "    self.flat = tf.keras.layers.Flatten()\n",
        "    self.dense1 = tf.keras.layers.Dense(4096, activation='relu', name='fc1')\n",
        "    self.droput1 = tf.keras.layers.Dropout(rate=0.5, name='Dropout1')\n",
        "    self.dense2 = tf.keras.layers.Dense(4096, activation='relu', name='fc2')\n",
        "    self.droput2 = tf.keras.layers.Dropout(rate=0.5, name='Dropout2')\n",
        "    self.dense3 = tf.keras.layers.Dense(1000, activation='softmax', name='fc2')\n",
        "\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # inputs = tf.keras.Input(shape=(224, 224, 1))\n",
        "    x = self.conv1(inputs)\n",
        "    x = self.conv2(x)\n",
        "    x = self.maxpool1(x)\n",
        "\n",
        "    x = self.conv3(x)\n",
        "    x = self.conv4(x)\n",
        "    x = self.maxpool2(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = self.conv6(x)\n",
        "    x = self.conv7(x)\n",
        "    x = self.maxpool3(x)\n",
        "\n",
        "    x = self.conv8(x)\n",
        "    x = self.conv9(x)\n",
        "    x = self.conv10(x)\n",
        "    x = self.maxpool4(x)\n",
        "\n",
        "    x = self.conv11(x)\n",
        "    x = self.conv12(x)\n",
        "    x = self.conv13(x)\n",
        "    x = self.maxpool5(x)\n",
        "    \n",
        "    x = self.flat(x)\n",
        "\n",
        "    x = self.dense1(x)\n",
        "    x = self.droput1(x)\n",
        "\n",
        "    x = self.dense2(x)\n",
        "    x = self.droput2(x)\n",
        "\n",
        "    x = self.dense3(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyU8lPo9OeZl"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPjTj7LYQWfc",
        "outputId": "547f92fa-3546-4941-946f-49188f5122fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"vgg16_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " block1_conv1 (Conv2D)       multiple                  1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       multiple                  36928     \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  multiple                 0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       multiple                  73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       multiple                  147584    \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  multiple                 0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       multiple                  295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       multiple                  590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       multiple                  590080    \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  multiple                 0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       multiple                  1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       multiple                  2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       multiple                  2359808   \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  multiple                 0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       multiple                  2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       multiple                  2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       multiple                  2359808   \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  multiple                 0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         multiple                  0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 multiple                  102764544 \n",
            "                                                                 \n",
            " Dropout1 (Dropout)          multiple                  0         \n",
            "                                                                 \n",
            " fc2 (Dense)                 multiple                  16781312  \n",
            "                                                                 \n",
            " Dropout2 (Dropout)          multiple                  0         \n",
            "                                                                 \n",
            " fc2 (Dense)                 multiple                  4097000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "vgg16_model = VGG16()\n",
        "vgg16_model.build(input_shape=(1, 224, 224, 3))\n",
        "vgg16_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4Nr1TerOn2s"
      },
      "outputs": [],
      "source": [
        "vgg16_weights = 'vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n",
        "vgg16_model.load_weights('vgg16_weights_tf_dim_ordering_tf_kernels.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NitQbDeI2F4g"
      },
      "outputs": [],
      "source": [
        "predict_img(test_imgs, test_imgs_y, vgg16_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUQsA65T-hGD"
      },
      "source": [
        "###Pretrained VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgEusVYmFCE-"
      },
      "outputs": [],
      "source": [
        "def image_loader_pretrained(the_model, img_path, t_size=224):\n",
        "  img = tf.keras.preprocessing.image.load_img(img_path, target_size=(t_size, t_size))\n",
        "  img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img = np.expand_dims(img, axis=0)\n",
        "  img = the_model.preprocess_input(img)\n",
        "  return img\n",
        "\n",
        "def predict_img_pretrained(imgs, imgs_y, model, the_model):\n",
        "  fig, ax = plt.subplots(1, 4, figsize=(30, 40))  \n",
        "  for i, img_path in enumerate(imgs):\n",
        "    img = image_loader_pretrained(the_model, img_path[1])\n",
        "    preds = the_model.decode_predictions(model.predict(img), top=10)[0]\n",
        "    flower_pred = None\n",
        "    for p in preds:\n",
        "      if p[1] in categories:\n",
        "        flower_pred = p\n",
        "        break\n",
        "    final_pred = flower_pred if flower_pred else preds[0]\n",
        "\n",
        "    ax[i].imshow(Image.open(imgs[i][1]).resize((200, 200), Image.ANTIALIAS))\n",
        "    color = 'green' if final_pred[1] == imgs_y[i] else 'red'\n",
        "    ax[i].set_title(f\"Pred: {final_pred[1]} with: %{100*final_pred[-1]:.2f} Confidence\", color= color, fontweight='bold')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXxP545lof_W"
      },
      "outputs": [],
      "source": [
        "vgg16_model_pretrained = tf.keras.applications.VGG16(weights=vgg16_weights)\n",
        "predict_img_pretrained(test_imgs, test_imgs_y, vgg16_model_pretrained, tf.keras.applications.vgg16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esnPAwvdIvae"
      },
      "source": [
        "##1.2 VGG19\n",
        "####It is the VGG16 model with a small difference, there is one extra convolutional layer in each of the [3, 4, 5] blocks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Oskv7JQJS01"
      },
      "source": [
        "###From Scratch VGG19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4IfLpqWJXk_"
      },
      "outputs": [],
      "source": [
        "class VGG19(tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super(VGG19, self).__init__()\n",
        "\n",
        "    #1\n",
        "    self.conv1 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu', name='block1_conv1')\n",
        "    self.conv2 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu', name='block1_conv2')\n",
        "    self.maxpool1 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))\n",
        "    #2\n",
        "    self.conv3 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu', name='block2_conv1')\n",
        "    self.conv4 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu', name='block2_conv2')\n",
        "    self.maxpool2 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))\n",
        "    #3\n",
        "    self.conv5 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu', name='block3_conv1')\n",
        "    self.conv6 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu', name='block3_conv2')\n",
        "    self.conv7 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu', name='block3_conv3')\n",
        "    self.conv8 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu', name='block3_conv4')\n",
        "    self.maxpool3 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))\n",
        "    #4\n",
        "    self.conv9 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, padding='same', activation='relu', name='block4_conv1')\n",
        "    self.conv10 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, padding='same', activation='relu', name='block4_conv2')\n",
        "    self.conv11 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, padding='same', activation='relu', name='block4_conv3')\n",
        "    self.conv12 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, padding='same', activation='relu', name='block4_conv4')\n",
        "    self.maxpool4 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))\n",
        "    #5\n",
        "    self.conv13 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, padding='same', activation='relu', name='block5_conv1')\n",
        "    self.conv14 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, padding='same', activation='relu', name='block5_conv2')\n",
        "    self.conv15 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, padding='same', activation='relu', name='block5_conv3')\n",
        "    self.conv16 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, padding='same', activation='relu', name='block5_conv4')\n",
        "\n",
        "    self.maxpool5 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))\n",
        "    #6\n",
        "    self.flat = tf.keras.layers.Flatten()\n",
        "    self.dense1 = tf.keras.layers.Dense(4096, activation='relu', name='fc1')\n",
        "    self.droput1 = tf.keras.layers.Dropout(rate=0.5, name='Dropout1')\n",
        "    self.dense2 = tf.keras.layers.Dense(4096, activation='relu', name='fc2')\n",
        "    self.droput2 = tf.keras.layers.Dropout(rate=0.5, name='Dropout2')\n",
        "    self.dense3 = tf.keras.layers.Dense(1000, activation='softmax', name='fc2')\n",
        "\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # inputs = tf.keras.Input(shape=(224, 224, 1))\n",
        "    x = self.conv1(inputs)\n",
        "    x = self.conv2(x)\n",
        "    x = self.maxpool1(x)\n",
        "\n",
        "    x = self.conv3(x)\n",
        "    x = self.conv4(x)\n",
        "    x = self.maxpool2(x)\n",
        "\n",
        "    x = self.conv5(x)\n",
        "    x = self.conv6(x)\n",
        "    x = self.conv7(x)\n",
        "    x = self.conv8(x)\n",
        "    x = self.maxpool3(x)\n",
        "\n",
        "    x = self.conv9(x)\n",
        "    x = self.conv10(x)\n",
        "    x = self.conv11(x)\n",
        "    x = self.conv12(x)\n",
        "    x = self.maxpool4(x)\n",
        "\n",
        "    x = self.conv13(x)\n",
        "    x = self.conv14(x)\n",
        "    x = self.conv15(x)\n",
        "    x = self.conv16(x)\n",
        "    x = self.maxpool5(x)\n",
        "    \n",
        "    x = self.flat(x)\n",
        "\n",
        "    x = self.dense1(x)\n",
        "    x = self.droput1(x)\n",
        "\n",
        "    x = self.dense2(x)\n",
        "    x = self.droput2(x)\n",
        "\n",
        "    x = self.dense3(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4pbNmb0JAiV"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7kJ6fgPMExs",
        "outputId": "0798fe20-e357-48fc-db68-4761ff6f37e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"vgg19_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " block1_conv1 (Conv2D)       multiple                  1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       multiple                  36928     \n",
            "                                                                 \n",
            " max_pooling2d_25 (MaxPoolin  multiple                 0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       multiple                  73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       multiple                  147584    \n",
            "                                                                 \n",
            " max_pooling2d_26 (MaxPoolin  multiple                 0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       multiple                  295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       multiple                  590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       multiple                  590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       multiple                  590080    \n",
            "                                                                 \n",
            " max_pooling2d_27 (MaxPoolin  multiple                 0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       multiple                  1180160   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       multiple                  2359808   \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       multiple                  2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       multiple                  2359808   \n",
            "                                                                 \n",
            " max_pooling2d_28 (MaxPoolin  multiple                 0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       multiple                  2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       multiple                  2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       multiple                  2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       multiple                  2359808   \n",
            "                                                                 \n",
            " max_pooling2d_29 (MaxPoolin  multiple                 0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         multiple                  0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 multiple                  102764544 \n",
            "                                                                 \n",
            " Dropout1 (Dropout)          multiple                  0         \n",
            "                                                                 \n",
            " fc2 (Dense)                 multiple                  16781312  \n",
            "                                                                 \n",
            " Dropout2 (Dropout)          multiple                  0         \n",
            "                                                                 \n",
            " fc2 (Dense)                 multiple                  4097000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 143,667,240\n",
            "Trainable params: 143,667,240\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "vgg19_model = VGG19()\n",
        "vgg19_model.build(input_shape=(1, 224, 224, 3))\n",
        "vgg19_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YN6U9c52MX1G"
      },
      "outputs": [],
      "source": [
        "vgg19_weights = 'vgg19_weights_tf_dim_ordering_tf_kernels.h5'\n",
        "vgg19_model.load_weights(vgg19_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEVLCoRaMpg-"
      },
      "outputs": [],
      "source": [
        "predict_img(test_imgs, test_imgs_y, vgg19_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pz7px5t7M9th"
      },
      "source": [
        "###Pretrained VGG19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkdRStS-EAGd"
      },
      "outputs": [],
      "source": [
        "vgg19_weights = 'vgg19_weights_tf_dim_ordering_tf_kernels.h5'\n",
        "vgg19_model_pretrained = tf.keras.applications.VGG19(weights=vgg19_weights)\n",
        "predict_img_pretrained(test_imgs, test_imgs_y, vgg19_model_pretrained, tf.keras.applications.vgg19)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wNbIDKpUS4d"
      },
      "source": [
        "##1.3 InceptionNets (GoogleNet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaeJmFbztntf"
      },
      "source": [
        "## 1.4ResNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBTf-8_gtsh3"
      },
      "source": [
        "##1.5 XceptionNets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ixl42mCJvuFG"
      },
      "source": [
        "# 2.Flower Recognition CNN Keras\n",
        "[Note Book](https://www.kaggle.com/code/rajmehra03/flower-recognition-cnn-keras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCWmR7JmwvYc"
      },
      "outputs": [],
      "source": [
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "datagen.fit(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=5, padding='same',activation='relu', input_shape=(224, 224, 3)))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=5, padding='same',activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=5, padding='same',activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=5, padding='same',activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(5, activation='softmax'))"
      ],
      "metadata": {
        "id": "f2wI0cWdAhFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_callback =  tf.keras.callbacks.ReduceLROnPlateau(monitor='val_acc', pationce=3, verbose=1, factor=0.1)"
      ],
      "metadata": {
        "id": "n2XR4O19Cz32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(lr=0.001),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ucboXSICDETF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNdfE9LeDUHS",
        "outputId": "a2d83852-49a2-46f7-8c08-04ed5cf4753b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 224, 224, 32)      2432      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 112, 112, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 112, 112, 64)      51264     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 56, 56, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 56, 56, 128)       204928    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 28, 28, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 28, 28, 128)       409728    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 14, 14, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               12845568  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 2565      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,516,485\n",
            "Trainable params: 13,516,485\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "history =model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                   epochs=1, validation_data=(x_test, y_test), verbose=1)"
      ],
      "metadata": {
        "id": "WhhxPg32DVfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(hist, loss='True'):\n",
        "  title = 'loss' if loss else 'accuracy'\n",
        "  plt.plot(hist.history[f'{title}'])\n",
        "  plt.plot(hist.history[f'val_{title}'])\n",
        "  plt.title(f'Model {title}')\n",
        "  plt.ylabel(f'{title}')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend(['train', 'test'])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "qc8QdX0SHDnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(history)"
      ],
      "metadata": {
        "id": "7g2WD2ILHjqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(history, False)"
      ],
      "metadata": {
        "id": "bV_qeRrqHeFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting predictions on val set.\n",
        "pred=model.predict(x_test)\n",
        "pred_digits=np.argmax(pred,axis=1)\n",
        "# now storing some properly as well as misclassified indexes'.\n",
        "i=0\n",
        "prop_class=[]\n",
        "mis_class=[]\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "    if(np.argmax(y_test[i])==pred_digits[i]):\n",
        "        prop_class.append(i)\n",
        "    if(len(prop_class)==8):\n",
        "        break\n",
        "\n",
        "i=0\n",
        "for i in range(len(y_test)):\n",
        "    if(not np.argmax(y_test[i])==pred_digits[i]):\n",
        "        mis_class.append(i)\n",
        "    if(len(mis_class)==8):\n",
        "        break"
      ],
      "metadata": {
        "id": "Z8ARIL7RHyzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count=0\n",
        "fig,ax=plt.subplots(4,2)\n",
        "fig.set_size_inches(15,15)\n",
        "for i in range (4):\n",
        "    for j in range (2):\n",
        "        ax[i,j].imshow(x_test[prop_class[count]])\n",
        "        ax[i,j].set_title(\"Predicted Flower : \"+str(le.inverse_transform([pred_digits[prop_class[count]]]))+\"\\n\"+\"Actual Flower : \"+str(le.inverse_transform(np.argmax([y_test[prop_class[count]]]))))\n",
        "        plt.tight_layout()\n",
        "        count+=1"
      ],
      "metadata": {
        "id": "_U6Q_28HHkhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count=0\n",
        "fig,ax=plt.subplots(4,2)\n",
        "fig.set_size_inches(15,15)\n",
        "for i in range (4):\n",
        "    for j in range (2):\n",
        "        ax[i,j].imshow(x_test[mis_class[count]])\n",
        "        ax[i,j].set_title(\"Predicted Flower : \"+str(le.inverse_transform([pred_digits[mis_class[count]]]))+\"\\n\"+\"Actual Flower : \"+str(le.inverse_transform(np.argmax([y_test[mis_class[count]]]))))\n",
        "        plt.tight_layout()\n",
        "        count+=1"
      ],
      "metadata": {
        "id": "hvIvPxUsHuOQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "mount_file_id": "15-SrDUSQaTQfJJRr-m2CbeLEnOAvdABB",
      "authorship_tag": "ABX9TyMZnjjgOR4aL3N5pKzzsCTr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
