{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "OUTSAYdXquv3",
        "d-EQjAKHVgjg",
        "VpTPyLRSWrCa",
        "diAfMmX1YRU0",
        "KarV4t5uZUUC"
      ],
      "mount_file_id": "1EkPO3-a7zWEBBox_OayTsTNDMvTNzzuS",
      "authorship_tag": "ABX9TyMVk3Odbb1cRhVABu4cALO9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/Computer-Vision-Projects/blob/main/Arthropod_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [Arthropod Taxonomy Orders Object Detection Dataset](https://www.kaggle.com/datasets/mistag/arthropod-taxonomy-orders-object-detection-dataset/)\n",
        "\n",
        "\n",
        "\n",
        "###### Lepidoptera = butterfies and moths\n",
        "###### Hymenoptera = wasps, bees and ants\n",
        "###### Hemiptera = true bugs (cicadas, aphids, shield bugs, ...)\n",
        "###### Odonata = dragonflies\n",
        "###### Diptera = fies\n",
        "###### Araneae = spiders\n",
        "###### Coleoptera = beetles\n",
        "\n",
        "###### NOT IN DATASET\n",
        "###### Orthoptera = grasshoppers"
      ],
      "metadata": {
        "id": "VdtRvVryHrSc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Jc6VQxrK6Zz3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8806fc9f-6e7f-4071-9ecd-db9992a068cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.1 MB 40.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 70.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 238 kB 78.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 70.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 118 kB 69.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 56.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 662 kB 80.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 75.8 MB/s \n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import numpy as np\n",
        "import pprint as pp\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import matplotlib as mpl\n",
        "import concurrent.futures\n",
        "from PIL import Image, ImageDraw\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "AUTO = tf.data.AUTOTUNE\n",
        "pp = pp.PrettyPrinter()\n",
        "\n",
        "!pip install --quiet tf-models-official==2.9.2\n",
        "sys.path.append('PATH_TO_TENSORFLOW_OBJECT_DETECTION_FOLDER')# load all the metadata\n",
        "\n",
        "import tensorflow_models as tfm\n",
        "from tensorflow_models.vision import box_ops as box"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR']='/content/drive/MyDrive/'\n",
        "!kaggle datasets download -d mistag/arthropod-taxonomy-orders-object-detection-dataset\n",
        "!unzip *.zip && rm *.zip"
      ],
      "metadata": {
        "id": "OEQKeqZl8mgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Data Exploring](https://www.kaggle.com/code/mistag/starter-arthropod-taxonomy-orders-data-exploring)\n",
        "\n",
        "The Arthropod Taxonomy Orders dataset is a collection of highres images annotated with labels from the taxanomy rank order. Annotations have been made with VoTT. VoTT stores all metadata in json files. In this kernel we will import all the metadata into DataFrames and export metadata to a variety of formats for object detection model training.\n",
        "The dataset is distributed under CC BY-NC-SA 4.0"
      ],
      "metadata": {
        "id": "uh4YUVG9NG1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "pfiles = glob.glob('/content/ArTaxOr/**/*.vott', recursive=True)\n",
        "\n",
        "df = pd.DataFrame()\n",
        "for p in pfiles:\n",
        "  print(p)\n",
        "  with open(p) as f:\n",
        "    pdata = json.load(f)\n",
        "    # print(pdata)\n",
        "    df = df.append(pd.DataFrame(list(pdata['assets'].values())), ignore_index=True)\n",
        "\n",
        "df['path'] = df['path'].str.replace('file:F:/', '')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MA9dMUdJNyi7",
        "outputId": "ccae1a92-5e60-4a97-fd74-b373a11f9415"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ArTaxOr/Araneae/annotations/Araneae.vott\n",
            "/content/ArTaxOr/Odonata/annotations/Odonata.vott\n",
            "/content/ArTaxOr/Diptera/annotations/Diptera.vott\n",
            "/content/ArTaxOr/Lepidoptera/annotations/Lepidoptera.vott\n",
            "/content/ArTaxOr/Hymenoptera/annotations/Hymenoptera.vott\n",
            "/content/ArTaxOr/Hemiptera/annotations/Hemiptera.vott\n",
            "/content/ArTaxOr/Coleoptera/annotations/Coleoptera.vott\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "OTtv5Gz0btMp",
        "outputId": "826800c4-7a7f-4091-9980-26e2ccc7a36b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      format                                id              name  \\\n",
              "0        jpg  d0469bd539bde1b15b0acf2cd0d87f9d  0019ce6cda02.jpg   \n",
              "1        jpg  679107280d2f692152b436167c164018  003eb3db1665.jpg   \n",
              "2        jpg  f662e6835a6640dce287f3cf5f1373c6  00594c648f4d.jpg   \n",
              "3        jpg  de01228a5521101e5fd9164a1a6cf8cc  007e1a3a7667.jpg   \n",
              "4        jpg  be2462acc54305b1a0a88c69cc17c273  00c50b891171.jpg   \n",
              "...      ...                               ...               ...   \n",
              "15371    jpg  a6b3e0784ae7e7b7217c039594bcca78  ff7ad41ae3f2.jpg   \n",
              "15372    jpg  eb85b2a0363a14b8cd3e92c9c7c6ebf8  ff7f66cd4c82.jpg   \n",
              "15373    jpg  7a368cb2ae24af0a9cc9462477d6d363  ffa8620d4605.jpg   \n",
              "15374    jpg  3b7ecb51a97135974f263b751f3cc1cf  ffb21ba5c537.jpg   \n",
              "15375    jpg  8cc997deb4c8ca46e6d51e86fb04d430  ffc92baca6e4.jpg   \n",
              "\n",
              "                                      path                             size  \\\n",
              "0         ArTaxOr/Araneae/0019ce6cda02.jpg  {'width': 1100, 'height': 1588}   \n",
              "1         ArTaxOr/Araneae/003eb3db1665.jpg   {'width': 1280, 'height': 960}   \n",
              "2         ArTaxOr/Araneae/00594c648f4d.jpg  {'width': 2048, 'height': 1370}   \n",
              "3         ArTaxOr/Araneae/007e1a3a7667.jpg  {'width': 1128, 'height': 1349}   \n",
              "4         ArTaxOr/Araneae/00c50b891171.jpg  {'width': 1344, 'height': 2048}   \n",
              "...                                    ...                              ...   \n",
              "15371  ArTaxOr/Coleoptera/ff7ad41ae3f2.jpg    {'width': 907, 'height': 656}   \n",
              "15372  ArTaxOr/Coleoptera/ff7f66cd4c82.jpg  {'width': 1520, 'height': 1140}   \n",
              "15373  ArTaxOr/Coleoptera/ffa8620d4605.jpg  {'width': 1536, 'height': 2048}   \n",
              "15374  ArTaxOr/Coleoptera/ffb21ba5c537.jpg    {'width': 800, 'height': 593}   \n",
              "15375  ArTaxOr/Coleoptera/ffc92baca6e4.jpg  {'width': 2048, 'height': 1536}   \n",
              "\n",
              "       state  type  \n",
              "0          2     1  \n",
              "1          2     1  \n",
              "2          2     1  \n",
              "3          2     1  \n",
              "4          2     1  \n",
              "...      ...   ...  \n",
              "15371      2     1  \n",
              "15372      2     1  \n",
              "15373      2     1  \n",
              "15374      2     1  \n",
              "15375      2     1  \n",
              "\n",
              "[15376 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-01290dae-f136-4a90-9bd6-9db04abc7f74\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>format</th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>path</th>\n",
              "      <th>size</th>\n",
              "      <th>state</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>jpg</td>\n",
              "      <td>d0469bd539bde1b15b0acf2cd0d87f9d</td>\n",
              "      <td>0019ce6cda02.jpg</td>\n",
              "      <td>ArTaxOr/Araneae/0019ce6cda02.jpg</td>\n",
              "      <td>{'width': 1100, 'height': 1588}</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jpg</td>\n",
              "      <td>679107280d2f692152b436167c164018</td>\n",
              "      <td>003eb3db1665.jpg</td>\n",
              "      <td>ArTaxOr/Araneae/003eb3db1665.jpg</td>\n",
              "      <td>{'width': 1280, 'height': 960}</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>jpg</td>\n",
              "      <td>f662e6835a6640dce287f3cf5f1373c6</td>\n",
              "      <td>00594c648f4d.jpg</td>\n",
              "      <td>ArTaxOr/Araneae/00594c648f4d.jpg</td>\n",
              "      <td>{'width': 2048, 'height': 1370}</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jpg</td>\n",
              "      <td>de01228a5521101e5fd9164a1a6cf8cc</td>\n",
              "      <td>007e1a3a7667.jpg</td>\n",
              "      <td>ArTaxOr/Araneae/007e1a3a7667.jpg</td>\n",
              "      <td>{'width': 1128, 'height': 1349}</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jpg</td>\n",
              "      <td>be2462acc54305b1a0a88c69cc17c273</td>\n",
              "      <td>00c50b891171.jpg</td>\n",
              "      <td>ArTaxOr/Araneae/00c50b891171.jpg</td>\n",
              "      <td>{'width': 1344, 'height': 2048}</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15371</th>\n",
              "      <td>jpg</td>\n",
              "      <td>a6b3e0784ae7e7b7217c039594bcca78</td>\n",
              "      <td>ff7ad41ae3f2.jpg</td>\n",
              "      <td>ArTaxOr/Coleoptera/ff7ad41ae3f2.jpg</td>\n",
              "      <td>{'width': 907, 'height': 656}</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15372</th>\n",
              "      <td>jpg</td>\n",
              "      <td>eb85b2a0363a14b8cd3e92c9c7c6ebf8</td>\n",
              "      <td>ff7f66cd4c82.jpg</td>\n",
              "      <td>ArTaxOr/Coleoptera/ff7f66cd4c82.jpg</td>\n",
              "      <td>{'width': 1520, 'height': 1140}</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15373</th>\n",
              "      <td>jpg</td>\n",
              "      <td>7a368cb2ae24af0a9cc9462477d6d363</td>\n",
              "      <td>ffa8620d4605.jpg</td>\n",
              "      <td>ArTaxOr/Coleoptera/ffa8620d4605.jpg</td>\n",
              "      <td>{'width': 1536, 'height': 2048}</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15374</th>\n",
              "      <td>jpg</td>\n",
              "      <td>3b7ecb51a97135974f263b751f3cc1cf</td>\n",
              "      <td>ffb21ba5c537.jpg</td>\n",
              "      <td>ArTaxOr/Coleoptera/ffb21ba5c537.jpg</td>\n",
              "      <td>{'width': 800, 'height': 593}</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15375</th>\n",
              "      <td>jpg</td>\n",
              "      <td>8cc997deb4c8ca46e6d51e86fb04d430</td>\n",
              "      <td>ffc92baca6e4.jpg</td>\n",
              "      <td>ArTaxOr/Coleoptera/ffc92baca6e4.jpg</td>\n",
              "      <td>{'width': 2048, 'height': 1536}</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15376 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01290dae-f136-4a90-9bd6-9db04abc7f74')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-01290dae-f136-4a90-9bd6-9db04abc7f74 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-01290dae-f136-4a90-9bd6-9db04abc7f74');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = pd.DataFrame(list(pdata['tags']))[:-3]\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "tCBoBkXWUgtJ",
        "outputId": "eea9b26e-e2b7-4109-b8cb-c9b2992c4f8f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          name    color\n",
              "0  Lepidoptera  #5db300\n",
              "1   Coleoptera  #e81123\n",
              "2  Hymenoptera  #6917aa\n",
              "3      Diptera  #015cda\n",
              "4      Araneae  #4894fe\n",
              "5    Hemiptera  #257ffe\n",
              "6      Odonata  #257ffe"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef7d3945-887d-479c-8c05-c6ec99d8d58f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>color</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Lepidoptera</td>\n",
              "      <td>#5db300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Coleoptera</td>\n",
              "      <td>#e81123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hymenoptera</td>\n",
              "      <td>#6917aa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Diptera</td>\n",
              "      <td>#015cda</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Araneae</td>\n",
              "      <td>#4894fe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Hemiptera</td>\n",
              "      <td>#257ffe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Odonata</td>\n",
              "      <td>#257ffe</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef7d3945-887d-479c-8c05-c6ec99d8d58f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ef7d3945-887d-479c-8c05-c6ec99d8d58f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ef7d3945-887d-479c-8c05-c6ec99d8d58f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = 'ArTaxOr/Diptera/fff86b0ae807.jpg'\n",
        "index = p[::-1].find('/')+1\n",
        "p[:-index]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TwxU2QuBjzvE",
        "outputId": "c97c6714-dbe8-40e8-a1f7-2282093d9f57"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ArTaxOr/Diptera'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "anno=pd.DataFrame(columns=['label', 'label_idx', 'xres', 'yres', 'height', 'width', 'left', 'top', \n",
        "                           'right', 'bottom', 'area', 'xcenter', 'ycenter', 'blurred',\n",
        "                           'occluded', 'truncated', 'file', 'id'])\n",
        "\n",
        "\n",
        "#get all the image's annotation details (object data) from a json file and store it in a dataframe\n",
        "for i in range(len(df)):  #15376 images(with details)\n",
        "  p = df['path'][i]\n",
        "  index = p[::-1].find('/')+1\n",
        "  json_file=f'/content/{p[:-index]}/annotations/{df[\"id\"][i]}-asset.json'\n",
        "\n",
        "  if os.path.isfile(json_file):\n",
        "    with open(json_file) as f:\n",
        "      adata = json.load(f)\n",
        "    xres=adata['asset']['size']['width']\n",
        "    yres=adata['asset']['size']['height'] \n",
        "    for j in range(len(adata['regions'])):\n",
        "            h=adata['regions'][j]['boundingBox']['height']/yres\n",
        "            w=adata['regions'][j]['boundingBox']['width']/xres\n",
        "            tags=adata['regions'][j]['tags']\n",
        "            anno=anno.append({'label': tags[0],\n",
        "                              'label_idx': labels[labels.name==tags[0]].index[0],\n",
        "                              'xres': xres,\n",
        "                              'yres': yres,\n",
        "                              'height': h,\n",
        "                              'width': w,                              \n",
        "                              'left': adata['regions'][j]['boundingBox']['left']/xres,\n",
        "                              'top': adata['regions'][j]['boundingBox']['top']/yres,\n",
        "                              'right': adata['regions'][j]['boundingBox']['left']/xres+w,\n",
        "                              'bottom': adata['regions'][j]['boundingBox']['top']/yres+h, \n",
        "                              'area': h*w,\n",
        "                              'xcenter': adata['regions'][j]['boundingBox']['left']/xres+0.5*w,\n",
        "                              'ycenter': adata['regions'][j]['boundingBox']['top']/yres+0.5*h,\n",
        "                              'blurred': int(any(ele == '_blurred' for ele in tags)),\n",
        "                              'occluded': int(any(ele == '_occluded' for ele in tags)),\n",
        "                              'truncated': int(any(ele == '_truncated' for ele in tags)),\n",
        "                              'file': adata['asset']['path'].replace('file:F:/',''),\n",
        "                              'id': adata['asset']['id'],}, ignore_index=True)"
      ],
      "metadata": {
        "id": "HNdMpKItVrll"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anno.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "tvYUXy6PvcEQ",
        "outputId": "4fe9fcb1-2f82-464f-8182-c244282dc770"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             label label_idx  xres  yres    height     width      left  \\\n",
              "17451   Coleoptera         1  1862  1510  0.743295  0.830614  0.028118   \n",
              "12451  Hymenoptera         2  1999  2048  0.498084  0.421001  0.137405   \n",
              "10402  Lepidoptera         0  5184  3456  0.476732  0.430737  0.250172   \n",
              "12377  Hymenoptera         2  2048  1536  0.188697  0.130029  0.587284   \n",
              "8328   Lepidoptera         0  4272  2848  0.385729  0.363887  0.356306   \n",
              "\n",
              "            top     right    bottom      area   xcenter   ycenter blurred  \\\n",
              "17451  0.194444  0.858732  0.937739  0.617391  0.443425  0.566092       0   \n",
              "12451  0.000000  0.558406  0.498084  0.209694  0.347905  0.249042       0   \n",
              "10402  0.391594  0.680910  0.868327  0.205346  0.465541  0.629961       0   \n",
              "12377  0.277778  0.717313  0.466475  0.024536  0.652299  0.372126       0   \n",
              "8328   0.279909  0.720193  0.665638  0.140362  0.538249  0.472773       0   \n",
              "\n",
              "      occluded truncated                                  file  \\\n",
              "17451        0         0   ArTaxOr/Coleoptera/35740cd3ee05.jpg   \n",
              "12451        1         0  ArTaxOr/Hymenoptera/8aa762a85fc8.jpg   \n",
              "10402        0         0  ArTaxOr/Lepidoptera/defe4353a751.jpg   \n",
              "12377        0         0  ArTaxOr/Hymenoptera/85296e576e36.jpg   \n",
              "8328         0         0  ArTaxOr/Lepidoptera/309899c278ac.jpg   \n",
              "\n",
              "                                     id  \n",
              "17451  5c4e0e30ceba0d331a4bd347c6a2b136  \n",
              "12451  6607379d3e9c539148e6e3a0ab052c10  \n",
              "10402  f3e80ac65a66998ec7dca28af96f4169  \n",
              "12377  8c002355e76bb2c8fc07d8b20cc72c07  \n",
              "8328   71f4525fdbda1da4041657bcea0a00c1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d0512f04-b618-4b0d-8382-1bde71cd4517\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>label_idx</th>\n",
              "      <th>xres</th>\n",
              "      <th>yres</th>\n",
              "      <th>height</th>\n",
              "      <th>width</th>\n",
              "      <th>left</th>\n",
              "      <th>top</th>\n",
              "      <th>right</th>\n",
              "      <th>bottom</th>\n",
              "      <th>area</th>\n",
              "      <th>xcenter</th>\n",
              "      <th>ycenter</th>\n",
              "      <th>blurred</th>\n",
              "      <th>occluded</th>\n",
              "      <th>truncated</th>\n",
              "      <th>file</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17451</th>\n",
              "      <td>Coleoptera</td>\n",
              "      <td>1</td>\n",
              "      <td>1862</td>\n",
              "      <td>1510</td>\n",
              "      <td>0.743295</td>\n",
              "      <td>0.830614</td>\n",
              "      <td>0.028118</td>\n",
              "      <td>0.194444</td>\n",
              "      <td>0.858732</td>\n",
              "      <td>0.937739</td>\n",
              "      <td>0.617391</td>\n",
              "      <td>0.443425</td>\n",
              "      <td>0.566092</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ArTaxOr/Coleoptera/35740cd3ee05.jpg</td>\n",
              "      <td>5c4e0e30ceba0d331a4bd347c6a2b136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12451</th>\n",
              "      <td>Hymenoptera</td>\n",
              "      <td>2</td>\n",
              "      <td>1999</td>\n",
              "      <td>2048</td>\n",
              "      <td>0.498084</td>\n",
              "      <td>0.421001</td>\n",
              "      <td>0.137405</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.558406</td>\n",
              "      <td>0.498084</td>\n",
              "      <td>0.209694</td>\n",
              "      <td>0.347905</td>\n",
              "      <td>0.249042</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>ArTaxOr/Hymenoptera/8aa762a85fc8.jpg</td>\n",
              "      <td>6607379d3e9c539148e6e3a0ab052c10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10402</th>\n",
              "      <td>Lepidoptera</td>\n",
              "      <td>0</td>\n",
              "      <td>5184</td>\n",
              "      <td>3456</td>\n",
              "      <td>0.476732</td>\n",
              "      <td>0.430737</td>\n",
              "      <td>0.250172</td>\n",
              "      <td>0.391594</td>\n",
              "      <td>0.680910</td>\n",
              "      <td>0.868327</td>\n",
              "      <td>0.205346</td>\n",
              "      <td>0.465541</td>\n",
              "      <td>0.629961</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ArTaxOr/Lepidoptera/defe4353a751.jpg</td>\n",
              "      <td>f3e80ac65a66998ec7dca28af96f4169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12377</th>\n",
              "      <td>Hymenoptera</td>\n",
              "      <td>2</td>\n",
              "      <td>2048</td>\n",
              "      <td>1536</td>\n",
              "      <td>0.188697</td>\n",
              "      <td>0.130029</td>\n",
              "      <td>0.587284</td>\n",
              "      <td>0.277778</td>\n",
              "      <td>0.717313</td>\n",
              "      <td>0.466475</td>\n",
              "      <td>0.024536</td>\n",
              "      <td>0.652299</td>\n",
              "      <td>0.372126</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ArTaxOr/Hymenoptera/85296e576e36.jpg</td>\n",
              "      <td>8c002355e76bb2c8fc07d8b20cc72c07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8328</th>\n",
              "      <td>Lepidoptera</td>\n",
              "      <td>0</td>\n",
              "      <td>4272</td>\n",
              "      <td>2848</td>\n",
              "      <td>0.385729</td>\n",
              "      <td>0.363887</td>\n",
              "      <td>0.356306</td>\n",
              "      <td>0.279909</td>\n",
              "      <td>0.720193</td>\n",
              "      <td>0.665638</td>\n",
              "      <td>0.140362</td>\n",
              "      <td>0.538249</td>\n",
              "      <td>0.472773</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ArTaxOr/Lepidoptera/309899c278ac.jpg</td>\n",
              "      <td>71f4525fdbda1da4041657bcea0a00c1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d0512f04-b618-4b0d-8382-1bde71cd4517')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d0512f04-b618-4b0d-8382-1bde71cd4517 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d0512f04-b618-4b0d-8382-1bde71cd4517');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sns.relplot(x=\"width\", y=\"height\", hue=\"label\", col=\"label\", data=anno)"
      ],
      "metadata": {
        "id": "g1OwH8uBvv8C"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sns.jointplot(x='width', y='height', data=anno.loc[anno['label'] == 'Diptera'])"
      ],
      "metadata": {
        "id": "ZrfImW5uZyW2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(rc={'figure.figsize': (12,6)})\n",
        "# sns.violinplot(x=anno['label'], y=anno['area'])"
      ],
      "metadata": {
        "id": "vvZl1B14aIE_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# graph=sns.countplot(data=anno, x='label')\n",
        "# graph.set_xticklabels(graph.get_xticklabels(), rotation=90)\n",
        "\n",
        "# for p in graph.patches:\n",
        "#   height = p.get_height()\n",
        "#   graph.text(p.get_x() + p.get_width()/2, height + 0.1, height, ha='center')"
      ],
      "metadata": {
        "id": "V-8gzBGdbCtd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp = 'truncated'\n",
        "df2 = anno[['label', temp]]\n",
        "df2 = df2.loc[df2[temp] == 1]\n",
        "# sns.countplot(x=temp, hue='label', data=df2)"
      ],
      "metadata": {
        "id": "hNxAAUNhkPfH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp = 'blurred'\n",
        "df2 = anno[['label', temp]]\n",
        "df2 = df2.loc[df2[temp] == 1]\n",
        "# sns.countplot(x=temp, hue='label', data=df2)"
      ],
      "metadata": {
        "id": "wuVHit5UnaYe"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp = 'occluded'\n",
        "df2 = anno[['label', temp]]\n",
        "df2 = df2.loc[df2[temp] == 1]\n",
        "# sns.countplot(x=temp, hue='label', data=df2)"
      ],
      "metadata": {
        "id": "dUemf28wqjCO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image exploration\n"
      ],
      "metadata": {
        "id": "OUTSAYdXquv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def attribution(fname):\n",
        "    img = Image.open(fname)\n",
        "    exif_data = img._getexif()\n",
        "    img.close()\n",
        "    if len(exif_data[315]) > 0:\n",
        "        s='Photo: '+exif_data[315]\n",
        "    else:\n",
        "        s=exif_data[37510][8:].decode('ascii')\n",
        "    return s\n",
        "\n",
        "def plot_img(axes, image_df, highlight=True):\n",
        "    image_file_name='/content/'+image_df.iloc[0].file\n",
        "    im = Image.open(image_file_name)\n",
        "    im.thumbnail((300,300),Image.ANTIALIAS)  #A small image representation of a larger image\n",
        "    draw = ImageDraw.Draw(im)\n",
        "    xres, yres = im.size[0], im.size[1] # X, Y Resolution\n",
        "    for i in range(len(image_df)):\n",
        "        selected_img = image_df.iloc[i]\n",
        "        if highlight==True:\n",
        "            color=(255, 0, 0) if i == 0 else (128, 128, 128)          \n",
        "        else:\n",
        "            color=labels[labels.name == selected_img.label].color.iloc[0]\n",
        "        \n",
        "        #draw a boundingbox\n",
        "        draw.rectangle([int(selected_img['left']*xres),\n",
        "                        int(selected_img['top']*yres),\n",
        "                        int(selected_img['right']*xres),\n",
        "                        int(selected_img['bottom']*yres)], outline=color, width=2)\n",
        "        \n",
        "    plt.setp(axes, xticks=[], yticks=[])  #remove the grids\n",
        "    axes.set_title(image_df.iloc[0].label+'\\n'+attribution(image_file_name))\n",
        "    plt.imshow(im)"
      ],
      "metadata": {
        "id": "cTqGpMM6qrMC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(16,26))\n",
        "for i in range(len(labels)):\n",
        "  for j in range(3):\n",
        "    #Select 3 images with the largest area\n",
        "    # ldf=anno[anno.label == labels.name[i]].nlargest(3, 'area') \n",
        "\n",
        "    #Select images with the most objects\n",
        "    a=anno[anno.label == labels.name[i]]['id'].value_counts()\n",
        "    ldf=anno[anno.id == a.index[j]]\n",
        "    # axes = fig.add_subplot(len(labels), 3, 1+i*3+j)\n",
        "    # plot_img(axes, anno[anno.id == ldf.iloc[j].id].sort_values(by=['area'], ascending=False), highlight=False)"
      ],
      "metadata": {
        "id": "j4_spNIJwy07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "7fcef90f-df5a-4ccb-f3fe-2c27875e1a28"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x1872 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metadata export\n",
        "\n",
        "export metadata to various formats for object detection model training\n"
      ],
      "metadata": {
        "id": "6uLxEYlyUPis"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CSV"
      ],
      "metadata": {
        "id": "d-EQjAKHVgjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "header = ['file', 'label', 'height', 'width', 'left', 'top', 'right', 'bottom'] # change as required\n",
        "anno.to_csv('./ArTaxOr.csv', index=False, columns = header) "
      ],
      "metadata": {
        "id": "A3AEp6QfTDhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pascal VOC\n",
        "\n",
        "Pascal VOC files are xml format, and there is one xml file per image file, with same name."
      ],
      "metadata": {
        "id": "VpTPyLRSWrCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!{sys.executable} -m pip install pascal_voc_writer\n",
        "from pascal_voc_writer import Writer\n",
        "\n",
        "if not os.path.exists('voc'):\n",
        "    os.mkdir('voc')\n",
        "\n",
        "for i in range(len(df)):\n",
        "    ldf=anno[anno.id == df.id[i]].reset_index()\n",
        "    p=df.path[i].split('/')\n",
        "    image_xml = p[2].replace('.jpg','.xml') \n",
        "    width, height = ldf.xres[0], ldf.yres[0]\n",
        "    \n",
        "    writer = Writer(df.path[i], width, height)\n",
        "    for j in range(len(ldf)):\n",
        "        writer.addObject(ldf.label[j], \n",
        "                         int(ldf.left[j]*width), \n",
        "                         int(ldf.top[j]*height), \n",
        "                         int(ldf.right[j]*width),\n",
        "                         int(ldf.bottom[j]*height))\n",
        "    writer.save(f'./voc/{image_xml}')\n",
        "# print(os.listdir(\"./voc\"))"
      ],
      "metadata": {
        "id": "S-dahuQxWQSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85892247-89da-4aa1-9c5d-7756c46d4033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pascal_voc_writer\n",
            "  Downloading pascal_voc_writer-0.1.4-py2.py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from pascal_voc_writer) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->pascal_voc_writer) (2.0.1)\n",
            "Installing collected packages: pascal-voc-writer\n",
            "Successfully installed pascal-voc-writer-0.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Darknet YOLOv3\n",
        "Darknet expects one annotation file per image file. Each object is described by:\n",
        "\n",
        "`class x_center y_center width height`"
      ],
      "metadata": {
        "id": "diAfMmX1YRU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('labels'):\n",
        "    os.mkdir('labels')\n",
        "\n",
        "for i in range(len(df)):\n",
        "    ldf=anno[anno.id == df.id[i]].reset_index()\n",
        "    p=df.path[i].split('/') \n",
        "    image_txt = p[2].replace('.jpg','.txt') \n",
        "    \n",
        "    file=open(f'./labels/{image_txt}','w')\n",
        "    for j in range(len(ldf)):\n",
        "        label_name=labels[labels.name == ldf.label[j]].index.to_list()\n",
        "        file.write(f'{label_name[0]} {ldf.xcenter[j]} {ldf.ycenter[j]} {ldf.width[j]} {ldf.height[j]}\\n')\n",
        "    file.close()\n",
        "# print(os.listdir(\"./labels\"))"
      ],
      "metadata": {
        "id": "l4nM9T5oXSu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pickle"
      ],
      "metadata": {
        "id": "KarV4t5uZUUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels.to_pickle('./ArTaxOr_labels.pkl')\n",
        "df.to_pickle('./ArTaxOr_filelist.pkl')\n",
        "anno.to_pickle('./ArTaxOr_objects.pkl')"
      ],
      "metadata": {
        "id": "DExR1xN-ZlIW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [TensorFlow TFRecords](https://www.kaggle.com/code/mistag/tensorflow-tfrecords-demystified/notebook)"
      ],
      "metadata": {
        "id": "8BcSEkLQZtVD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Protocol buffers\n",
        "TFRecords are Protocol buffers. Protocol buffers are a way of serializing structured data in a compact and efficient way. A Protocol buffer message is defined by a .proto file. Example:\n",
        "\n",
        "```\n",
        "syntax = \"proto3\"; // define protocol version\n",
        "\n",
        "// Define \"Employee\" message with 3 fields\n",
        "message Employee {\n",
        " string name = 1; // a unique number is assigned to each field\n",
        " int32 company_id = 2;\n",
        " string address = 3;\n",
        "}\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "A single .proto-file can define multiple messages and messages can be nested. The beauty of protocol buffers is that the .proto-files can be compiled into a library (language of choice) with access functions using the protoc compiler. But for TFRecords the access functions we need are already part of TensorFlow, so no need to worry about compiling .proto files."
      ],
      "metadata": {
        "id": "sB9A-jiU--T_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TFRecord format with simple data\n",
        "TFRecords are made to support just about any type of data, and that means nesting basic features into a hierarchy of features.TFRecords supports only three different data types:\n",
        "\n",
        "bytes\n",
        "float\n",
        "int64\n",
        "\n",
        "So any data must be converted into one of these three types."
      ],
      "metadata": {
        "id": "SMeqEluCXpPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.train.Feature can be used to convert data into lists of these types.\n",
        "int_list = tf.train.Feature(int64_list=tf.train.Int64List(value=np.arange(8)))\n",
        "int_list"
      ],
      "metadata": {
        "id": "oxSVjC42ZnKK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09f56306-ac60-4712-bf85-bdb3a34bc583"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "int64_list {\n",
              "  value: 0\n",
              "  value: 1\n",
              "  value: 2\n",
              "  value: 3\n",
              "  value: 4\n",
              "  value: 5\n",
              "  value: 6\n",
              "  value: 7\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float_list = tf.train.Feature(float_list=tf.train.FloatList(value=np.random.rand(10)))\n",
        "float_list"
      ],
      "metadata": {
        "id": "38YowPsCYFF7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abc351ed-2c85-401e-b2d6-ec2e72a8b76b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "float_list {\n",
              "  value: 0.6677202582359314\n",
              "  value: 0.527971625328064\n",
              "  value: 0.04802408441901207\n",
              "  value: 0.578150749206543\n",
              "  value: 0.7106977105140686\n",
              "  value: 0.19086655974388123\n",
              "  value: 0.11398348212242126\n",
              "  value: 0.5690155625343323\n",
              "  value: 0.9284249544143677\n",
              "  value: 0.8978065252304077\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bytes_list = tf.train.Feature(bytes_list=tf.train.BytesList(value=['hello, my name is Esmail'.encode()]))\n",
        "bytes_list"
      ],
      "metadata": {
        "id": "su4O4azoZWlh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d64b54ff-6847-454a-827c-e49c7875a119"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bytes_list {\n",
              "  value: \"hello, my name is Esmail\"\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = tf.train.Features(feature={\n",
        "    'integers': int_list,\n",
        "    'float': float_list,\n",
        "    'description': bytes_list\n",
        "})\n",
        "features"
      ],
      "metadata": {
        "id": "WxVEf1nzaK9O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42ea7ec9-20b0-41e9-ca0a-3a073b322223"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "feature {\n",
              "  key: \"description\"\n",
              "  value {\n",
              "    bytes_list {\n",
              "      value: \"hello, my name is Esmail\"\n",
              "    }\n",
              "  }\n",
              "}\n",
              "feature {\n",
              "  key: \"float\"\n",
              "  value {\n",
              "    float_list {\n",
              "      value: 0.6677202582359314\n",
              "      value: 0.527971625328064\n",
              "      value: 0.04802408441901207\n",
              "      value: 0.578150749206543\n",
              "      value: 0.7106977105140686\n",
              "      value: 0.19086655974388123\n",
              "      value: 0.11398348212242126\n",
              "      value: 0.5690155625343323\n",
              "      value: 0.9284249544143677\n",
              "      value: 0.8978065252304077\n",
              "    }\n",
              "  }\n",
              "}\n",
              "feature {\n",
              "  key: \"integers\"\n",
              "  value {\n",
              "    int64_list {\n",
              "      value: 0\n",
              "      value: 1\n",
              "      value: 2\n",
              "      value: 3\n",
              "      value: 4\n",
              "      value: 5\n",
              "      value: 6\n",
              "      value: 7\n",
              "    }\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last step is to create an example TFRecord. So, example is not a very good name, but that is what the TFRecord is called. We simply pass the list of features to `tf.train.Example.`"
      ],
      "metadata": {
        "id": "iL5fblsigNLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf_record = tf.train.Example(features=features)\n",
        "tf_record"
      ],
      "metadata": {
        "id": "gkXwCv8ec_4G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03e86f0b-f517-41cf-ddd7-b13db6872cf1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "features {\n",
              "  feature {\n",
              "    key: \"description\"\n",
              "    value {\n",
              "      bytes_list {\n",
              "        value: \"hello, my name is Esmail\"\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  feature {\n",
              "    key: \"float\"\n",
              "    value {\n",
              "      float_list {\n",
              "        value: 0.6677202582359314\n",
              "        value: 0.527971625328064\n",
              "        value: 0.04802408441901207\n",
              "        value: 0.578150749206543\n",
              "        value: 0.7106977105140686\n",
              "        value: 0.19086655974388123\n",
              "        value: 0.11398348212242126\n",
              "        value: 0.5690155625343323\n",
              "        value: 0.9284249544143677\n",
              "        value: 0.8978065252304077\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  feature {\n",
              "    key: \"integers\"\n",
              "    value {\n",
              "      int64_list {\n",
              "        value: 0\n",
              "        value: 1\n",
              "        value: 2\n",
              "        value: 3\n",
              "        value: 4\n",
              "        value: 5\n",
              "        value: 6\n",
              "        value: 7\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " write this record to a file using tf.io.TFRecordWriter"
      ],
      "metadata": {
        "id": "MZBifcLJ4-CS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fname='example1.tfrecord'\n",
        "with tf.io.TFRecordWriter(fname) as writer:\n",
        "    writer.write(tf_record.SerializeToString())\n",
        "print(f\"Size of {fname} is {os.path.getsize(fname)} bytes\")"
      ],
      "metadata": {
        "id": "DLf1E-bQgPvi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97d3df9b-cccc-42a4-8388-68c6b5aa9ec6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of example1.tfrecord is 144 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, read the file back in and access the data using tf.data.TFRecordDataset and tf.train.Example.FromString:"
      ],
      "metadata": {
        "id": "givAS1jm5Dc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.TFRecordDataset(fname)\n",
        "raw_example = next(iter(dataset))\n",
        "parsed = tf.train.Example.FromString(raw_example.numpy())\n",
        "parsed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5H0myY2JwZJD",
        "outputId": "588f78c1-2ca3-4c98-cf8e-b0c1d7e8cec5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "features {\n",
              "  feature {\n",
              "    key: \"description\"\n",
              "    value {\n",
              "      bytes_list {\n",
              "        value: \"hello, my name is Esmail\"\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  feature {\n",
              "    key: \"float\"\n",
              "    value {\n",
              "      float_list {\n",
              "        value: 0.6677202582359314\n",
              "        value: 0.527971625328064\n",
              "        value: 0.04802408441901207\n",
              "        value: 0.578150749206543\n",
              "        value: 0.7106977105140686\n",
              "        value: 0.19086655974388123\n",
              "        value: 0.11398348212242126\n",
              "        value: 0.5690155625343323\n",
              "        value: 0.9284249544143677\n",
              "        value: 0.8978065252304077\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  feature {\n",
              "    key: \"integers\"\n",
              "    value {\n",
              "      int64_list {\n",
              "        value: 0\n",
              "        value: 1\n",
              "        value: 2\n",
              "        value: 3\n",
              "        value: 4\n",
              "        value: 5\n",
              "        value: 6\n",
              "        value: 7\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Access each feature using `parsed.features.feature['<feature name>']`\n",
        "\n"
      ],
      "metadata": {
        "id": "eEro0qp95vEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parsed.features.feature['description'].bytes_list.value[0].decode()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "s4r9_43_5frG",
        "outputId": "240141e7-b6b8-4c11-fcfb-6f3bc53eeb4f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hello, my name is Esmail'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parsed.features.feature['integers'].int64_list.value[:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ty5AdvZ26XAV",
        "outputId": "7cbfedaa-04e2-47b4-b3dc-7a1606822b06"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 5, 6, 7]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parsed.features.feature['float'].float_list.value[:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G79upiYD6veC",
        "outputId": "7af8e45f-e2cc-4da9-caf2-059c74fb8977"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6677202582359314,\n",
              " 0.527971625328064,\n",
              " 0.04802408441901207,\n",
              " 0.578150749206543,\n",
              " 0.7106977105140686,\n",
              " 0.19086655974388123,\n",
              " 0.11398348212242126,\n",
              " 0.5690155625343323,\n",
              " 0.9284249544143677,\n",
              " 0.8978065252304077]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TFRecords with image data\n",
        "\n",
        "To make input function efficient, all preprocessing steps should be performed when creating TFRecords, otherwise the input function must repeat preprocessing each time the training passed over the TFRecord. Typical preprocessing steps are:\n",
        "\n",
        "#### Decode image from jpg etc.\n",
        "#### Resize image\n",
        "#### Convert to float\n",
        "#### Normalize to [0,1] range\n",
        "\n",
        "Augumentation is not something to do in a TFRecord, since agumentation could be different each time training passes over the data"
      ],
      "metadata": {
        "id": "tdVicXz7zYqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "from io import BytesIO\n",
        "from PIL import Image, ImageFont, ImageDraw\n",
        "ARTAXOR_PATH = '/content/'\n",
        "\n",
        "pickles='/content/'\n",
        "objectdf=pd.read_pickle(pickles+'ArTaxOr_objects.pkl')\n",
        "labels=pd.read_pickle(pickles+'ArTaxOr_labels.pkl')\n",
        "objectdf.sample(5)"
      ],
      "metadata": {
        "id": "7vpbCIhX7435",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "a172d184-2c60-4e9d-fdb1-75d766316b5d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             label label_idx  xres  yres    height     width      left  \\\n",
              "2768       Odonata         6  2047  1399  0.441978  0.360690  0.442759   \n",
              "17886   Coleoptera         1  1451  2048  0.565134  0.705405  0.212627   \n",
              "3813       Odonata         6  2048  1365  0.929907  0.857217  0.024013   \n",
              "11322  Hymenoptera         2  1312  1056  0.272989  0.348497  0.316921   \n",
              "9048   Lepidoptera         0  4272  2848  0.455016  0.299104  0.090283   \n",
              "\n",
              "            top     right    bottom      area   xcenter   ycenter blurred  \\\n",
              "2768   0.235621  0.803448  0.677598  0.159417  0.623103  0.456609       0   \n",
              "17886  0.219349  0.918032  0.784483  0.398649  0.565329  0.501916       0   \n",
              "3813   0.070093  0.881231  1.000000  0.797132  0.452622  0.535047       0   \n",
              "11322  0.294061  0.665418  0.567050  0.095136  0.491170  0.430556       0   \n",
              "9048   0.338854  0.389387  0.793870  0.136097  0.239835  0.566362       0   \n",
              "\n",
              "      occluded truncated                                  file  \\\n",
              "2768         0         0      ArTaxOr/Odonata/3dfb0b15d471.jpg   \n",
              "17886        0         0   ArTaxOr/Coleoptera/59d7c2c9c772.jpg   \n",
              "3813         1         1      ArTaxOr/Odonata/8b9055492e62.jpg   \n",
              "11322        0         0  ArTaxOr/Hymenoptera/2e8b57f68c5e.jpg   \n",
              "9048         0         0  ArTaxOr/Lepidoptera/7899b796e05b.jpg   \n",
              "\n",
              "                                     id  \n",
              "2768   5c9df99a1658f495cec1ae11c1dd49c0  \n",
              "17886  2d22cb18d6ccd58db98a406c45243d35  \n",
              "3813   44fd20c34f64c4b6e5b27c3c9cd3baa5  \n",
              "11322  d4f20504e7b2fb0351896ad91cdf4ae8  \n",
              "9048   d7ef598f897f3dc6bf86d2341ef27e58  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d815d5fe-e42f-4538-bb8c-819162486eb4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>label_idx</th>\n",
              "      <th>xres</th>\n",
              "      <th>yres</th>\n",
              "      <th>height</th>\n",
              "      <th>width</th>\n",
              "      <th>left</th>\n",
              "      <th>top</th>\n",
              "      <th>right</th>\n",
              "      <th>bottom</th>\n",
              "      <th>area</th>\n",
              "      <th>xcenter</th>\n",
              "      <th>ycenter</th>\n",
              "      <th>blurred</th>\n",
              "      <th>occluded</th>\n",
              "      <th>truncated</th>\n",
              "      <th>file</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2768</th>\n",
              "      <td>Odonata</td>\n",
              "      <td>6</td>\n",
              "      <td>2047</td>\n",
              "      <td>1399</td>\n",
              "      <td>0.441978</td>\n",
              "      <td>0.360690</td>\n",
              "      <td>0.442759</td>\n",
              "      <td>0.235621</td>\n",
              "      <td>0.803448</td>\n",
              "      <td>0.677598</td>\n",
              "      <td>0.159417</td>\n",
              "      <td>0.623103</td>\n",
              "      <td>0.456609</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ArTaxOr/Odonata/3dfb0b15d471.jpg</td>\n",
              "      <td>5c9df99a1658f495cec1ae11c1dd49c0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17886</th>\n",
              "      <td>Coleoptera</td>\n",
              "      <td>1</td>\n",
              "      <td>1451</td>\n",
              "      <td>2048</td>\n",
              "      <td>0.565134</td>\n",
              "      <td>0.705405</td>\n",
              "      <td>0.212627</td>\n",
              "      <td>0.219349</td>\n",
              "      <td>0.918032</td>\n",
              "      <td>0.784483</td>\n",
              "      <td>0.398649</td>\n",
              "      <td>0.565329</td>\n",
              "      <td>0.501916</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ArTaxOr/Coleoptera/59d7c2c9c772.jpg</td>\n",
              "      <td>2d22cb18d6ccd58db98a406c45243d35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3813</th>\n",
              "      <td>Odonata</td>\n",
              "      <td>6</td>\n",
              "      <td>2048</td>\n",
              "      <td>1365</td>\n",
              "      <td>0.929907</td>\n",
              "      <td>0.857217</td>\n",
              "      <td>0.024013</td>\n",
              "      <td>0.070093</td>\n",
              "      <td>0.881231</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.797132</td>\n",
              "      <td>0.452622</td>\n",
              "      <td>0.535047</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>ArTaxOr/Odonata/8b9055492e62.jpg</td>\n",
              "      <td>44fd20c34f64c4b6e5b27c3c9cd3baa5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11322</th>\n",
              "      <td>Hymenoptera</td>\n",
              "      <td>2</td>\n",
              "      <td>1312</td>\n",
              "      <td>1056</td>\n",
              "      <td>0.272989</td>\n",
              "      <td>0.348497</td>\n",
              "      <td>0.316921</td>\n",
              "      <td>0.294061</td>\n",
              "      <td>0.665418</td>\n",
              "      <td>0.567050</td>\n",
              "      <td>0.095136</td>\n",
              "      <td>0.491170</td>\n",
              "      <td>0.430556</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ArTaxOr/Hymenoptera/2e8b57f68c5e.jpg</td>\n",
              "      <td>d4f20504e7b2fb0351896ad91cdf4ae8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9048</th>\n",
              "      <td>Lepidoptera</td>\n",
              "      <td>0</td>\n",
              "      <td>4272</td>\n",
              "      <td>2848</td>\n",
              "      <td>0.455016</td>\n",
              "      <td>0.299104</td>\n",
              "      <td>0.090283</td>\n",
              "      <td>0.338854</td>\n",
              "      <td>0.389387</td>\n",
              "      <td>0.793870</td>\n",
              "      <td>0.136097</td>\n",
              "      <td>0.239835</td>\n",
              "      <td>0.566362</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ArTaxOr/Lepidoptera/7899b796e05b.jpg</td>\n",
              "      <td>d7ef598f897f3dc6bf86d2341ef27e58</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d815d5fe-e42f-4538-bb8c-819162486eb4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d815d5fe-e42f-4538-bb8c-819162486eb4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d815d5fe-e42f-4538-bb8c-819162486eb4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a function that creates a tf.train.Example from an image and the objects contained within.\n",
        "\n",
        "    Note that TensorFlow Object Detection API expects jpeg-encoded image data\n",
        "\n",
        ", so the only preprocessing to be done is resize (optional) before the image is re-encoded (via a memory buffer using BytesIO).\n",
        "\n",
        "\n",
        "The input to this function is a DataFrame that contains one row per object and the columns shown above. This record is generous with features, but that is to make sure that the TF Object Detection API will successfully run the evaluation phase during training."
      ],
      "metadata": {
        "id": "PvLRW9vVhCY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch attribution string from image EXIF data\n",
        "def get_attribution(file):\n",
        "    with Image.open(file) as img:\n",
        "        exif_data = img._getexif()\n",
        "    \n",
        "    source ='Photo: unknown'\n",
        "    if exif_data is not None:\n",
        "        if 37510 in exif_data and len(exif_data[37510]) > 0:\n",
        "            source = exif_data[37510][8:].decode('ascii')\n",
        "        if 315 in exif_data and len(exif_data[315]) > 0:\n",
        "            source = 'Photo: ' + exif_data[315]\n",
        "    return source\n",
        "\n",
        "# Create example for TensorFlow Object Detection API\n",
        "def create_tf_example(imagedf, longest_edge=1024):  \n",
        "    fname = ARTAXOR_PATH+imagedf.file.iloc[0]  #exclude image path \n",
        "    filename=fname.split('/')[-1]              #exclude image name\n",
        "    by = get_attribution(fname)                #exclude EXIF data\n",
        "    img = Image.open(fname, \"r\")\n",
        "\n",
        "    # resize image if larger that longest edge while keeping aspect ratio\n",
        "    if max(img.size) > longest_edge:\n",
        "        img.thumbnail((longest_edge, longest_edge), Image.ANTIALIAS)\n",
        "    \n",
        "    width, height = img.size #(w, h)\n",
        "\n",
        "    buf= BytesIO()\n",
        "    img.save(buf, format= 'JPEG') # encode to jpeg in memory\n",
        "    encoded_image_data= buf.getvalue()\n",
        "    image_format = b'jpeg'\n",
        "    \n",
        "    source_id = filename.split('.')[0]\n",
        "    license = 'CC BY-NC-SA 4.0'\n",
        "    # A hash of the image is used in some frameworks\n",
        "    key = hashlib.sha256(encoded_image_data).hexdigest() \n",
        "\n",
        "    # object bounding boxes \n",
        "    # List of normalized coordinates in bounding box (1 per box)\n",
        "    xmins, xmaxs, ymins, ymaxs = imagedf[['left', 'right', 'top', 'bottom']].values.T\n",
        "\n",
        "    # List of string class name & id of bounding box (1 per box)\n",
        "    object_count = len(imagedf)\n",
        "    classes_text = []\n",
        "    classes = []\n",
        "    for i in range(object_count):\n",
        "        classes_text.append(imagedf.label.iloc[i].encode())\n",
        "        classes.append(1 + imagedf.label_idx.iloc[i])\n",
        "\n",
        "    #??????????????????????????????????????????????????????????????????\n",
        "    \n",
        "    # unused features from Open Image \n",
        "    depiction = np.zeros(object_count, dtype=int)\n",
        "    group_of = np.zeros(object_count, dtype=int)\n",
        "    occluded = imagedf.occluded.values #also Pascal VOC\n",
        "    truncated = imagedf.truncated.values # also Pascal VOC\n",
        "\n",
        "\n",
        "    # Pascal VOC\n",
        "    view_text = []\n",
        "    for i in range(object_count):\n",
        "        view_text.append('frontal'.encode())\n",
        "    difficult = np.zeros(object_count, dtype=int)\n",
        "\n",
        "    tf_record = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'image/height': tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n",
        "        'image/width': tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n",
        "        'image/filename': tf.train.Feature(bytes_list=tf.train.BytesList(value=[filename.encode()])),\n",
        "        'image/source_id': tf.train.Feature(bytes_list=tf.train.BytesList(value=[source_id.encode()])),\n",
        "        'image/license': tf.train.Feature(bytes_list=tf.train.BytesList(value=[license.encode()])),\n",
        "        'image/by': tf.train.Feature(bytes_list=tf.train.BytesList(value=[by.encode()])),\n",
        "        'image/encoded': tf.train.Feature(bytes_list=tf.train.BytesList(value=[encoded_image_data])),\n",
        "        'image/key/sha256': tf.train.Feature(bytes_list=tf.train.BytesList(value=[key.encode()])),\n",
        "        'image/format': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_format])),\n",
        "        'image/object/bbox/xmin': tf.train.Feature(float_list=tf.train.FloatList(value=xmins)),\n",
        "        'image/object/bbox/xmax': tf.train.Feature(float_list=tf.train.FloatList(value=xmaxs)),\n",
        "        'image/object/bbox/ymin': tf.train.Feature(float_list=tf.train.FloatList(value=ymins)),\n",
        "        'image/object/bbox/ymax': tf.train.Feature(float_list=tf.train.FloatList(value=ymaxs)),\n",
        "        'image/object/class/text': tf.train.Feature(bytes_list=tf.train.BytesList(value=classes_text)),\n",
        "        'image/object/class/label': tf.train.Feature(int64_list=tf.train.Int64List(value=classes)),\n",
        "        'image/object/depiction': tf.train.Feature(int64_list=tf.train.Int64List(value=depiction)),\n",
        "        'image/object/group_of': tf.train.Feature(int64_list=tf.train.Int64List(value=group_of)),\n",
        "        'image/object/occluded': tf.train.Feature(int64_list=tf.train.Int64List(value=occluded)),\n",
        "        'image/object/truncated': tf.train.Feature(int64_list=tf.train.Int64List(value=truncated)),\n",
        "        'image/object/difficult': tf.train.Feature(int64_list=tf.train.Int64List(value=difficult)),\n",
        "        'image/object/view': tf.train.Feature(bytes_list=tf.train.BytesList(value=view_text))\n",
        "    }))\n",
        "    return tf_record"
      ],
      "metadata": {
        "id": "1OoKPnsXPrxy"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#An Example of creating tf record\n",
        "sample_file='ArTaxOr/Hemiptera/00600a41bcaf.jpg'\n",
        "imagedf=objectdf[objectdf.file == sample_file]\n",
        "tfr=create_tf_example(imagedf)\n",
        "# print(tfr)\n",
        "fname='./image_ex1.tfrecord'\n",
        "with tf.io.TFRecordWriter(fname) as writer:\n",
        "    writer.write(tfr.SerializeToString())\n",
        "print(f\"Size of {fname} is {fname, os.path.getsize(fname)//1024} kbytes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9Dd10e-iYxc",
        "outputId": "bb19696b-481d-4cc1-b0be-4ecd6bb33fe9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of ./image_ex1.tfrecord is ('./image_ex1.tfrecord', 95) kbytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "load back in and visualize the Tensordlow records contents."
      ],
      "metadata": {
        "id": "NdKTo6vbEa4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "font = ImageFont.load_default()\n",
        "def bbox(img, xmin, ymin, xmax, ymax, color, width, label, score):\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    xres, yres = img.size  #(w, h)\n",
        "\n",
        "    #box[0] = xmin*xres\n",
        "    box = np.multiply([xmin, ymin, xmax, ymax], [xres, yres, xres, yres]).astype(int).tolist()\n",
        "\n",
        "    txt = f\" {label}: {round(score, 1)}\" if score >= 0. else f\" {label}\"\n",
        "    ts = draw.textsize(txt, font=ImageFont.load_default())\n",
        "    draw.rectangle(box, outline=color, width=width)\n",
        "\n",
        "    #######????????    \n",
        "    if len(label) > 0:\n",
        "        if box[1] >= ts[1]+3:\n",
        "            xsmin, ysmin = box[0],                box[1]-ts[1]-3\n",
        "            xsmax, ysmax = box[0] + ts[0] + 2,    box[1]\n",
        "        else:\n",
        "            xsmin, ysmin = box[0],               box[3]\n",
        "            xsmax, ysmax = box[0] + ts[0] + 2,   box[3] + ts[1] + 1\n",
        "            \n",
        "        draw.rectangle([xsmin, ysmin, xsmax, ysmax], fill=color)\n",
        "        draw.text((xsmin, ysmin), txt, font=font, fill='white')"
      ],
      "metadata": {
        "id": "_XxpRUOD1TNk"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_img(img, axes, xmin, ymin, xmax, ymax, classes, class_label, by):\n",
        "    for i in range(len(xmin)):\n",
        "        color=labels.color[class_label[i]-1]\n",
        "        bbox(img, xmin[i], ymin[i], xmax[i], ymax[i], color, 5, classes[i].decode(), -1)\n",
        "    plt.setp(axes, xticks=[], yticks=[])\n",
        "    axes.set_title(by)\n",
        "    plt.imshow(img)"
      ],
      "metadata": {
        "id": "5dPclDgW1VYY"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load tfrecord\n",
        "fname='image_ex1.tfrecord'\n",
        "dataset = tf.data.TFRecordDataset(fname)\n",
        "img_example = next(iter(dataset))\n",
        "img_parsed = tf.train.Example.FromString(img_example.numpy())\n",
        "# only extract features we will actually use\n",
        "xmin=img_parsed.features.feature['image/object/bbox/xmin'].float_list.value[:]\n",
        "xmax=img_parsed.features.feature['image/object/bbox/xmax'].float_list.value[:]\n",
        "ymin=img_parsed.features.feature['image/object/bbox/ymin'].float_list.value[:]\n",
        "ymax=img_parsed.features.feature['image/object/bbox/ymax'].float_list.value[:]\n",
        "by=img_parsed.features.feature['image/by'].bytes_list.value[0].decode()\n",
        "classes=img_parsed.features.feature['image/object/class/text'].bytes_list.value[:]\n",
        "class_label=img_parsed.features.feature['image/object/class/label'].int64_list.value[:]\n",
        "img_encoded=img_parsed.features.feature['image/encoded'].bytes_list.value[0]"
      ],
      "metadata": {
        "id": "PK92uoV5p-7h"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fig = plt.figure(figsize=(10,10))\n",
        "# axes = axes = fig.add_subplot(1, 1, 1)\n",
        "# img = Image.open(BytesIO(img_encoded))\n",
        "# plot_img(img, axes, xmin, ymin, xmax, ymax, classes, class_label, by)"
      ],
      "metadata": {
        "id": "-udKyMdQELVs"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice: putting jpeg-encoded images in TFRecords does not release the full potential of TFRecords. If you are training on a machine with fast I/O and lots of disk space, it is better to do all the preprocessing before storing the image as normalized float array. Let's define another function for this:"
      ],
      "metadata": {
        "id": "CEQLIixA8lJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tf_example2(imagedf, longest_edge=1024):  \n",
        "    # Filename of the image (full path is useful when there are multiple image directories)\n",
        "    fname = ARTAXOR_PATH+imagedf.file.iloc[0]  #exclude image path \n",
        "    filename=fname.split('/')[-1]              #exclude image name\n",
        "    by = get_attribution(fname)                #exclude EXIF data\n",
        "    img = Image.open(fname, \"r\")\n",
        "    source_id = filename.split('.')[0]\n",
        "\n",
        "    # resize image if larger that longest edge while keeping aspect ratio\n",
        "    if max(img.size) > longest_edge:\n",
        "        img.thumbnail((longest_edge, longest_edge), Image.ANTIALIAS)\n",
        "\n",
        "    image_data = np.asarray(img)\n",
        "\n",
        "    # storing shape will make it easy to reconstruct image later\n",
        "    image_shape = np.array(image_data.shape)\n",
        "    # convert to float\n",
        "    image_data = image_data.reshape(image_data.shape[0] * image_data.shape[1] * image_data.shape[2])\n",
        "    image_data = image_data.astype(float)/255. # normalize to [0,1]\n",
        "\n",
        "    # object bounding boxes \n",
        "    # List of normalized coordinates in bounding box (1 per box)\n",
        "    xmins, xmaxs, ymins, ymaxs = imagedf[['left', 'right', 'top', 'bottom']].values.T\n",
        "\n",
        "    # List of string class name & id of bounding box (1 per box)\n",
        "    classes_text = []\n",
        "    classes = []\n",
        "    for i in range(len(imagedf)):\n",
        "        classes_text.append(imagedf.label.iloc[i].encode())\n",
        "        classes.append(1+imagedf.label_idx.iloc[i])\n",
        "\n",
        "    tf_record = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'image/shape': tf.train.Feature(int64_list=tf.train.Int64List(value=image_shape)),\n",
        "        'image/filename': tf.train.Feature(bytes_list=tf.train.BytesList(value=[filename.encode()])),\n",
        "        'image/source_id': tf.train.Feature(bytes_list=tf.train.BytesList(value=[source_id.encode()])),\n",
        "        'image/by': tf.train.Feature(bytes_list=tf.train.BytesList(value=[by.encode()])),\n",
        "        'image/data': tf.train.Feature(float_list=tf.train.FloatList(value=image_data)),\n",
        "        'image/object/bbox/xmin': tf.train.Feature(float_list=tf.train.FloatList(value=xmins)),\n",
        "        'image/object/bbox/xmax': tf.train.Feature(float_list=tf.train.FloatList(value=xmaxs)),\n",
        "        'image/object/bbox/ymin': tf.train.Feature(float_list=tf.train.FloatList(value=ymins)),\n",
        "        'image/object/bbox/ymax': tf.train.Feature(float_list=tf.train.FloatList(value=ymaxs)),\n",
        "        'image/object/class/text': tf.train.Feature(bytes_list=tf.train.BytesList(value=classes_text)),\n",
        "        'image/object/class/label': tf.train.Feature(int64_list=tf.train.Int64List(value=classes))\n",
        "    }))\n",
        "    return tf_record"
      ],
      "metadata": {
        "id": "gVce0WX0Q_Bk"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_file2='ArTaxOr/Hymenoptera/ab30b4c2f70c.jpg'\n",
        "imagedf=objectdf[objectdf.file == sample_file2]\n",
        "tfr2 = create_tf_example2(imagedf)\n",
        "fname2 = 'image_ex2.tfrecord'\n",
        "with tf.io.TFRecordWriter(fname2) as writer:\n",
        "    writer.write(tfr2.SerializeToString())\n",
        "print(f\"Size of {fname2} is {os.path.getsize(fname2)//1024} kbytes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fc5IvqPf8wxQ",
        "outputId": "76abea3f-5b60-4ca8-e8d1-aaaefc995511"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of image_ex2.tfrecord is 9768 kbytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice: \n",
        "\n",
        "Storing image data as float gives a filesize of almost 10MB while the jpeg-encoded one was only 104kB. But now all preprocessing steps are complete, and the image can be fed directly to training (or possibly agumentation)."
      ],
      "metadata": {
        "id": "mFyEkutyRI1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset2 = tf.data.TFRecordDataset(fname2)\n",
        "img_example2 = next(iter(dataset2)) \n",
        "img_parsed2 = tf.train.Example.FromString(img_example2.numpy())\n",
        "# extract features\n",
        "xmin=img_parsed2.features.feature['image/object/bbox/xmin'].float_list.value[:]\n",
        "xmax=img_parsed2.features.feature['image/object/bbox/xmax'].float_list.value[:]\n",
        "ymin=img_parsed2.features.feature['image/object/bbox/ymin'].float_list.value[:]\n",
        "ymax=img_parsed2.features.feature['image/object/bbox/ymax'].float_list.value[:]\n",
        "by=img_parsed2.features.feature['image/by'].bytes_list.value[0].decode()\n",
        "classes=img_parsed2.features.feature['image/object/class/text'].bytes_list.value[:]\n",
        "class_label=img_parsed2.features.feature['image/object/class/label'].int64_list.value[:]\n",
        "img_shape=img_parsed2.features.feature['image/shape'].int64_list.value[:]\n",
        "img_data=img_parsed2.features.feature['image/data'].float_list.value[:]"
      ],
      "metadata": {
        "id": "K6kXJyoIL98G"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image2=np.array(img_data).reshape(img_shape) # reshape\n",
        "image2=image2*255. # scale back to [0, 255] and convert to int\n",
        "image2=image2.astype(int)\n",
        "img=Image.fromarray(np.uint8(image2))   ###????\n",
        "# fig = plt.figure(figsize=(10,10))\n",
        "# axes = axes = fig.add_subplot(1, 1, 1)\n",
        "# plot_img(img, axes, xmin, ymin, xmax, ymax, classes, class_label, by)"
      ],
      "metadata": {
        "id": "96oE9yPWNs2m"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's consider the case when we have a huge dataset, and need to create multiple TFRecords."
      ],
      "metadata": {
        "id": "gHheeeGpRaNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filelist=pd.read_pickle(pickles+'ArTaxOr_filelist.pkl')\n",
        "filelist=filelist.sample(frac=1)\n",
        "filelist.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "X1S92WRJQ7Jx",
        "outputId": "ea5806ab-1e03-47ce-bb04-f5713b744ade"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     format                                id              name  \\\n",
              "6199    jpg  fe581fd8fd1a9f2126a5f805adf4a728  c43c4edff6db.jpg   \n",
              "3267    jpg  6afabf834ab4e4678b9a48661dcbd8fb  8a60682eaf27.jpg   \n",
              "7032    jpg  d3f7c5eb4885f6fcbe86005ba8bade79  22f73c720688.jpg   \n",
              "5187    jpg  c2bcc2e6e1659db355f34f14ea77550f  3e31b19f381f.jpg   \n",
              "8299    jpg  d05a5b6709a571e7d902e02c8924846e  bde2bfd00ac8.jpg   \n",
              "\n",
              "                                      path                             size  \\\n",
              "6199      ArTaxOr/Diptera/c43c4edff6db.jpg    {'width': 790, 'height': 925}   \n",
              "3267      ArTaxOr/Odonata/8a60682eaf27.jpg  {'width': 2048, 'height': 1366}   \n",
              "7032  ArTaxOr/Lepidoptera/22f73c720688.jpg  {'width': 5184, 'height': 3456}   \n",
              "5187      ArTaxOr/Diptera/3e31b19f381f.jpg  {'width': 2048, 'height': 1536}   \n",
              "8299  ArTaxOr/Lepidoptera/bde2bfd00ac8.jpg  {'width': 2048, 'height': 1589}   \n",
              "\n",
              "      state  type  \n",
              "6199      2     1  \n",
              "3267      2     1  \n",
              "7032      2     1  \n",
              "5187      2     1  \n",
              "8299      2     1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a2b78ced-720b-46bf-af7c-fa46fdabb9e4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>format</th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>path</th>\n",
              "      <th>size</th>\n",
              "      <th>state</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6199</th>\n",
              "      <td>jpg</td>\n",
              "      <td>fe581fd8fd1a9f2126a5f805adf4a728</td>\n",
              "      <td>c43c4edff6db.jpg</td>\n",
              "      <td>ArTaxOr/Diptera/c43c4edff6db.jpg</td>\n",
              "      <td>{'width': 790, 'height': 925}</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3267</th>\n",
              "      <td>jpg</td>\n",
              "      <td>6afabf834ab4e4678b9a48661dcbd8fb</td>\n",
              "      <td>8a60682eaf27.jpg</td>\n",
              "      <td>ArTaxOr/Odonata/8a60682eaf27.jpg</td>\n",
              "      <td>{'width': 2048, 'height': 1366}</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7032</th>\n",
              "      <td>jpg</td>\n",
              "      <td>d3f7c5eb4885f6fcbe86005ba8bade79</td>\n",
              "      <td>22f73c720688.jpg</td>\n",
              "      <td>ArTaxOr/Lepidoptera/22f73c720688.jpg</td>\n",
              "      <td>{'width': 5184, 'height': 3456}</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5187</th>\n",
              "      <td>jpg</td>\n",
              "      <td>c2bcc2e6e1659db355f34f14ea77550f</td>\n",
              "      <td>3e31b19f381f.jpg</td>\n",
              "      <td>ArTaxOr/Diptera/3e31b19f381f.jpg</td>\n",
              "      <td>{'width': 2048, 'height': 1536}</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8299</th>\n",
              "      <td>jpg</td>\n",
              "      <td>d05a5b6709a571e7d902e02c8924846e</td>\n",
              "      <td>bde2bfd00ac8.jpg</td>\n",
              "      <td>ArTaxOr/Lepidoptera/bde2bfd00ac8.jpg</td>\n",
              "      <td>{'width': 2048, 'height': 1589}</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2b78ced-720b-46bf-af7c-fa46fdabb9e4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a2b78ced-720b-46bf-af7c-fa46fdabb9e4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a2b78ced-720b-46bf-af7c-fa46fdabb9e4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The contextlib2 library\n",
        " is used to automatically close all TFRecords files after writing is finished.\n",
        "\n"
      ],
      "metadata": {
        "id": "hENW4ztMRiNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import contextlib2\n",
        "\n",
        "!mkdir /content/tensorflow-tfrecords-demystified/\n",
        "\n",
        "########???????????????????????????\n",
        "def open_sharded_tfrecords(exit_stack, base_path, num_shards):\n",
        "    tf_record_output_filenames = [f'/content/tensorflow-tfrecords-demystified/{base_path}-{idx:05d}-of-{num_shards:05d}.tfrecord' for idx in range(num_shards)]\n",
        "\n",
        "    tfrecords = [exit_stack.enter_context(tf.io.TFRecordWriter(file_name)) for file_name in tf_record_output_filenames]\n",
        "\n",
        "    return tfrecords\n",
        "\n",
        "num_shards=50\n",
        "output_filebase='./ArTaxOr'\n",
        "\n",
        "with contextlib2.ExitStack() as tf_record_close_stack:\n",
        "    output_tfrecords = open_sharded_tfrecords(tf_record_close_stack, output_filebase, num_shards)\n",
        "    for i in range(len(filelist)):\n",
        "        ldf=objectdf[objectdf.id == filelist.id.iloc[i]].reset_index()\n",
        "        tf_record = create_tf_example(ldf, longest_edge=1280)\n",
        "        output_shard_index = i % num_shards\n",
        "        output_tfrecords[output_shard_index].write(tf_record.SerializeToString())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ8gpuE1RdEz",
        "outputId": "b9048a80-bf12-43c5-fbde-7dbe74a897f9"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 37min 54s, sys: 19.3 s, total: 38min 13s\n",
            "Wall time: 38min 54s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content/tensorflow-tfrecords-demystified/ArTaxOr*.tfrecord"
      ],
      "metadata": {
        "id": "E9Su-vwoSEBV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f553559-6db5-4d97-f946-71ba5c77653c"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 39M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00000-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 42M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00001-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 40M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00002-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 41M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00003-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 39M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00004-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 40M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00005-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 40M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00006-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 42M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00007-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 41M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00008-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 39M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00009-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 40M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00010-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 42M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00011-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 40M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00012-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 41M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00013-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 40M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00014-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 40M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00015-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 40M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00016-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 41M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00017-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 40M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00018-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 41M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00019-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 40M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00020-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 40M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00021-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 40M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00022-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 41M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00023-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 42M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00024-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 41M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00025-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 42M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00026-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 41M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00027-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 41M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00028-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 40M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00029-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 41M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00030-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 41M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00031-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 39M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00032-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 40M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00033-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 41M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00034-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 39M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00035-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 39M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00036-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 39M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00037-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 41M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00038-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 41M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00039-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 41M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00040-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 40M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00041-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 41M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00042-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 41M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00043-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 40M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00044-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 41M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00045-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 42M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00046-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 42M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00047-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 44M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00048-of-00050.tfrecord\n",
            "-rw-r--r-- 1 root root 40M Dec  9 07:56 /content/tensorflow-tfrecords-demystified/ArTaxOr-00049-of-00050.tfrecord\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use TF Object Detection API, a label definition file is also needed\n"
      ],
      "metadata": {
        "id": "GEDWNKvXgu63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels=pd.read_pickle(pickles+'ArTaxOr_labels.pkl')\n",
        "pbfile=open('/content/tensorflow-tfrecords-demystified/ArTaxOr.pbtxt', 'w') \n",
        "for i in range(len(labels)): \n",
        "    pbfile.write(f\"item {{\\n id: {i+1}\\n name:\\'{labels.name[i]}\\'\\n}}\\n\\n\")\n",
        "pbfile.close()"
      ],
      "metadata": {
        "id": "ZfZCeVUafIGQ"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Read a few records from one of the .tfrecord files\n",
        "# fname='./ArTaxOr-00029-of-00050.tfrecord' \n",
        "# dataset3 = tf.data.TFRecordDataset(fname)\n",
        "# fig = plt.figure(figsize=(16,18))\n",
        "# idx=1\n",
        "# for raw_record in dataset3.take(6):\n",
        "#     axes = fig.add_subplot(3, 2, idx)\n",
        "#     example = tf.train.Example()\n",
        "#     example.ParseFromString(raw_record.numpy())\n",
        "#     xmin=example.features.feature['image/object/bbox/xmin'].float_list.value[:]\n",
        "#     xmax=example.features.feature['image/object/bbox/xmax'].float_list.value[:]\n",
        "#     ymin=example.features.feature['image/object/bbox/ymin'].float_list.value[:]\n",
        "#     ymax=example.features.feature['image/object/bbox/ymax'].float_list.value[:]\n",
        "#     by=example.features.feature['image/by'].bytes_list.value[0].decode()\n",
        "#     classes=example.features.feature['image/object/class/text'].bytes_list.value[:]\n",
        "#     class_label=example.features.feature['image/object/class/label'].int64_list.value[:]\n",
        "#     img_encoded=example.features.feature['image/encoded'].bytes_list.value[0]\n",
        "#     img = Image.open(BytesIO(img_encoded))\n",
        "#     plot_img(img, axes, xmin, ymin, xmax, ymax, classes, class_label, by)\n",
        "#     idx=idx+1"
      ],
      "metadata": {
        "id": "2pgErYJpg3WD"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF2 Object Detection API"
      ],
      "metadata": {
        "id": "Zt3jjT4z9IX9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Object Detection API"
      ],
      "metadata": {
        "id": "6m-z6Qg09rzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "# Clone the tensorflow models repository if it doesn't already exist\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "metadata": {
        "id": "yPF40pyRhipQ"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the Object Detection API\n",
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ],
      "metadata": {
        "id": "dckufU_pIXTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92a5ad6e-5693-4040-cabf-5006156a4ed8"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/models/research\n",
            "Requirement already satisfied: avro-python3 in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.10.2)\n",
            "Requirement already satisfied: apache-beam in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.43.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (4.9.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.29.32)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.0.6)\n",
            "Requirement already satisfied: lvis in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Requirement already satisfied: tf-models-official>=2.5.1 in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.9.2)\n",
            "Requirement already satisfied: tensorflow_io in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.28.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.9.0)\n",
            "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: sacrebleu<=2.2.0 in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2022.6.2)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2.6.0)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.8.10)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.21.6)\n",
            "Requirement already satisfied: tensorflow-text~=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.9.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.6.0.66)\n",
            "Requirement already satisfied: pyyaml<6.0,>=5.1 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.1)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.6.0)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.11)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.7.3)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.18.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.1.97)\n",
            "Requirement already satisfied: tensorflow~=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.9.2)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.15.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: protobuf<5.0.0dev,>=3.15.0 in /usr/local/lib/python3.8/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.19.6)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.8/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.28.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.57.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (7.0.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.9.24)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->object-detection==0.1) (2022.6)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (4.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (2.9.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (2.1.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.28.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.51.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.6)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (2.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.38.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.4.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.11.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Requirement already satisfied: cloudpickle~=2.2.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2.2.0)\n",
            "Requirement already satisfied: fasteners<1.0,>=0.3 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (0.18)\n",
            "Requirement already satisfied: zstandard<1,>=0.18.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (0.19.0)\n",
            "Requirement already satisfied: pyarrow<10.0.0,>=0.15.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: fastavro<2,>=0.23.6 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.7.0)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.22.1)\n",
            "Requirement already satisfied: objsize<0.6.0,>=0.5.2 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (0.5.2)\n",
            "Requirement already satisfied: orjson<4.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (3.8.3)\n",
            "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (0.3.1.1)\n",
            "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (3.13.0)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2.7.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.8/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (4.6.0.66)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.10.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.11.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.9.0)\n",
            "Building wheels for collected packages: object-detection\n",
            "  Building wheel for object-detection (setup.py): started\n",
            "  Building wheel for object-detection (setup.py): finished with status 'done'\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1696518 sha256=bfd65f13578cab29efc09098cb8dd6f5a2c17e2892354e7938dfe038d2941f9d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-h14elixx/wheels/7d/96/c1/072a751379735e8dfdada1def1c62a89afb3cc45654fd6fd28\n",
            "Successfully built object-detection\n",
            "Installing collected packages: object-detection\n",
            "  Attempting uninstall: object-detection\n",
            "    Found existing installation: object-detection 0.1\n",
            "    Uninstalling object-detection-0.1:\n",
            "      Successfully uninstalled object-detection-0.1\n",
            "Successfully installed object-detection-0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # make sure we have the right tf version\n",
        "# !pip install tensorflow==2.4.1\n",
        "# !pip install tensorflow-addons\n",
        "\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder"
      ],
      "metadata": {
        "id": "3ySt8Y_L9zHH"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hack to enable auto-augmentation\n",
        "The auto-augmentation policy does not work in the current release, so a hack is made below to make it work."
      ],
      "metadata": {
        "id": "fpN81oZS-DMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/models/research/object_detection/utils\n",
        "# !cp autoaugment_utils.py autoaugment_utils.py.org\n",
        "\n",
        "# with open('autoaugment_utils.py.org', 'r') as f:\n",
        "#     txt = f.read()\n",
        "\n",
        "# # hack to make auto_augmentation work\n",
        "# txt = txt.replace('from tensorflow.contrib import image as contrib_image', 'from tensorflow_addons import image as contrib_image')\n",
        "# txt = txt.replace('from tensorflow.contrib import training as contrib_training', 'from collections import namedtuple')\n",
        "# txt = txt.replace('# TODO(barretzoph): Add in ArXiv link once paper is out.', 'def hparams(**kwargs):\\n    return namedtuple(\\\"HParams\\\", kwargs.keys())(*kwargs.values())\\n\\n')\n",
        "# txt = txt.replace('augmentation_hparams = contrib_training.HParams(', 'augmentation_hparams = hparams(')\n",
        "\n",
        "# with open('autoaugment_utils.py', 'w') as f:\n",
        "#     f.write(txt)\n",
        "# # copy the file to the installation directory\n",
        "# !cp autoaugment_utils.py /lib/python3.7/site-packages/object_detection/utils/.\n",
        "# %cd /content\n",
        "\n"
      ],
      "metadata": {
        "id": "49Qyxq_t93ca"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install a model from the model garden\n",
        "Choose from a large selection of object detection models in the [TensorFlow 2 Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)."
      ],
      "metadata": {
        "id": "5ZBSOWI2_614"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL = \"faster_rcnn_resnet50_v1_1024x1024_coco17_tpu-8\"\n",
        "\n",
        "%cd /content/models/research/object_detection\n",
        "!mkdir pre-trained-models\n",
        "%cd pre-trained-models\n",
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/{MODEL}.tar.gz\n",
        "!tar -xf {MODEL}.tar.gz\n",
        "!rm {MODEL}.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wQjxfo0_RdA",
        "outputId": "8365045e-2af5-45c6-ffdf-bddde021774b"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research/object_detection\n",
            "mkdir: cannot create directory ‘pre-trained-models’: File exists\n",
            "/content/models/research/object_detection/pre-trained-models\n",
            "--2022-12-09 08:02:29--  http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_1024x1024_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 172.217.194.128, 2404:6800:4003:c04::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|172.217.194.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 212150153 (202M) [application/x-tar]\n",
            "Saving to: ‘faster_rcnn_resnet50_v1_1024x1024_coco17_tpu-8.tar.gz’\n",
            "\n",
            "faster_rcnn_resnet5 100%[===================>] 202.32M  45.9MB/s    in 4.4s    \n",
            "\n",
            "2022-12-09 08:02:34 (45.9 MB/s) - ‘faster_rcnn_resnet50_v1_1024x1024_coco17_tpu-8.tar.gz’ saved [212150153/212150153]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Edit pipeline.config\n",
        "The pipeline.config file is in protocol buffer format, and we can use the config_util to change the settings we need."
      ],
      "metadata": {
        "id": "EQPnrvtRA39-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from object_detection.utils import config_util\n",
        "\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder"
      ],
      "metadata": {
        "id": "pClQyqY0BDOw"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_config = f\"./{MODEL}/pipeline.config\"\n",
        "model_dir = f\"./{MODEL}/checkpoint\"\n",
        "\n",
        "config = config_util.get_configs_from_pipeline_file(pipeline_config)\n",
        "model_config = config['model']\n",
        "\n",
        "# detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
        "\n",
        "# ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "# ckpt.restore(os.path.join(model_dir, 'ckpt-0')).expect_partial()\n",
        "\n",
        "\n",
        "model_config = config['model']\n",
        "model_config.faster_rcnn.num_classes = 7\n",
        "train_config = config['train_config']\n",
        "train_config.fine_tune_checkpoint = \"/content/models/research/object_detection/pre-trained-models/\"+MODEL+\"/checkpoint/ckpt-0\"\n",
        "# GPU memory limits batch size\n",
        "train_config.batch_size = 2\n",
        "train_config.use_bfloat16 = False\n",
        "# some models use \"fine_tune\" rather than \"detection\" for fine-tuning\n",
        "train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "# set auto-augmentation\n",
        "\n",
        "del train_config.data_augmentation_options[:]\n",
        "\n",
        "a1=train_config.data_augmentation_options.add()\n",
        "a1.autoaugment_image.policy_name = \"v2\"\n",
        "\n",
        "# training dataset (80%)\n",
        "train_input_config = config['train_input_config']\n",
        "train_input_config.label_map_path = \"/content/tensorflow-tfrecords-demystified/ArTaxOr.pbtxt\"\n",
        "train_input_config.tf_record_input_reader.input_path[:] = [\"/content/tensorflow-tfrecords-demystified/ArTaxOr-????0-of-00050.tfrecord\",\n",
        "                                                           \"/content/tensorflow-tfrecords-demystified/ArTaxOr-????2-of-00050.tfrecord\",\n",
        "                                                           \"/content/tensorflow-tfrecords-demystified/ArTaxOr-????3-of-00050.tfrecord\",\n",
        "                                                           \"/content/tensorflow-tfrecords-demystified/ArTaxOr-????4-of-00050.tfrecord\",\n",
        "                                                           \"/content/tensorflow-tfrecords-demystified/ArTaxOr-????5-of-00050.tfrecord\",\n",
        "                                                           \"/content/tensorflow-tfrecords-demystified/ArTaxOr-????6-of-00050.tfrecord\",\n",
        "                                                           \"/content/tensorflow-tfrecords-demystified/ArTaxOr-????7-of-00050.tfrecord\",\n",
        "                                                           \"/content/tensorflow-tfrecords-demystified/ArTaxOr-????9-of-00050.tfrecord\"]\n",
        "# evaluation dataset (20%)                                                           \n",
        "eval_input_config = config['eval_input_config']\n",
        "eval_input_config.label_map_path = \"/content/tensorflow-tfrecords-demystified/ArTaxOr.pbtxt\"\n",
        "eval_input_config.tf_record_input_reader.input_path[:] = [\"/content/tensorflow-tfrecords-demystified/ArTaxOr-????1-of-00050.tfrecord\",\n",
        "                                                          \"/content/tensorflow-tfrecords-demystified/ArTaxOr-????8-of-00050.tfrecord\"]\n",
        "# save pipeline.config file\n",
        "pipeline_proto = config_util.create_pipeline_proto_from_configs(config)\n",
        "config_util.save_pipeline_config(pipeline_config=pipeline_proto, \n",
        "                                 directory=f'/content/models/research/object_detection/pre-trained-models/{MODEL}')"
      ],
      "metadata": {
        "id": "FY_5v7KWBH4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fdf6d3a-148a-43c4-b155-c2155239a090"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/tensorflow-tfrecords-demystified/’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the contents of the pipeline.config file:\n",
        "\n",
        "!cat /content/models/research/object_detection/pre-trained-models/{MODEL}/pipeline.config"
      ],
      "metadata": {
        "id": "nRL9ENv3BKRD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56a8bc2b-8534-4e2b-a245-40059325cd5e"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model {\n",
            "  faster_rcnn {\n",
            "    num_classes: 7\n",
            "    image_resizer {\n",
            "      fixed_shape_resizer {\n",
            "        height: 1024\n",
            "        width: 1024\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: \"faster_rcnn_resnet50_keras\"\n",
            "      batch_norm_trainable: true\n",
            "    }\n",
            "    first_stage_anchor_generator {\n",
            "      grid_anchor_generator {\n",
            "        height_stride: 16\n",
            "        width_stride: 16\n",
            "        scales: 0.25\n",
            "        scales: 0.5\n",
            "        scales: 1.0\n",
            "        scales: 2.0\n",
            "        aspect_ratios: 0.5\n",
            "        aspect_ratios: 1.0\n",
            "        aspect_ratios: 2.0\n",
            "      }\n",
            "    }\n",
            "    first_stage_box_predictor_conv_hyperparams {\n",
            "      op: CONV\n",
            "      regularizer {\n",
            "        l2_regularizer {\n",
            "          weight: 0.0\n",
            "        }\n",
            "      }\n",
            "      initializer {\n",
            "        truncated_normal_initializer {\n",
            "          stddev: 0.01\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    first_stage_nms_score_threshold: 0.0\n",
            "    first_stage_nms_iou_threshold: 0.7\n",
            "    first_stage_max_proposals: 300\n",
            "    first_stage_localization_loss_weight: 2.0\n",
            "    first_stage_objectness_loss_weight: 1.0\n",
            "    initial_crop_size: 14\n",
            "    maxpool_kernel_size: 2\n",
            "    maxpool_stride: 2\n",
            "    second_stage_box_predictor {\n",
            "      mask_rcnn_box_predictor {\n",
            "        fc_hyperparams {\n",
            "          op: FC\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.0\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            variance_scaling_initializer {\n",
            "              factor: 1.0\n",
            "              uniform: true\n",
            "              mode: FAN_AVG\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        use_dropout: false\n",
            "        dropout_keep_probability: 1.0\n",
            "        share_box_across_classes: true\n",
            "      }\n",
            "    }\n",
            "    second_stage_post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 0.0\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 300\n",
            "      }\n",
            "      score_converter: SOFTMAX\n",
            "    }\n",
            "    second_stage_localization_loss_weight: 2.0\n",
            "    second_stage_classification_loss_weight: 1.0\n",
            "    use_matmul_crop_and_resize: true\n",
            "    clip_anchors_to_image: true\n",
            "    use_matmul_gather_in_matcher: true\n",
            "    use_static_balanced_label_sampler: true\n",
            "    use_static_shapes: true\n",
            "  }\n",
            "}\n",
            "train_config {\n",
            "  batch_size: 2\n",
            "  data_augmentation_options {\n",
            "    autoaugment_image {\n",
            "      policy_name: \"v2\"\n",
            "    }\n",
            "  }\n",
            "  sync_replicas: true\n",
            "  optimizer {\n",
            "    momentum_optimizer {\n",
            "      learning_rate {\n",
            "        cosine_decay_learning_rate {\n",
            "          learning_rate_base: 0.04\n",
            "          total_steps: 100000\n",
            "          warmup_learning_rate: 0.013333\n",
            "          warmup_steps: 2000\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "    }\n",
            "    use_moving_average: false\n",
            "  }\n",
            "  fine_tune_checkpoint: \"/content/models/research/object_detection/pre-trained-models/faster_rcnn_resnet50_v1_1024x1024_coco17_tpu-8/checkpoint/ckpt-0\"\n",
            "  num_steps: 100000\n",
            "  startup_delay_steps: 0.0\n",
            "  replicas_to_aggregate: 8\n",
            "  max_number_of_boxes: 100\n",
            "  unpad_groundtruth_tensors: false\n",
            "  fine_tune_checkpoint_type: \"detection\"\n",
            "  use_bfloat16: false\n",
            "  fine_tune_checkpoint_version: V2\n",
            "}\n",
            "train_input_reader {\n",
            "  label_map_path: \"/content/tensorflow-tfrecords-demystified/ArTaxOr.pbtxt\"\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/tensorflow-tfrecords-demystified/ArTaxOr-????0-of-00050.tfrecord\"\n",
            "    input_path: \"/content/tensorflow-tfrecords-demystified/ArTaxOr-????2-of-00050.tfrecord\"\n",
            "    input_path: \"/content/tensorflow-tfrecords-demystified/ArTaxOr-????3-of-00050.tfrecord\"\n",
            "    input_path: \"/content/tensorflow-tfrecords-demystified/ArTaxOr-????4-of-00050.tfrecord\"\n",
            "    input_path: \"/content/tensorflow-tfrecords-demystified/ArTaxOr-????5-of-00050.tfrecord\"\n",
            "    input_path: \"/content/tensorflow-tfrecords-demystified/ArTaxOr-????6-of-00050.tfrecord\"\n",
            "    input_path: \"/content/tensorflow-tfrecords-demystified/ArTaxOr-????7-of-00050.tfrecord\"\n",
            "    input_path: \"/content/tensorflow-tfrecords-demystified/ArTaxOr-????9-of-00050.tfrecord\"\n",
            "  }\n",
            "}\n",
            "eval_config {\n",
            "  metrics_set: \"coco_detection_metrics\"\n",
            "  use_moving_averages: false\n",
            "  batch_size: 1\n",
            "}\n",
            "eval_input_reader {\n",
            "  label_map_path: \"/content/tensorflow-tfrecords-demystified/ArTaxOr.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_epochs: 1\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/tensorflow-tfrecords-demystified/ArTaxOr-????1-of-00050.tfrecord\"\n",
            "    input_path: \"/content/tensorflow-tfrecords-demystified/ArTaxOr-????8-of-00050.tfrecord\"\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "_QSfYgydz4QZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/models/research\n",
        "!python object_detection/model_main_tf2.py \\\n",
        "    --num_train_steps=1000 \\\n",
        "    --pipeline_config_path=/content/models/research/object_detection/pre-trained-models/{MODEL}/pipeline.config \\\n",
        "    --model_dir=/content/ \\\n",
        "    --alsologtostderr &> /content/train.log"
      ],
      "metadata": {
        "id": "P6Iob_3ZTfpQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f1c741-545e-4be3-f50f-bb4195ed8195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -n 10 /content/train.log"
      ],
      "metadata": {
        "id": "PcuRq1pF1qx4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7137b8db-fbdf-47d6-adac-e3295a5c46d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    name_to_id = label_map_util.get_label_map_dict(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/object_detection/utils/label_map_util.py\", line 201, in get_label_map_dict\n",
            "    label_map = load_labelmap(label_map_path_or_proto)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/object_detection/utils/label_map_util.py\", line 168, in load_labelmap\n",
            "    label_map_string = fid.read()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/lib/io/file_io.py\", line 114, in read\n",
            "    self._preread_check()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/lib/io/file_io.py\", line 76, in _preread_check\n",
            "    self._read_buf = _pywrap_file_io.BufferedInputStream(\n",
            "tensorflow.python.framework.errors_impl.NotFoundError: /content/tensorflow-tfrecords-demystified/ArTaxOr.pbtxt; No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training curve by parsing the log file:\n",
        "\n",
        "\n",
        "with open('/content/train.log') as f:\n",
        "  data = f.read()\n",
        "\n",
        "loss = []\n",
        "for l in re.findall('loss=[.0-9]+', data):\n",
        "  loss.append(float(l.split('=')[-1]))\n",
        "\n",
        "step = []\n",
        "for s in re.findall(\"Step [0-9]+\", data):\n",
        "    step.append(int(s.split(' ')[-1]))\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.plot(step,loss)\n",
        "plt.legend(['model loss'])\n",
        "plt.xlabel('Global step')\n",
        "plt.title('Learning curve')"
      ],
      "metadata": {
        "id": "KYM8SGrr1wkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation step\n",
        "!python object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path=/content/models/research/object_detection/pre-trained-models/{MODEL}/pipeline.config \\\n",
        "    --model_dir=/content/training/ \\\n",
        "    --checkpoint_dir=/content/training/ \\\n",
        "    --eval_timeout=30 \\\n",
        "    --alsologtostderr"
      ],
      "metadata": {
        "id": "jelSkbSYJvM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Copy the piplie.config for later use\n",
        "!cp /content/models/research/object_detection/pre-trained-models/{MODEL}/pipeline.config /content/training/."
      ],
      "metadata": {
        "id": "GQUQTtvjJ1Rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Export trained model\n",
        "!python object_detection/exporter_main_v2.py \\\n",
        "    --input_type image_tensor \\\n",
        "    --pipeline_config_path=/kaggle/working/models/research/object_detection/pre-trained-models/{MODEL}/pipeline.config \\\n",
        "    --trained_checkpoint_dir /kaggle/working/training/ \\\n",
        "    --output_directory /kaggle/working/exported-models/effdet_d2"
      ],
      "metadata": {
        "id": "nS6-iJoYKHI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -al /kaggle/working/exported-models/effdet_d2/saved_model"
      ],
      "metadata": {
        "id": "WdDXyy26Kl_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean-up \n",
        "%cd /kaggle/working\n",
        "!rm -fr ./models"
      ],
      "metadata": {
        "id": "nYnpf7kXKl1e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}