{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Z_rpO7sX1a0L7XqXkgjDQJa93limDY6M",
      "authorship_tag": "ABX9TyNmAHAE4nSwGvZPNOKSlqlB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/Computer-Vision-Projects/blob/main/YOLO_v5_Wheet_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiiATdLgeuHj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import tqdm\n",
        "import torch\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clone YOLOv5\n",
        "\n",
        "Clone the YOLOv5 repository, and move all the yolo files to your current working directory"
      ],
      "metadata": {
        "id": "44D6dYOOfils"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n",
        "!mv yolov5/* ./"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33iCddyafZmk",
        "outputId": "13de5228-09d4-4f6c-f22f-764ed37a4f98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 15978, done.\u001b[K\n",
            "remote: Counting objects: 100% (147/147), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 15978 (delta 89), reused 118 (delta 75), pack-reused 15831\u001b[K\n",
            "Receiving objects: 100% (15978/15978), 14.61 MiB | 14.85 MiB/s, done.\n",
            "Resolving deltas: 100% (10958/10958), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "FPTbEpdyfqSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive'\n",
        "!kaggle competitions download global-wheat-detection\n",
        "!unzip \\*.zip && rm *.zip\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "g-qmqkbHgKsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/train.csv')\n",
        "bboxs = np.stack(df['bbox'].apply(lambda x: np.fromstring(x[1:-1], sep=',')))\n",
        "for i, column in enumerate(['x', 'y', 'w', 'h']):\n",
        "    df[column] = bboxs[:,i]\n",
        "df.drop(columns=['bbox'], inplace=True)\n",
        "df['x_center'] = df['x'] + df['w']/2\n",
        "df['y_center'] = df['y'] + df['h']/2\n",
        "df['classes'] = 0\n",
        "df = df[['image_id','x', 'y', 'w', 'h','x_center','y_center','classes']]\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "acVkLNE3hR8h",
        "outputId": "0d608bdc-8345-45af-9383-6ebb97d5f88b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         image_id      x      y      w      h  x_center  y_center  classes\n",
              "0       b6ab77fd7  834.0  222.0   56.0   36.0     862.0     240.0        0\n",
              "1       b6ab77fd7  226.0  548.0  130.0   58.0     291.0     577.0        0\n",
              "2       b6ab77fd7  377.0  504.0   74.0  160.0     414.0     584.0        0\n",
              "3       b6ab77fd7  834.0   95.0  109.0  107.0     888.5     148.5        0\n",
              "4       b6ab77fd7   26.0  144.0  124.0  117.0      88.0     202.5        0\n",
              "...           ...    ...    ...    ...    ...       ...       ...      ...\n",
              "147788  5e0747034   64.0  619.0   84.0   95.0     106.0     666.5        0\n",
              "147789  5e0747034  292.0  549.0  107.0   82.0     345.5     590.0        0\n",
              "147790  5e0747034  134.0  228.0  141.0   71.0     204.5     263.5        0\n",
              "147791  5e0747034  430.0   13.0  184.0   79.0     522.0      52.5        0\n",
              "147792  5e0747034  875.0  740.0   94.0   61.0     922.0     770.5        0\n",
              "\n",
              "[147793 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-308b4db9-27ea-47a6-a463-a603eb1f13fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>w</th>\n",
              "      <th>h</th>\n",
              "      <th>x_center</th>\n",
              "      <th>y_center</th>\n",
              "      <th>classes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b6ab77fd7</td>\n",
              "      <td>834.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>862.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b6ab77fd7</td>\n",
              "      <td>226.0</td>\n",
              "      <td>548.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>291.0</td>\n",
              "      <td>577.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b6ab77fd7</td>\n",
              "      <td>377.0</td>\n",
              "      <td>504.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>414.0</td>\n",
              "      <td>584.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b6ab77fd7</td>\n",
              "      <td>834.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>109.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>888.5</td>\n",
              "      <td>148.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b6ab77fd7</td>\n",
              "      <td>26.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>202.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147788</th>\n",
              "      <td>5e0747034</td>\n",
              "      <td>64.0</td>\n",
              "      <td>619.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>666.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147789</th>\n",
              "      <td>5e0747034</td>\n",
              "      <td>292.0</td>\n",
              "      <td>549.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>345.5</td>\n",
              "      <td>590.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147790</th>\n",
              "      <td>5e0747034</td>\n",
              "      <td>134.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>204.5</td>\n",
              "      <td>263.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147791</th>\n",
              "      <td>5e0747034</td>\n",
              "      <td>430.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>184.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>522.0</td>\n",
              "      <td>52.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147792</th>\n",
              "      <td>5e0747034</td>\n",
              "      <td>875.0</td>\n",
              "      <td>740.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>922.0</td>\n",
              "      <td>770.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>147793 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-308b4db9-27ea-47a6-a463-a603eb1f13fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-308b4db9-27ea-47a6-a463-a603eb1f13fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-308b4db9-27ea-47a6-a463-a603eb1f13fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# index = list(set(df.image_id))\n",
        "# len(index)\n",
        "\n",
        "# source = 'train'\n",
        "# if True:\n",
        "#     for fold in [0]:\n",
        "#         val_index = index[len(index)*fold//5:len(index)*(fold+1)//5]\n",
        "#         for name, mini in tqdm.tqdm(df.groupby('image_id')):\n",
        "#             if name in val_index:\n",
        "#                 path2save = 'val2017/'\n",
        "#             else:\n",
        "#                 path2save = 'train2017/'\n",
        "#             if not os.path.exists('convertor/fold{}/labels/'.format(fold)+path2save):\n",
        "#                 os.makedirs('convertor/fold{}/labels/'.format(fold)+path2save)\n",
        "#             with open('convertor/fold{}/labels/'.format(fold)+path2save+name+\".txt\", 'w+') as f:\n",
        "#                 row = mini[['classes','x_center','y_center','w','h']].astype(float).values\n",
        "#                 row = row/1024\n",
        "#                 row = row.astype(str)\n",
        "#                 for j in range(len(row)):\n",
        "#                     text = ' '.join(row[j])\n",
        "#                     f.write(text)\n",
        "#                     f.write(\"\\n\")\n",
        "#             if not os.path.exists('convertor/fold{}/images/{}'.format(fold,path2save)):\n",
        "#                 os.makedirs('convertor/fold{}/images/{}'.format(fold,path2save))\n",
        "#             shutil.copy(\"/content/{}/{}.jpg\".format(source,name),'convertor/fold{}/images/{}/{}.jpg'.format(fold,path2save,name))\n",
        "\n",
        "\n",
        "# index = list(set(df.image_id))  #Each picture contains lots of bounding boxes, so #BBs >> #Img_ids\n",
        "# print(f'There are {len(index)} Images with {len(df.image_id)} Bounding Boxes')\n",
        "# source = 'train'\n",
        "# if True:\n",
        "#     for fold in [0]:\n",
        "#         val_index = index[len(index)*fold//5:len(index)*(fold+1)//5]\n",
        "#         print(len(index)*fold//5, len(index)*(fold+1)//5, val_index)\n",
        "#         for name, mini in tqdm.tqdm(df.groupby('image_id')):\n",
        "#             path2save = f'convertor/fold{fold}/labels/' + 'val2017' if name in val_index else 'train2017'\n",
        "#             os.makedirs(path2save, exist_ok=True)\n",
        "\n",
        "#             with open(f'{path2save}/{name}.txt', 'w+') as f:\n",
        "#                 row = mini[['classes','x_center','y_center','w','h']].astype(float).values\n",
        "#                 row = row/1024\n",
        "#                 row = row.astype(str)\n",
        "#                 for j in range(len(row)):\n",
        "#                     text = ' '.join(row[j])\n",
        "#                     f.write(text)\n",
        "#                     f.write(\"\\n\")\n",
        "            \n",
        "#             img2save = f'convertor/fold{fold}/images/'\n",
        "#             os.makedirs(img2save, exist_ok=True)\n",
        "#             # os.replace(f\"/content/{source}/{name}.jpg\", f'{img2save}{name}.jpg')\n",
        "#             shutil.copy(f\"/content/{source}/{name}.jpg\", f'{img2save}{name}.jpg')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "index = list(set(df.image_id))  #Each picture contains lots of bounding boxes, so #BBs >> #Img_ids\n",
        "print(f'There are {len(index)} Images with {len(df.image_id)} Bounding Boxes')\n",
        "source = 'train'\n",
        "for img_name, bboxs_list in tqdm.tqdm(df.groupby('image_id')):\n",
        "    label_path = f'convertor/labels/' \n",
        "    os.makedirs(label_path, exist_ok=True)\n",
        "\n",
        "    with open(f'{label_path}/{img_name}.txt', 'w+') as f:\n",
        "        row = bboxs_list[['classes','x_center','y_center','w','h']].astype(float).values\n",
        "        row = row/1024\n",
        "        row = row.astype(str)\n",
        "        for j in range(len(row)):\n",
        "            text = ' '.join(row[j])\n",
        "            f.write(text)\n",
        "            f.write(\"\\n\")\n",
        "    \n",
        "    img_path = f'convertor/images/'\n",
        "    os.makedirs(img_path, exist_ok=True)\n",
        "    os.replace(f\"/content/train/{img_name}.jpg\", f'{img_path}{img_name}.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqlkJs8BtfwO",
        "outputId": "082bd5fe-c2e7-4d66-a8f0-6b611fec019f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 3373 Images with 147793 Bounding Boxes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3373/3373 [00:06<00:00, 537.73it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = 0.2\n",
        "img_path = 'convertor/images'\n",
        "label_path = f'convertor/labels' \n",
        "\n",
        "os.makedirs(img_path+'/train', exist_ok=True)\n",
        "os.makedirs(img_path+'/val', exist_ok=True)\n",
        "os.makedirs(label_path+'/train', exist_ok=True)\n",
        "os.makedirs(label_path+'/val', exist_ok=True)\n",
        "\n",
        "\n",
        "for i in os.listdir(img_path):\n",
        "  name = i[:-4]\n",
        "  if i == 'train' or i == 'val':\n",
        "    continue\n",
        "  if np.random.randn() < p:\n",
        "    os.rename(f'{img_path}/{name}.jpg', f'{img_path}/val/{name}.jpg')\n",
        "    os.rename(f'{label_path}/{name}.txt', f'{label_path}/val/{name}.txt')\n",
        "  else:\n",
        "    os.rename(f'{img_path}/{name}.jpg', f'{img_path}/train/{name}.jpg') \n",
        "    os.rename(f'{label_path}/{name}.txt', f'{label_path}/train/{name}.txt')  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vZmgrAFHe3M",
        "outputId": "1c09b8a5-6da0-46b5-eba8-6f314a8ed80f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "999\n",
            "999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Configuration Files\n",
        "\n",
        "For a yolo model, we need two config files with .yaml as extension; they contain:\n",
        "####1.the location of training & validation folders, the number of classes and class names\n",
        "\n",
        "####2.yolo model architecture"
      ],
      "metadata": {
        "id": "QBJE2cdJXPPD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First YAML File"
      ],
      "metadata": {
        "id": "w9_nPtoJYtgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ./convertor/wheat0.yaml\n",
        "\n",
        "# COCO 2017 dataset http://cocodataset.org - first 128 training images\n",
        "# Download command:  python -c \"from yolov5.utils.google_utils import gdrive_download; gdrive_download('1n_oKgR81BJtqk75b00eAjdv03qVCQn2f','coco128.zip')\"\n",
        "# Train command: python train.py --data ./data/coco128.yaml\n",
        "# Dataset should be placed next to yolov5 folder:\n",
        "#   /parent_folder\n",
        "#     /coco128\n",
        "#     /yolov5\n",
        "\n",
        "\n",
        "# train and val datasets (image directory or *.txt file with image paths)\n",
        "train: ./convertor/images/train/\n",
        "val: ./convertor/images/val/\n",
        "\n",
        "# number of classes\n",
        "nc: 1\n",
        "\n",
        "# class names\n",
        "names: ['wheat']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jftKGwVEYt37",
        "outputId": "a53c6527-1194-4edd-8e81-c960657575c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing ./convertor/wheat0.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Second YAML File"
      ],
      "metadata": {
        "id": "F-jSQIxYYuIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ./convertor/yolov5x.yaml\n",
        "\n",
        "# parameters\n",
        "nc: 1  # number of classes\n",
        "depth_multiple: 1.33  # model depth multiple\n",
        "width_multiple: 1.25  # layer channel multiple\n",
        "\n",
        "# parameters\n",
        "nc: 1  # number of classes\n",
        "depth_multiple: 1.33  # model depth multiple\n",
        "width_multiple: 1.25  # layer channel multiple\n",
        "\n",
        "# anchors\n",
        "anchors:\n",
        "  - [116,90, 156,198, 373,326]  # P5/32\n",
        "  - [30,61, 62,45, 59,119]  # P4/16\n",
        "  - [10,13, 16,30, 33,23]  # P3/8\n",
        "\n",
        "# YOLOv5 backbone\n",
        "backbone:\n",
        "  # [from, number, module, args]\n",
        "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
        "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
        "   [-1, 3, BottleneckCSP, [128]],\n",
        "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
        "   [-1, 9, BottleneckCSP, [256]],\n",
        "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
        "   [-1, 9, BottleneckCSP, [512]],\n",
        "   [-1, 1, Conv, [1024, 3, 2]], # 7-P5/32\n",
        "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
        "  ]\n",
        "\n",
        "# YOLOv5 head\n",
        "head:\n",
        "  [[-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
        "\n",
        "   [-1, 1, Conv, [512, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
        "\n",
        "   [-1, 1, Conv, [256, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
        "   [-1, 3, BottleneckCSP, [256, False]],\n",
        "   [-1, 1, nn.Conv2d, [na * (nc + 5), 1, 1]],  # 18 (P3/8-small)\n",
        "\n",
        "   [-2, 1, Conv, [256, 3, 2]],\n",
        "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],\n",
        "   [-1, 1, nn.Conv2d, [na * (nc + 5), 1, 1]],  # 22 (P4/16-medium)\n",
        "\n",
        "   [-2, 1, Conv, [512, 3, 2]],\n",
        "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],\n",
        "   [-1, 1, nn.Conv2d, [na * (nc + 5), 1, 1]],  # 26 (P5/32-large)\n",
        "\n",
        "   [[], 1, Detect, [nc, anchors]],  # Detect(P5, P4, P3)\n",
        "  ]"
      ],
      "metadata": {
        "id": "9oZLVD2vxhGg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afad6171-3445-4a6b-9e6a-e2560ba48bb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing ./convertor/yolov5x.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Training\n",
        "\n",
        "!python /content/train.py --img 1024 --batch 16 --epochs 10 --data /content/convertor/wheat0.yaml --name yolov5x_fold0 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1V_jXbNadHo",
        "outputId": "cf595dea-b8d6-4794-9879-7135c08e4ed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/convertor/wheat0.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=16, imgsz=1024, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=yolov5x_fold0, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
            "YOLOv5 🚀 2023-6-10 Python-3.10.12 torch-2.0.1+cu118 CPU\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\n",
            "Dataset not found ⚠️, missing paths ['/content/convertor/images/val']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/train.py\", line 642, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/train.py\", line 531, in main\n",
            "    train(opt.hyp, opt, device, callbacks)\n",
            "  File \"/content/train.py\", line 112, in train\n",
            "    data_dict = data_dict or check_dataset(data)  # check if None\n",
            "  File \"/content/utils/general.py\", line 517, in check_dataset\n",
            "    raise Exception('Dataset not found ❌')\n",
            "Exception: Dataset not found ❌\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BIrNfqTGbFZI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}