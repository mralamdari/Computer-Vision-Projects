{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVRhf9AfJaTJDtzSK6ZnOv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/Computer-Vision-Projects/blob/main/Parking_spot_detection_Complete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parking Spot Detector 1\n",
        "\n",
        "\n",
        "###Notice:\n",
        "Since the model detects 3 different parking slots, it is difficult to detect them and if you want to continue this in the future, you must create a mask for each dataset and train on the images with some masks you created not the masks in the dataset, since they are a few and not accuracte enough,\n",
        " or you can combine this two projects to get a better project of them all.\n"
      ],
      "metadata": {
        "id": "2yGwYQ71JSFh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRlKy2hlJFox"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import pickle\n",
        "import sklearn\n",
        "import skimage\n",
        "import zipfile\n",
        "import IPython\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "import xml.etree.ElementTree as ET\n",
        "from sklearn import model_selection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive'\n",
        "!kaggle datasets download -d blanderbuss/parking-lot-dataset\n",
        "!unzip \\*.zip && rm *.zip\n",
        "IPython.display.clear_output()"
      ],
      "metadata": {
        "id": "Zii-NivlJUqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Image Classifier\n",
        "At first we need to create a model to predict if a spot shown in the image is Empty or Occupied.\n",
        "\n",
        "We use the [**parking lot dataset**](https://www.kaggle.com/datasets/blanderbuss/parking-lot-dataset) from kaggle for both classification and detection tasks."
      ],
      "metadata": {
        "id": "T1ZY5-qgJX1z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data"
      ],
      "metadata": {
        "id": "9ZVkpj8QJZPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cls_data = './PKLot/PKLotSegmented'\n",
        "train_path = './data/train'\n",
        "val_path   = './data/validation'\n",
        "os.makedirs(train_path, exist_ok=True)\n",
        "os.makedirs(val_path, exist_ok=True)\n",
        "\n",
        "VAL_THRESHOLD = 0.2"
      ],
      "metadata": {
        "id": "WPbRBe0LJUnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#since the models are big so we need to select only a portion of the data so the ram won't get fulled\n",
        "limit = 80\n",
        "data_arr = []\n",
        "\n",
        "for cat in os.listdir(cls_data):\n",
        "  for crs in os.listdir(cls_data+'/'+cat):\n",
        "    for day in os.listdir(cls_data+'/'+cat+'/'+crs):\n",
        "      for E_O in os.listdir(cls_data+'/'+cat+'/'+crs+'/'+day):\n",
        "        for img in os.listdir(cls_data+'/'+cat+'/'+crs+'/'+day+'/'+E_O)[:limit]:\n",
        "          path = os.path.join(cls_data, cat, crs, day, E_O, img)\n",
        "          folder_name = train_path if np.random.randn()<VAL_THRESHOLD else val_path\n",
        "          target = os.path.join(folder_name, img)\n",
        "          label = 0 if E_O == 'Empty' else 1\n",
        "          data_arr.append([target, label])\n",
        "          os.replace(path, target)\n",
        "\n",
        "\n",
        "data = pd.DataFrame(data_arr, columns=['path', 'label'])\n",
        "data"
      ],
      "metadata": {
        "id": "rQtp2iQAJUlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.groupby(['label']).count()"
      ],
      "metadata": {
        "id": "Z2RGH1XqJUi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds, val_ds = tf.keras.utils.image_dataset_from_directory('./data',\n",
        "                                                               validation_split=0.2,\n",
        "                                                               subset='both',\n",
        "                                                               seed=32,\n",
        "                                                               image_size=(150, 150),\n",
        "                                                               batch_size=32)"
      ],
      "metadata": {
        "id": "bf1m1-RBJfS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualization"
      ],
      "metadata": {
        "id": "HCutfbqiJhwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images(ds, augmentation=False):\n",
        "  plt.figure(figsize=(3, 3))\n",
        "  for images, labels in ds.take(1):\n",
        "      for i in range(9):\n",
        "          ax = plt.subplot(3, 3, i + 1)\n",
        "          if augmentation:\n",
        "            images = data_augmentation(images)\n",
        "            i = 0\n",
        "          plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "          plt.title(int(labels[i]))\n",
        "          plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "soojbxPaJfQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_images(train_ds)"
      ],
      "metadata": {
        "id": "qaIw2dLRJfOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomRotation(factor=0.15),\n",
        "    tf.keras.layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
        "    tf.keras.layers.RandomFlip(),\n",
        "    tf.keras.layers.RandomContrast(factor=0.1),\n",
        "    ], name=\"img_augmentation\")"
      ],
      "metadata": {
        "id": "u3T3IW3yJpIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_images(train_ds, augmentation=True)"
      ],
      "metadata": {
        "id": "BXgPT7i8JqYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_train_ds = train_ds.map(lambda img, label : (data_augmentation(img), label),\n",
        "                                  num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "#(buffered) Prefetching samples in GPU memory helps maximize GPU utilization.\n",
        "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
        "val_ds   = val_ds.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "lxHdzcIAJrmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_hist(hist, acc='binary_accuracy'):\n",
        "    plt.plot(hist.history[f\"{acc}\"])\n",
        "    plt.plot(hist.history[f\"val_{acc}\"])\n",
        "    plt.title(\"model accuracy\")\n",
        "    plt.ylabel(\"accuracy\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "FryQ3wJ_Jrjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1:\n",
        "**Yolo V8**\n",
        "\n",
        "Since the Yolo model needs some special data directory order, we need to change the data directory\n"
      ],
      "metadata": {
        "id": "Q25zXs61JuaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#install necessary libraries\n",
        "!pip install awscli\n",
        "!pip install ultralytics\n",
        "\n",
        "import ultralytics\n",
        "IPython.display.clear_output()"
      ],
      "metadata": {
        "id": "HyTPhkBiJrhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cls_data = './PKLot/PKLotSegmented'\n",
        "train_path_1 = './data/train/Empty/'\n",
        "train_path_2 = './data/train/Occupied/'\n",
        "val_path_1   = './data/validation/Empty/'\n",
        "val_path_2   = './data/validation/Occupied/'\n",
        "\n",
        "os.makedirs(train_path_1, exist_ok=True)\n",
        "os.makedirs(val_path_1, exist_ok=True)\n",
        "os.makedirs(train_path_2, exist_ok=True)\n",
        "os.makedirs(val_path_2, exist_ok=True)\n",
        "\n",
        "VAL_THRESHOLD = 0.2\n",
        "data_arr = []\n",
        "limit = 40\n",
        "\n",
        "\n",
        "data = pd.DataFrame(data_arr, columns=['path', 'label'])\n",
        "for cat in os.listdir(cls_data):\n",
        "  for crs in os.listdir(cls_data+'/'+cat):\n",
        "    for day in os.listdir(cls_data+'/'+cat+'/'+crs):\n",
        "      for E_O in os.listdir(cls_data+'/'+cat+'/'+crs+'/'+day):\n",
        "        for img in os.listdir(cls_data+'/'+cat+'/'+crs+'/'+day+'/'+E_O)[:limit]:\n",
        "          path = os.path.join(cls_data, cat, crs, day, E_O, img)\n",
        "          folder_name = 'train' if np.random.randn()<VAL_THRESHOLD else 'validation'\n",
        "          target = os.path.join('./data', folder_name, E_O, img)\n",
        "          label = 0 if E_O == 'Empty' else 1\n",
        "          data_arr.append([target, label])\n",
        "          os.replace(path, target)\n",
        "          break\n",
        "\n",
        "data = pd.DataFrame(data_arr, columns=['path', 'label'])\n",
        "data"
      ],
      "metadata": {
        "id": "OyNccrI4Jrep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = YOLO('yolov8n.yaml').load('yolov8n-cls.pt')  # build from YAML and transfer weights\n",
        "model = ultralytics.YOLO('yolov8n-cls.pt')\n",
        "model.train(data='./data', epochs = 10, device='cpu', seed=32)"
      ],
      "metadata": {
        "id": "VDgPe2ySJrcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model 2:\n",
        "SVC model from sklearn since our data is so simple that CNN can't detect any patterns we can get a simpler model like SVC to handle this problem."
      ],
      "metadata": {
        "id": "-OPQGVr1J8Xa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "for path, label in data_arr:\n",
        "  folder = path.split('/')[2]\n",
        "  img = skimage.io.imread(path)\n",
        "  img = skimage.transform.resize(img, (20, 20))\n",
        "\n",
        "  if folder == 'validation':\n",
        "    x_test.append(img.flatten())\n",
        "    y_test.append(label)\n",
        "  else:\n",
        "    x_train.append(img.flatten())\n",
        "    y_train.append(label)\n",
        "\n",
        "\n",
        "x_test = np.asarray(x_test)\n",
        "y_test = np.asarray(y_test)\n",
        "x_train = np.asarray(x_train)\n",
        "y_train = np.asarray(y_train)\n",
        "\n",
        "print(x_train.shape,y_train.shape)\n",
        "print(x_test.shape,y_test.shape)"
      ],
      "metadata": {
        "id": "vgMZ98pPJ7DW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = svm.SVC()\n",
        "\n",
        "parameters = [{'gamma': [0.01, 0.001, 0.0001], 'C': [1, 10, 100, 1000]}]\n",
        "\n",
        "grid_search = model_selection.GridSearchCV(clf, parameters)"
      ],
      "metadata": {
        "id": "uIAuR73PJ6-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# test performance\n",
        "best_estimator = grid_search.best_estimator_\n",
        "\n",
        "y_prediction = best_estimator.predict(x_test)\n",
        "\n",
        "score = metrics.accuracy_score(y_prediction, y_test)\n",
        "\n",
        "print(f'{score * 100}% of samples were correctly classified')\n",
        "\n",
        "pickle.dump(best_estimator, open('./drive/MyDrive/DATA/car_spot_model.p', 'wb'))"
      ],
      "metadata": {
        "id": "Nz8bSzA-J68B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = []\n",
        "test_label = []\n",
        "\n",
        "for cat in os.listdir(cls_data):\n",
        "  for crs in os.listdir(cls_data+'/'+cat):\n",
        "    for day in os.listdir(cls_data+'/'+cat+'/'+crs):\n",
        "      for E_O in os.listdir(cls_data+'/'+cat+'/'+crs+'/'+day):\n",
        "        for img in os.listdir(cls_data+'/'+cat+'/'+crs+'/'+day+'/'+E_O):\n",
        "          path = os.path.join(cls_data, cat, crs, day, E_O, img)\n",
        "          folder_name = train_path if np.random.randn()<VAL_THRESHOLD else val_path\n",
        "          target = os.path.join(folder_name, img)\n",
        "          label = 0 if E_O == 'Empty' else 1\n",
        "          test_data.append(path)\n",
        "          test_label.append(label)\n",
        "\n",
        "\n",
        "test = pd.DataFrame(test_data, columns=['path'])\n",
        "test"
      ],
      "metadata": {
        "id": "TEaS2n6PJ65k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = []\n",
        "for path, label in zip(test_data, test_label):\n",
        "  folder = path.split('/')[2]\n",
        "  img = skimage.io.imread(path)\n",
        "  img = skimage.transform.resize(img, (20, 20))\n",
        "  img = np.asarray(img.flatten())\n",
        "  img = np.expand_dims(img, 0)\n",
        "  pred = best_estimator.predict(img)\n",
        "  score = metrics.accuracy_score(pred, [label])\n",
        "  scores.append(score)"
      ],
      "metadata": {
        "id": "dcS6jZKtKA7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = []\n",
        "test_label = []\n",
        "\n",
        "for cat in os.listdir(cls_data):\n",
        "  for crs in os.listdir(cls_data+'/'+cat):\n",
        "    for day in os.listdir(cls_data+'/'+cat+'/'+crs):\n",
        "      for E_O in os.listdir(cls_data+'/'+cat+'/'+crs+'/'+day):\n",
        "        for img in os.listdir(cls_data+'/'+cat+'/'+crs+'/'+day+'/'+E_O):\n",
        "          path = os.path.join(cls_data, cat, crs, day, E_O, img)\n",
        "          folder_name = train_path if np.random.randn()<VAL_THRESHOLD else val_path\n",
        "          target = os.path.join(folder_name, img)\n",
        "          label = 0 if E_O == 'Empty' else 1\n",
        "          test_data.append(path)\n",
        "          test_label.append(label)\n",
        "\n",
        "\n",
        "test = pd.DataFrame(test_data, columns=['path'])\n",
        "test"
      ],
      "metadata": {
        "id": "j5vZHsmRKA46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = []\n",
        "for path, label in zip(test_data, test_label):\n",
        "  folder = path.split('/')[2]\n",
        "  img = skimage.io.imread(path)\n",
        "  img = skimage.transform.resize(img, (20, 20))\n",
        "  img = np.asarray(img.flatten())\n",
        "  img = np.expand_dims(img, 0)\n",
        "  pred = best_estimator.predict(img)\n",
        "  score = metrics.accuracy_score(pred, [label])\n",
        "  scores.append(score)"
      ],
      "metadata": {
        "id": "0F8mbISBKA2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "totall_score = np.sum(scores) / len(scores)\n",
        "print(f'{totall_score * 100:.4f}% of samples were correctly classified, from {len(scores)}')\n",
        "print(f'In totall, The model got {int(np.sum(scores))} / {len(scores)} Right answer')\n",
        "print(f'In totall, The model got {len(scores) - int(np.sum(scores))} / {len(scores)} Wrong answer')"
      ],
      "metadata": {
        "id": "M9x0-g7uKJGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detection"
      ],
      "metadata": {
        "id": "7sebYn74KLKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cls_data = './PKLot/PKLotSegmented'\n",
        "train_path_1 = './data/train/Empty/'\n",
        "train_path_2 = './data/train/Occupied/'\n",
        "val_path_1   = './data/validation/Empty/'\n",
        "val_path_2   = './data/validation/Occupied/'\n",
        "\n",
        "os.makedirs(train_path_1, exist_ok=True)\n",
        "os.makedirs(val_path_1, exist_ok=True)\n",
        "os.makedirs(train_path_2, exist_ok=True)\n",
        "os.makedirs(val_path_2, exist_ok=True)"
      ],
      "metadata": {
        "id": "4tel0_oEKJEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xml_files = []\n",
        "jpg_files = []\n",
        "data_path = '/content/PKLot/PKLot/'\n",
        "\n",
        "for root, dirs, files in os.walk(data_path):\n",
        "  for my_file in files:\n",
        "    if my_file.endswith('.jpg') and os.path.exists(os.path.join(root,my_file[:-4]+'.xml')):\n",
        "      jpg_files.append(os.path.join(root, my_file))\n",
        "      xml_files.append(os.path.join(root, my_file[:-4]+'.xml'))\n",
        "\n",
        "xml_files.sort()\n",
        "jpg_files.sort()\n",
        "\n",
        "len(xml_files), len(jpg_files)"
      ],
      "metadata": {
        "id": "vvZbsdM-KI_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_ids = ['Occupied', 'Empty']\n",
        "class_mapping = dict(zip(range(len(class_ids)), class_ids))\n",
        "class_mapping"
      ],
      "metadata": {
        "id": "Fh47g5N1KN8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_parking_spaces(image_path, xml_path, save_dir='cropped_images', display_results=False, return_contours=False):\n",
        "\n",
        "  for img_p, xml_p in zip(image_path, xml_path):\n",
        "      # Load the image\n",
        "      img = cv2.imread(img_p)\n",
        "      img_contours = img.copy()\n",
        "\n",
        "      # Load the XML file\n",
        "      tree = ET.parse(xml_p)\n",
        "      root = tree.getroot()\n",
        "\n",
        "      # Define a list to store the cropped images\n",
        "      cropped_images = []\n",
        "      contours = []\n",
        "\n",
        "      os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "      # Iterate over the spaces in the XML file\n",
        "      for space in root.iter('space'):\n",
        "          # Extract the rotated rectangle and contour from the XML file\n",
        "          rotated_rect = space.find('rotatedRect')\n",
        "          contour = space.find('contour')\n",
        "          center = rotated_rect.find('center')\n",
        "          size = rotated_rect.find('size')\n",
        "          angle = rotated_rect.find('angle')\n",
        "\n",
        "          # Extract the values from the XML elements\n",
        "          cx, cy = int(center.attrib['x']), int(center.attrib['y'])\n",
        "          w, h = int(size.attrib['w']), int(size.attrib['h'])\n",
        "          angle_deg = float(angle.attrib['d'])\n",
        "\n",
        "          # Convert the angle to radians\n",
        "          # angle_rad = angle_deg * (3.14159 / 180)\n",
        "\n",
        "          # Extract the points from the contour\n",
        "          pts = []\n",
        "          for point in contour.iter('point'):\n",
        "              x, y = int(point.attrib['x']), int(point.attrib['y'])\n",
        "              pts.append((x, y))\n",
        "\n",
        "          # Create a mask for the polygon\n",
        "          mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
        "          cv2.fillPoly(mask, [np.array(pts)], (255, 255, 255))\n",
        "\n",
        "          # Rotate the mask by the angle\n",
        "          M = cv2.getRotationMatrix2D((cx, cy), angle_deg, 1)\n",
        "          rotated_mask = cv2.warpAffine(mask, M, (img.shape[1], img.shape[0]))\n",
        "\n",
        "          # Crop the region from the image\n",
        "          cropped = cv2.bitwise_and(img, img, mask=rotated_mask)\n",
        "\n",
        "          # Find the bounding box of the contour\n",
        "          x, y, w, h = cv2.boundingRect(np.array(pts))\n",
        "          # Crop the region of interest from the cropped image\n",
        "          roi = img[y:y+h, x:x+w]\n",
        "\n",
        "          # Resize the region of interest to 100x100\n",
        "          resized_roi = cv2.resize(roi, (100, 100))\n",
        "\n",
        "          # Append the cropped image to the list\n",
        "          cropped_images.append(resized_roi)\n",
        "          colors = (np.random.randint(0, 255), np.random.randint(0, 255), np.random.randint(0, 255))\n",
        "\n",
        "          # Draw the contour on the image\n",
        "          cv2.drawContours(img_contours, [np.array(pts)], 0, colors, 2)\n",
        "\n",
        "          contours.append(np.array(pts))\n",
        "\n",
        "      if display_results:\n",
        "          plt.grid(linewidth=0)\n",
        "          plt.imshow(img_contours)\n",
        "          plt.show()\n",
        "\n",
        "      # Convert the list of cropped images to a numpy array\n",
        "      cropped_images_array = np.array(cropped_images)\n",
        "\n",
        "      contours = np.array(contours)\n",
        "\n",
        "      if return_contours:\n",
        "              return cropped_images_array, contours\n",
        "\n",
        "  return cropped_images_array"
      ],
      "metadata": {
        "id": "tDxDSU2mKN6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = extract_parking_spaces([jpg_files[9000]], [xml_files[9000]], display_results=True)\n",
        "res.shape"
      ],
      "metadata": {
        "id": "Em0wgwk9KN0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_parking_spaces(jpg_files, json_file, display=True, return_contours=False, roi_size=20):\n",
        "\n",
        "    # Load the image\n",
        "    img = cv2.imread(jpg_files)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    img_contours = img.copy()\n",
        "    # Define a list to store the cropped images\n",
        "    cropped_images = []\n",
        "    contours = []\n",
        "\n",
        "    with open(json_file) as f:\n",
        "      json_dic = json.load(f)\n",
        "\n",
        "    full_mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
        "    for id, shape in enumerate(json_dic['shapes']):\n",
        "      points = shape['points']\n",
        "      pts = []\n",
        "      for p in points:\n",
        "        pts.append((int(p[0]), int(p[1])))\n",
        "\n",
        "      mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
        "      cv2.fillPoly(mask, [np.array(pts)], (255, 255, 255))\n",
        "      cv2.fillPoly(full_mask, [np.array(pts)], (255, 255, 255))\n",
        "      # Crop the region from the image\n",
        "      cropped = cv2.bitwise_and(img, img, mask=mask)\n",
        "\n",
        "      # Find the bounding box of the contour\n",
        "      x, y, w, h = cv2.boundingRect(np.array(pts))\n",
        "      # Crop the region of interest from the cropped image\n",
        "      roi = img[y:y+h, x:x+w]\n",
        "\n",
        "      # Resize the region of interest to 20x20\n",
        "      resized_roi = cv2.resize(roi, (roi_size, roi_size))\n",
        "\n",
        "      # Append the cropped image to the list\n",
        "      cropped_images.append(resized_roi)\n",
        "      colors = (np.random.randint(0, 255), np.random.randint(0, 255), np.random.randint(0, 255))\n",
        "\n",
        "    # Draw the contour on the image\n",
        "      cv2.drawContours(img_contours, [np.array(pts)], 0, colors, 2)\n",
        "\n",
        "      contours.append(np.array(pts))\n",
        "\n",
        "      img_contours = cv2.putText(img_contours, str(id), pts[2], cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1, cv2.LINE_AA)\n",
        "      full_mask = cv2.putText(full_mask, str(id), pts[2], cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 1, cv2.LINE_AA)\n",
        "\n",
        "    if display:\n",
        "      plt.imshow(full_mask)\n",
        "      plt.show()\n",
        "\n",
        "      plt.grid(linewidth=0)\n",
        "      plt.imshow(img_contours)\n",
        "      plt.show()\n",
        "\n",
        "    cropped_images_array = np.array(cropped_images)\n",
        "\n",
        "    if return_contours:\n",
        "          return cropped_images_array, contours\n",
        "    return cropped_images_array"
      ],
      "metadata": {
        "id": "g6vvzF7TKTSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jpg_files = '/content/drive/MyDrive/DATA/2012-12-12_10_00_05.jpg'\n",
        "json_files = '/content/drive/MyDrive/DATA/2012-12-12_10_00_05.json'\n",
        "\n",
        "s = extract_parking_spaces(jpg_files, json_files)\n",
        "s.shape"
      ],
      "metadata": {
        "id": "_tQN2Rd3KTP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jpg_files = '/content/drive/MyDrive/DATA/2013-03-09_13_10_08.jpg'\n",
        "json_files = '/content/drive/MyDrive/DATA/2013-03-09_13_10_08.json'\n",
        "\n",
        "s = extract_parking_spaces(jpg_files, json_files)\n",
        "s.shape"
      ],
      "metadata": {
        "id": "z5IWkR5LKTNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jpg_files = '/content/drive/MyDrive/DATA/2012-10-25_08_23_19.jpg'\n",
        "json_files = '/content/drive/MyDrive/DATA/2012-10-25_08_23_19.json'\n",
        "\n",
        "s = extract_parking_spaces(jpg_files, json_files)\n",
        "s.shape"
      ],
      "metadata": {
        "id": "mgoWsa2dKXJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parking1 = '/content/PKLot/PKLot/PUCPR/'\n",
        "parking2 = '/content/PKLot/PKLot/UFPR04/'\n",
        "parking3 = '/content/PKLot/PKLot/UFPR05/'\n",
        "\n",
        "mask1 = '/content/drive/MyDrive/DATA/2012-10-25_08_23_19.json'\n",
        "mask2 = '/content/drive/MyDrive/DATA/2012-12-12_10_00_05.json'\n",
        "mask3 = '/content/drive/MyDrive/DATA/2013-03-09_13_10_08.json'"
      ],
      "metadata": {
        "id": "6UmMDMw5KXC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = pickle.load(open('./drive/MyDrive/DATA/car_spot_model.p', 'rb'))"
      ],
      "metadata": {
        "id": "Tbpqp4L4KXAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(image_path, json_path, classifier=None, display=True):\n",
        "    lots, contours = extract_parking_spaces(jpg_files, json_files, display=False, return_contours=True)\n",
        "    image = skimage.io.imread(jpg_files)\n",
        "\n",
        "    for i, lot in enumerate(lots):\n",
        "        img = np.asarray(lot.flatten())\n",
        "        img = np.expand_dims(img, 0)\n",
        "        pred = model.predict(img)\n",
        "        # print(pred)\n",
        "        color = (0, 255, 0) if pred[0] == 1 else (0, 0, 255)\n",
        "        cv2.drawContours(image, [contours[i]], 0, color, 2)\n",
        "\n",
        "    if display:\n",
        "        plt.grid(linewidth=1)\n",
        "        plt.imshow(image)\n",
        "        print(image.shape)\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "YLt-13DkKW7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jpg_files = '/content/drive/MyDrive/DATA/2012-10-25_08_23_19.jpg'\n",
        "json_files = '/content/drive/MyDrive/DATA/2012-10-25_08_23_19.json'\n",
        "\n",
        "make_predictions(jpg_files, json_files, classifier=model, display=True)"
      ],
      "metadata": {
        "id": "X2D7-O2_Kbtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jpg_files = '/content/drive/MyDrive/DATA/2013-03-09_13_10_08.jpg'\n",
        "json_files = '/content/drive/MyDrive/DATA/2013-03-09_13_10_08.json'\n",
        "\n",
        "make_predictions(jpg_files, json_files, classifier=model, display=True)"
      ],
      "metadata": {
        "id": "OUbMqxcUKbrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jpg_files = '/content/drive/MyDrive/DATA/2012-12-12_10_00_05.jpg'\n",
        "json_files = '/content/drive/MyDrive/DATA/2012-12-12_10_00_05.json'\n",
        "\n",
        "make_predictions(jpg_files, json_files, classifier=model, display=True)"
      ],
      "metadata": {
        "id": "-NWyCiTGKfIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parking Spot Detector 2\n",
        "\n",
        "\n",
        "###Notice:\n",
        "\n",
        "Since the camera that records the video, moves some inches throughout the whole video, the mask we created, won't be on the exact parking spots so the model won't work that great but you can get a new video and try the script with it in the future."
      ],
      "metadata": {
        "id": "PWreuJ65Kq7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from sklearn import ensemble\n",
        "from sklearn import linear_model\n",
        "from sklearn import model_selection"
      ],
      "metadata": {
        "id": "xXbOPZslKsKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: get the video from youtube and take it's frames"
      ],
      "metadata": {
        "id": "lSisBAf7Kv4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.youtube.com/watch?v=yojapmOkIfg\n",
        "v1 = './yt5s.io-Busy Parking Lot - Aerial Time-Lapse-(1080p).mp4'\n",
        "\n",
        "os.makedirs('./frames/', exist_ok=True)\n",
        "\n",
        "cap = cv2.VideoCapture(v1)\n",
        "\n",
        "i = 0\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    i += 1\n",
        "    if ret:\n",
        "        cv2.imwrite(f'./frames/{i}.jpg', frame)\n",
        "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "            break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "rkO4bLjBKsEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step2: read each frame and get the labels based on the mask you created from a single frame"
      ],
      "metadata": {
        "id": "1A8O4GjDK8Gr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_parking_spaces(jpg_files, json_file, display=True, return_contours=True, return_labels=True, roi_size=100):\n",
        "\n",
        "    # Load the image\n",
        "    if type(jpg_files) == str:\n",
        "        img = cv2.imread(jpg_files)\n",
        "    else:\n",
        "        img = jpg_files\n",
        "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    img_contours = img.copy()\n",
        "    # Define a list to store the cropped images\n",
        "    cropped_images = []\n",
        "    contours = []\n",
        "    labels = []\n",
        "    with open(json_file) as f:\n",
        "      json_dic = json.load(f)\n",
        "\n",
        "    full_mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
        "    for id, shape in enumerate(json_dic['shapes']):\n",
        "      labels.append(int(shape['label']))\n",
        "      points = shape['points']\n",
        "      pts = []\n",
        "      for p in points:\n",
        "        pts.append((int(p[0]), int(p[1])))\n",
        "\n",
        "      mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
        "      cv2.fillPoly(mask, [np.array(pts)], (255, 255, 255))\n",
        "      cv2.fillPoly(full_mask, [np.array(pts)], (255, 255, 255))\n",
        "      # Crop the region from the image\n",
        "      cropped = cv2.bitwise_and(img, img, mask=mask)\n",
        "\n",
        "      # Find the bounding box of the contour\n",
        "      x, y, w, h = cv2.boundingRect(np.array(pts))\n",
        "      # Crop the region of interest from the cropped image\n",
        "      roi = img[y:y+h, x:x+w]\n",
        "      # Resize the region of interest to 20x20\n",
        "      resized_roi = cv2.resize(roi, (roi_size, roi_size))\n",
        "      # Append the cropped image to the list\n",
        "      cropped_images.append(resized_roi)\n",
        "      colors = (np.random.randint(0, 255), np.random.randint(0, 255), np.random.randint(0, 255))\n",
        "\n",
        "    # Draw the contour on the image\n",
        "      xmin, ymin = np.array(pts)[0]\n",
        "      xmax, ymax = np.array(pts)[1]\n",
        "      w = xmax - xmin\n",
        "      h = ymax - ymin\n",
        "      Coordinates = [np.array([(xmin, ymin), (xmin+w, ymin), (xmax, ymax), (xmin, ymin+h)])]\n",
        "#       cv2.drawContours(img_contours, [(xmin, ymin), (xmin+w, ymin), (xmax, ymax), (xmin, ymin+h)], 0, colors, 2)\n",
        "      cv2.drawContours(img_contours, Coordinates, -1, colors, 2)\n",
        "      cv2.drawContours(full_mask, Coordinates, -1, colors, 2)\n",
        "\n",
        "      contours.append(np.array(Coordinates))\n",
        "\n",
        "    img_contours = cv2.putText(img_contours, str(id), pts[0], cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1, cv2.LINE_AA)\n",
        "    full_mask = cv2.putText(full_mask, str(id), pts[0], cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 1, cv2.LINE_AA)\n",
        "\n",
        "    if display:\n",
        "      plt.imshow(full_mask)\n",
        "      plt.show()\n",
        "\n",
        "      plt.grid(linewidth=0)\n",
        "      plt.imshow(img_contours)\n",
        "      plt.show()\n",
        "\n",
        "    cropped_images_array = np.array(cropped_images)\n",
        "\n",
        "    if return_contours:\n",
        "        if return_labels:\n",
        "          return cropped_images_array, contours, labels\n",
        "        else:\n",
        "          return cropped_images_array, contours\n",
        "    return cropped_images_array"
      ],
      "metadata": {
        "id": "KzRHOc1iKr_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jpg_file = './1285.jpg'\n",
        "json_file = './1285.json'\n",
        "\n",
        "cropped_images_array, contours, labels = extract_parking_spaces(jpg_file, json_file)"
      ],
      "metadata": {
        "id": "UYkN-G_YKrd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step3: get some frames with spots and their labels as train/test data\n"
      ],
      "metadata": {
        "id": "f-tWCZFbLAiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cropped_images_array, contours, labels = [], [], []\n",
        "for i in os.listdir('./New folder/'):\n",
        "    num, types = i.split('.')\n",
        "    if types == 'jpg':\n",
        "        jpg_file = f'./drive/MyDrive/DATA/New_folder/{num}.jpg'\n",
        "        json_file = f'./drive/MyDrive/DATA/New_folder/{num}.json'\n",
        "        c_img, c, l = extract_parking_spaces(jpg_file, json_file, display=False)\n",
        "        cropped_images_array.extend(c_img)\n",
        "        contours.extend(c)\n",
        "        labels.extend(l)\n",
        "\n",
        "np.array(contours).shape, np.array(cropped_images_array).shape, np.array(labels).shape"
      ],
      "metadata": {
        "id": "6I2hDn-mK_Hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(labels, return_counts=True)"
      ],
      "metadata": {
        "id": "5-FAaRlZK_FP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Bias dataset\n",
        "\n",
        "Since The dataset is not biased, we only have to limit the dataset to create a balanced dataset\n"
      ],
      "metadata": {
        "id": "oEa56l66LGyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counter = 0\n",
        "X = []\n",
        "Y = []\n",
        "for img, label in zip(cropped_images_array, labels):\n",
        "    if label == 0 and counter < 600:\n",
        "        counter += 1\n",
        "        X.append(img.flatten()/255)\n",
        "        Y.append(label)\n",
        "    if label == 1:\n",
        "        X.append(img.flatten()/255)\n",
        "        Y.append(label)\n",
        "\n",
        "#     X.append(img.flatten()/255)\n",
        "#     Y.append(label)\n",
        "\n",
        "train_x, test_x, train_y, test_y = model_selection.train_test_split(X, Y, random_state=32, test_size=0.1)"
      ],
      "metadata": {
        "id": "9GY-8O3QK_Cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "MNIUWDufLMqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = linear_model.SGDClassifier(max_iter=1000, tol=1e-4, loss='log')\n",
        "model.fit(train_x, train_y)"
      ],
      "metadata": {
        "id": "5iLGNsXkLKuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(X)\n",
        "metrics.accuracy_score(pred, Y)"
      ],
      "metadata": {
        "id": "sQTNPYSRLKkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the model on some frames"
      ],
      "metadata": {
        "id": "TLKlDTeiLZPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(image_path, json_path, model=None, display=True, name='1'):\n",
        "    lots, contours = extract_parking_spaces(image_path, json_path, display=False, return_contours=True, return_labels=False)\n",
        "    image = cv2.imread(image_path).copy()\n",
        "\n",
        "    for i, lot in enumerate(lots):\n",
        "        img = np.asarray(lot.flatten())\n",
        "        img = np.expand_dims(img, 0)\n",
        "        pred = model.predict(img)\n",
        "        color = (0, 255, 0) if pred[0] == 1 else (255, 0, 0)\n",
        "        cv2.drawContours(image, [contours[i]], 0, color, 2)\n",
        "\n",
        "    if display:\n",
        "        plt.grid(linewidth=1)\n",
        "        plt.imsave(f'./{name}.jpg',image)\n",
        "        plt.imshow(image)\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "RK-wvs6wLaEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jpg_file = './4.jpg'\n",
        "json_file = './1285.json'\n",
        "\n",
        "make_predictions(jpg_file, json_file, model=model, display=True, name='4a')"
      ],
      "metadata": {
        "id": "JUYIHaLELaLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jpg_file = './5.jpg'\n",
        "json_file = './1285.json'\n",
        "\n",
        "make_predictions(jpg_file, json_file, model=model, display=True, name='5a')"
      ],
      "metadata": {
        "id": "Pueh7LGRLaJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the model on the whole video"
      ],
      "metadata": {
        "id": "sTCBoiIJLdsp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reading the input\n",
        "cap = cv2.VideoCapture(v1)\n",
        "output = cv2.VideoWriter(\"output.mp4\", cv2.VideoWriter_fourcc(*'MPEG'), 30, (520, 720))\n",
        "frame_nmr = 0\n",
        "step = 30\n",
        "\n",
        "while(True):\n",
        "    ret, frame = cap.read()\n",
        "    if ret and np.sum(frame) > 0:\n",
        "        lots, contours = extract_parking_spaces(frame, json_file, display=False, return_contours=True, return_labels=False)\n",
        "        total = len(lots)\n",
        "        count = 0\n",
        "        for i, lot in enumerate(lots):\n",
        "            img = np.asarray(lot.flatten())\n",
        "            img = np.expand_dims(img, 0)\n",
        "            pred = model.predict(img)\n",
        "            if pred[0] == 1:\n",
        "                color = (0, 255, 0)\n",
        "                count += 1\n",
        "            else:\n",
        "                color = (0, 0, 255)\n",
        "\n",
        "            cv2.drawContours(frame, [contours[i]], 0, color, 2)\n",
        "            output.write(frame)\n",
        "        cv2.rectangle(frame, (80, 20), (550, 80), (0, 0, 0), -1)\n",
        "        cv2.putText(frame, f'Available spots: {count} / {total}', (100, 60),\n",
        "        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "\n",
        "        cv2.namedWindow('output', cv2.WINDOW_NORMAL)\n",
        "        cv2.imshow(\"output\", frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "        frame_nmr += 1\n",
        "cv2.destroyAllWindows()\n",
        "output.release()\n",
        "cap.release()"
      ],
      "metadata": {
        "id": "VzKaZdVFLaGn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}